{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "740d03b15a2f4790babd1f5302c4462f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8859cace83e643b78782a7d266d9431f",
              "IPY_MODEL_960e2fb8726746ec8bd009d893968761",
              "IPY_MODEL_df1e3869ede74a728dc1b0836c48136b"
            ],
            "layout": "IPY_MODEL_90feeb189fe247dcb6118ff58806fb68"
          }
        },
        "8859cace83e643b78782a7d266d9431f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1c0b53853674b50bc7fa9d5fbb38ea3",
            "placeholder": "​",
            "style": "IPY_MODEL_7cd810f0c8d7411da2b1b54771294419",
            "value": "modules.json: 100%"
          }
        },
        "960e2fb8726746ec8bd009d893968761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93b4b1fb49ce41e4bbf8de13e2d59f8a",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_804d167e02c0463283ed0da056282415",
            "value": 349
          }
        },
        "df1e3869ede74a728dc1b0836c48136b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a6e241daba346e4aaaf88847be7fc22",
            "placeholder": "​",
            "style": "IPY_MODEL_fb5dfe79e87141e1a858a4f7974a34f2",
            "value": " 349/349 [00:00&lt;00:00, 8.64kB/s]"
          }
        },
        "90feeb189fe247dcb6118ff58806fb68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1c0b53853674b50bc7fa9d5fbb38ea3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cd810f0c8d7411da2b1b54771294419": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93b4b1fb49ce41e4bbf8de13e2d59f8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "804d167e02c0463283ed0da056282415": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a6e241daba346e4aaaf88847be7fc22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb5dfe79e87141e1a858a4f7974a34f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8cdf80b7c5174318a48acb61784fbfd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f8176ec1b534a618361d454160d3416",
              "IPY_MODEL_d99b5f98b4da47179aa1f36a4e0dc6d6",
              "IPY_MODEL_666d8308333a406ca3098804595aef0d"
            ],
            "layout": "IPY_MODEL_9e4027c1687e48d9a146879340cf77d1"
          }
        },
        "3f8176ec1b534a618361d454160d3416": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60f0b04c19e34243b1a4aecdec2cca8f",
            "placeholder": "​",
            "style": "IPY_MODEL_2aa40a8f068f452d811bb5d12f582a34",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "d99b5f98b4da47179aa1f36a4e0dc6d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6ea32a305c44dd08438c663150cc11a",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_869a0ca44295495e8fe4d1e9aa471b92",
            "value": 116
          }
        },
        "666d8308333a406ca3098804595aef0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_883c7d88248346d19901888b027094b3",
            "placeholder": "​",
            "style": "IPY_MODEL_0e4958341ce24c94b66e96a0781c8d1e",
            "value": " 116/116 [00:00&lt;00:00, 999B/s]"
          }
        },
        "9e4027c1687e48d9a146879340cf77d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60f0b04c19e34243b1a4aecdec2cca8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2aa40a8f068f452d811bb5d12f582a34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6ea32a305c44dd08438c663150cc11a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "869a0ca44295495e8fe4d1e9aa471b92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "883c7d88248346d19901888b027094b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e4958341ce24c94b66e96a0781c8d1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5201090141364aeba096441540f33b5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ce7c0629c984ddebf4f120445611441",
              "IPY_MODEL_2009440f51c24149a9864a339b439a9a",
              "IPY_MODEL_b69f9b080c6f400e9b61f3322980972c"
            ],
            "layout": "IPY_MODEL_728464a0b895450b8597fcf6828a3872"
          }
        },
        "6ce7c0629c984ddebf4f120445611441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_680b67597b384d248e14fe70aa3c0590",
            "placeholder": "​",
            "style": "IPY_MODEL_5b9c9c605f064f45b33b3ad6c390ad01",
            "value": "README.md: 100%"
          }
        },
        "2009440f51c24149a9864a339b439a9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27998701e96b4fb6b58eba1521699fea",
            "max": 10621,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7c69d0740aeb434088dbdfaddf3f2789",
            "value": 10621
          }
        },
        "b69f9b080c6f400e9b61f3322980972c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04f23a82749d4b9081eb90d880999461",
            "placeholder": "​",
            "style": "IPY_MODEL_5796f9785db54f48b12f0e8a7fa37f22",
            "value": " 10.6k/10.6k [00:00&lt;00:00, 96.7kB/s]"
          }
        },
        "728464a0b895450b8597fcf6828a3872": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "680b67597b384d248e14fe70aa3c0590": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b9c9c605f064f45b33b3ad6c390ad01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27998701e96b4fb6b58eba1521699fea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c69d0740aeb434088dbdfaddf3f2789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "04f23a82749d4b9081eb90d880999461": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5796f9785db54f48b12f0e8a7fa37f22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d84e2b53c9264cc68bad646b65ca975e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d02b263e5b294ecca9b54e7edadc40d7",
              "IPY_MODEL_8583e584f2c042b09f97629ce0765c87",
              "IPY_MODEL_582e344d4ecb4327aba2ebbe4a9accb1"
            ],
            "layout": "IPY_MODEL_536a43125e054fe496bd750a5d4c32d3"
          }
        },
        "d02b263e5b294ecca9b54e7edadc40d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49265b1de3b74671979c222c6b3373da",
            "placeholder": "​",
            "style": "IPY_MODEL_d6518fa91312439a81dc7ab5dae8d2d7",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "8583e584f2c042b09f97629ce0765c87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e79a36e568914d9ebf2995243e743fc2",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60da72eb0ef24bb784d8fc92c556940f",
            "value": 53
          }
        },
        "582e344d4ecb4327aba2ebbe4a9accb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99231476ff8740f1899f166484048b08",
            "placeholder": "​",
            "style": "IPY_MODEL_2baed9fd434b440197379da8e77f69e1",
            "value": " 53.0/53.0 [00:00&lt;00:00, 1.00kB/s]"
          }
        },
        "536a43125e054fe496bd750a5d4c32d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49265b1de3b74671979c222c6b3373da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6518fa91312439a81dc7ab5dae8d2d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e79a36e568914d9ebf2995243e743fc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60da72eb0ef24bb784d8fc92c556940f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "99231476ff8740f1899f166484048b08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2baed9fd434b440197379da8e77f69e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c580f84e67bd4d3f97682afe6cbcdb08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_04f581031f224f9cbf8a78a671dd30bf",
              "IPY_MODEL_b3b9d6ef89224aa9a785b7c028ea097e",
              "IPY_MODEL_1f068e78b4374923834644ba29a6f1d1"
            ],
            "layout": "IPY_MODEL_e77637acadd14b7e8211dddda53f0477"
          }
        },
        "04f581031f224f9cbf8a78a671dd30bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77eede7460544253b1f31c8d9148e461",
            "placeholder": "​",
            "style": "IPY_MODEL_34223b5ad016435b8a8cecc009cebcd1",
            "value": "config.json: 100%"
          }
        },
        "b3b9d6ef89224aa9a785b7c028ea097e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_710b7ae46b45434e9ac22cce091abe9e",
            "max": 571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1a820c371c94c378f46eb20a14464c5",
            "value": 571
          }
        },
        "1f068e78b4374923834644ba29a6f1d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36817b23123544fea23fea73f3fe6bee",
            "placeholder": "​",
            "style": "IPY_MODEL_3bec7ac03e12422abfb3be963a6706e1",
            "value": " 571/571 [00:00&lt;00:00, 4.33kB/s]"
          }
        },
        "e77637acadd14b7e8211dddda53f0477": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77eede7460544253b1f31c8d9148e461": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34223b5ad016435b8a8cecc009cebcd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "710b7ae46b45434e9ac22cce091abe9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1a820c371c94c378f46eb20a14464c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "36817b23123544fea23fea73f3fe6bee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bec7ac03e12422abfb3be963a6706e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9769a5bbc7e542efabb44d646968c99d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c53302de49af4f2683046b7f9cc18ed4",
              "IPY_MODEL_e593425190f34bb285a6f7d88090ba34",
              "IPY_MODEL_0c422e863ba1402a9fd8326262756ada"
            ],
            "layout": "IPY_MODEL_214136d2e53647f49e39877de3005a5b"
          }
        },
        "c53302de49af4f2683046b7f9cc18ed4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4a5948147304fa6ba400b5285df29ce",
            "placeholder": "​",
            "style": "IPY_MODEL_be47f67f1d924a73a4509e76f1e02b60",
            "value": "model.safetensors: 100%"
          }
        },
        "e593425190f34bb285a6f7d88090ba34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8be26080bf204359af36157777687b49",
            "max": 437971872,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ef7d77164284ad8877733e3504f7e5e",
            "value": 437971872
          }
        },
        "0c422e863ba1402a9fd8326262756ada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_476568b0657d4529983415d9f7f3c01c",
            "placeholder": "​",
            "style": "IPY_MODEL_cc2b712f8fcd4faea2285eaddbdfdcfa",
            "value": " 438M/438M [00:11&lt;00:00, 73.3MB/s]"
          }
        },
        "214136d2e53647f49e39877de3005a5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4a5948147304fa6ba400b5285df29ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be47f67f1d924a73a4509e76f1e02b60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8be26080bf204359af36157777687b49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ef7d77164284ad8877733e3504f7e5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "476568b0657d4529983415d9f7f3c01c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc2b712f8fcd4faea2285eaddbdfdcfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca972af323294581ab2a4d86b03ea453": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d86e3f7b8604c4a890649fbcfb07933",
              "IPY_MODEL_468d676385f14b8e9082aabada4a4550",
              "IPY_MODEL_0c0164019ec54b3f9d59593502fadab1"
            ],
            "layout": "IPY_MODEL_c191a380147748df9b9fccf662418ed1"
          }
        },
        "4d86e3f7b8604c4a890649fbcfb07933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c6b86a84dc041a38b8a9bbc84009bbb",
            "placeholder": "​",
            "style": "IPY_MODEL_95aed7ca9db649aeb957a0d1c44e65d4",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "468d676385f14b8e9082aabada4a4550": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b90432b951d497391eab594c0c72fa1",
            "max": 363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b29711797e1f48c695056664790f3283",
            "value": 363
          }
        },
        "0c0164019ec54b3f9d59593502fadab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f3118e32b1a4e148a1dbd28e0b6c2ea",
            "placeholder": "​",
            "style": "IPY_MODEL_cacc76c6df9441f9a2448ae6d32e89c9",
            "value": " 363/363 [00:00&lt;00:00, 10.1kB/s]"
          }
        },
        "c191a380147748df9b9fccf662418ed1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c6b86a84dc041a38b8a9bbc84009bbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95aed7ca9db649aeb957a0d1c44e65d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b90432b951d497391eab594c0c72fa1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b29711797e1f48c695056664790f3283": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f3118e32b1a4e148a1dbd28e0b6c2ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cacc76c6df9441f9a2448ae6d32e89c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98ea81ebb0174825bc7761c21a9ff18c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_743ed016c86644c98286f50059aa775f",
              "IPY_MODEL_582b70a324c6417fabcc6471dde2a358",
              "IPY_MODEL_3a17f4ba1b1c4bbd96edf8717c61f465"
            ],
            "layout": "IPY_MODEL_5554d345503f476aa91b0c7805fab906"
          }
        },
        "743ed016c86644c98286f50059aa775f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_735ab10dc60f44babdf48afedd8f20a3",
            "placeholder": "​",
            "style": "IPY_MODEL_ccf16d6de7d044319593480ce5125529",
            "value": "vocab.txt: 100%"
          }
        },
        "582b70a324c6417fabcc6471dde2a358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d279bc51f7e049aa962b3d081ae6adeb",
            "max": 231536,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23583af8388f403781c8fe3d3b387a77",
            "value": 231536
          }
        },
        "3a17f4ba1b1c4bbd96edf8717c61f465": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5edff04c32424354ae6b90569e411f05",
            "placeholder": "​",
            "style": "IPY_MODEL_638d9c875143491d82643a7271aa7332",
            "value": " 232k/232k [00:00&lt;00:00, 3.43MB/s]"
          }
        },
        "5554d345503f476aa91b0c7805fab906": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "735ab10dc60f44babdf48afedd8f20a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccf16d6de7d044319593480ce5125529": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d279bc51f7e049aa962b3d081ae6adeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23583af8388f403781c8fe3d3b387a77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5edff04c32424354ae6b90569e411f05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "638d9c875143491d82643a7271aa7332": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36b79347c6d046f09bb7f4d7f155af1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ace1ad2599e940d9a2dde2783e5f1714",
              "IPY_MODEL_ffe765e8d331432a95c9f2638d446df9",
              "IPY_MODEL_48fcc65f283f4bf4a0de7aec61cd74d9"
            ],
            "layout": "IPY_MODEL_98681534c63d40578b38fb0aa2632484"
          }
        },
        "ace1ad2599e940d9a2dde2783e5f1714": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_faad2852729849279a01d775a0a2e9e0",
            "placeholder": "​",
            "style": "IPY_MODEL_dab6106d08e94ce78e348cf5224ffe41",
            "value": "tokenizer.json: 100%"
          }
        },
        "ffe765e8d331432a95c9f2638d446df9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82e9285bac06468b94d038ee71b7f16c",
            "max": 466021,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f924e666f8a493ba5c6b91ab7269ef9",
            "value": 466021
          }
        },
        "48fcc65f283f4bf4a0de7aec61cd74d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fa60c0ea4f046bd9ba0948b879a4fff",
            "placeholder": "​",
            "style": "IPY_MODEL_8bcdf3e35eeb4989a3573a61bdd6112b",
            "value": " 466k/466k [00:00&lt;00:00, 10.3MB/s]"
          }
        },
        "98681534c63d40578b38fb0aa2632484": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faad2852729849279a01d775a0a2e9e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dab6106d08e94ce78e348cf5224ffe41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82e9285bac06468b94d038ee71b7f16c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f924e666f8a493ba5c6b91ab7269ef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5fa60c0ea4f046bd9ba0948b879a4fff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bcdf3e35eeb4989a3573a61bdd6112b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c373b2df2c542acb9b0fa73f36f71af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f352e76f23cf499faf10525b72f95dad",
              "IPY_MODEL_76ddfd5ac9cd43cbb80f89e0e8ff1e8a",
              "IPY_MODEL_117de8a811514d08966c6552316a18a8"
            ],
            "layout": "IPY_MODEL_b13117da84b0487c959ddfb2d7425698"
          }
        },
        "f352e76f23cf499faf10525b72f95dad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5b6ec0915a148ccac128117119deaf6",
            "placeholder": "​",
            "style": "IPY_MODEL_abff1f9e80674ce59b8c651cebac91e8",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "76ddfd5ac9cd43cbb80f89e0e8ff1e8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f54b5edb8aff4e2ebdf3280c8f2b603e",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b9e1305a84f433fa6af823c8f044c9a",
            "value": 239
          }
        },
        "117de8a811514d08966c6552316a18a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_279e45c7f35542f1861acd8e3573c16b",
            "placeholder": "​",
            "style": "IPY_MODEL_6e2e0f96f92c4a46a92623118bde0084",
            "value": " 239/239 [00:00&lt;00:00, 7.66kB/s]"
          }
        },
        "b13117da84b0487c959ddfb2d7425698": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5b6ec0915a148ccac128117119deaf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abff1f9e80674ce59b8c651cebac91e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f54b5edb8aff4e2ebdf3280c8f2b603e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b9e1305a84f433fa6af823c8f044c9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "279e45c7f35542f1861acd8e3573c16b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e2e0f96f92c4a46a92623118bde0084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bfedd7aafaf4b0a9889a724caa397d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89b57e3cddb5441fa89aa39d56f3fc85",
              "IPY_MODEL_78d35f20ec894990a42add1c08bba697",
              "IPY_MODEL_e827e34b258b4926a4adf113ccf1ffbf"
            ],
            "layout": "IPY_MODEL_259d2db53fe04d9eafdef1be306751e1"
          }
        },
        "89b57e3cddb5441fa89aa39d56f3fc85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97dc186b773e4d3f85caf31477862910",
            "placeholder": "​",
            "style": "IPY_MODEL_43fc7c6449514883bbefdb66409e8e6c",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "78d35f20ec894990a42add1c08bba697": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cb4201f169e458fa5ff2de49ad7c89b",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6c6e8ad6601410f8ae0aa9b05e9b255",
            "value": 190
          }
        },
        "e827e34b258b4926a4adf113ccf1ffbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8c75a6fd9e746ceb21862c9f2f119ff",
            "placeholder": "​",
            "style": "IPY_MODEL_b40a41a464d54aadb63b04e7fc34843a",
            "value": " 190/190 [00:00&lt;00:00, 3.51kB/s]"
          }
        },
        "259d2db53fe04d9eafdef1be306751e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97dc186b773e4d3f85caf31477862910": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43fc7c6449514883bbefdb66409e8e6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8cb4201f169e458fa5ff2de49ad7c89b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6c6e8ad6601410f8ae0aa9b05e9b255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8c75a6fd9e746ceb21862c9f2f119ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b40a41a464d54aadb63b04e7fc34843a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AslauAlexandru/Week-5-Headstarter-Accelerator-Project-5-Web-app-for-Codebase-RAG/blob/main/Week_5_Headstarter_Accelerator_Project_5_Web_app_for_Codebase_RAG_Completed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Part 1: Headstarter Codebase RAG Project and Part 2: Web app for Codebase RAG Project"
      ],
      "metadata": {
        "id": "FTmVgAC90r3Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Headstarter Codebase RAG Project"
      ],
      "metadata": {
        "id": "dTLocskubrGR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Necessary Libraries"
      ],
      "metadata": {
        "id": "MpmkP4rM1KRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pygithub langchain langchain-community openai tiktoken pinecone-client langchain_pinecone sentence-transformers"
      ],
      "metadata": {
        "id": "BGFWnzpBDkWH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5698e5b-5304-4c45-f0ed-238c26491106"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pygithub\n",
            "  Downloading PyGithub-2.5.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.4)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting pinecone-client\n",
            "  Downloading pinecone_client-5.0.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting langchain_pinecone\n",
            "  Downloading langchain_pinecone-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Collecting pynacl>=1.4.0 (from pygithub)\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: requests>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from pygithub) (2.32.3)\n",
            "Requirement already satisfied: pyjwt>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from pyjwt[crypto]>=2.4.0->pygithub) (2.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pygithub) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pygithub) (2.2.3)\n",
            "Requirement already satisfied: Deprecated in /usr/local/lib/python3.10/dist-packages (from pygithub) (1.2.15)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.2)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.19)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.143)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
            "  Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.9-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.15 (from langchain)\n",
            "  Downloading langchain_core-0.3.21-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2024.8.30)\n",
            "Collecting pinecone-plugin-inference<2.0.0,>=1.0.3 (from pinecone-client)\n",
            "  Downloading pinecone_plugin_inference-1.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone-client)\n",
            "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
            "  Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.46.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.26.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.17.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from pyjwt[crypto]>=2.4.0->pygithub) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from pynacl>=1.4.0->pygithub) (1.17.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.14.0->pygithub) (3.4.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->pygithub) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.4.1->pynacl>=1.4.0->pygithub) (2.22)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Downloading PyGithub-2.5.0-py3-none-any.whl (375 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.9/375.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.8-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.9-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_client-5.0.1-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_pinecone-0.2.0-py3-none-any.whl (11 kB)\n",
            "Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain_core-0.3.21-py3-none-any.whl (409 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.5/409.5 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_inference-1.1.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
            "Downloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
            "Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: SQLAlchemy, python-dotenv, pinecone-plugin-interface, mypy-extensions, marshmallow, httpx-sse, typing-inspect, tiktoken, pynacl, pinecone-plugin-inference, pydantic-settings, pinecone-client, dataclasses-json, aiohttp, pygithub, langchain-core, langchain_pinecone, langchain, langchain-community\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.36\n",
            "    Uninstalling SQLAlchemy-2.0.36:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.36\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.11.2\n",
            "    Uninstalling aiohttp-3.11.2:\n",
            "      Successfully uninstalled aiohttp-3.11.2\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.19\n",
            "    Uninstalling langchain-core-0.3.19:\n",
            "      Successfully uninstalled langchain-core-0.3.19\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.7\n",
            "    Uninstalling langchain-0.3.7:\n",
            "      Successfully uninstalled langchain-0.3.7\n",
            "Successfully installed SQLAlchemy-2.0.35 aiohttp-3.9.5 dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.9 langchain-community-0.3.8 langchain-core-0.3.21 langchain_pinecone-0.2.0 marshmallow-3.23.1 mypy-extensions-1.0.0 pinecone-client-5.0.1 pinecone-plugin-inference-1.1.0 pinecone-plugin-interface-0.0.7 pydantic-settings-2.6.1 pygithub-2.5.0 pynacl-1.5.0 python-dotenv-1.0.1 tiktoken-0.8.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zAIXpUxWDFSV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4a5b869-42e0-4146-b0b7-71bd2526062f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from google.colab import userdata\n",
        "from pinecone import Pinecone\n",
        "import os\n",
        "import tempfile\n",
        "from github import Github, Repository\n",
        "from git import Repo\n",
        "from openai import OpenAI\n",
        "from pathlib import Path\n",
        "from langchain.schema import Document\n",
        "from pinecone import Pinecone"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clone a GitHub Repo locally"
      ],
      "metadata": {
        "id": "hTLsQ9Ma1FpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clone_repository(repo_url):\n",
        "    \"\"\"Clones a GitHub repository to a temporary directory.\n",
        "\n",
        "    Args:\n",
        "        repo_url: The URL of the GitHub repository.\n",
        "\n",
        "    Returns:\n",
        "        The path to the cloned repository.\n",
        "    \"\"\"\n",
        "    repo_name = repo_url.split(\"/\")[-1]  # Extract repository name from URL\n",
        "    repo_path = f\"/content/{repo_name}\"\n",
        "    #repo_path=os.makedirs(repo_path, exist_ok=True)\n",
        "    if not os.path.exists(repo_path):\n",
        "\n",
        "      Repo.clone_from(repo_url, str(repo_path))\n",
        "\n",
        "      return str(repo_path)\n",
        "\n",
        "    else:\n",
        "\n",
        "      return str(repo_path)\n",
        "\n",
        "    '''\n",
        "    if os.path.exists(repo_path):\n",
        "\n",
        "      return str(repo_path)\n",
        "\n",
        "    else:\n",
        "\n",
        "      Repo.clone_from(repo_url, str(repo_path))\n",
        "\n",
        "      return str(repo_path)\n",
        "    '''\n"
      ],
      "metadata": {
        "id": "kKioMYZBDee4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = clone_repository(\"https://github.com/CoderAgent/SecureAgent\")"
      ],
      "metadata": {
        "id": "F_1zslPsDmJQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(path)"
      ],
      "metadata": {
        "id": "hFrrr5rjEfYn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de33a8ce-7ce1-42a8-d44c-765c99f8dc6f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SecureAgent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SUPPORTED_EXTENSIONS = {'.py', '.js', '.tsx', '.jsx', '.ipynb', '.java',\n",
        "                         '.cpp', '.ts', '.go', '.rs', '.vue', '.swift', '.c', '.h'}\n",
        "\n",
        "IGNORED_DIRS = {'node_modules', 'venv', 'env', 'dist', 'build', '.git',\n",
        "                '__pycache__', '.next', '.vscode', 'vendor'}"
      ],
      "metadata": {
        "id": "MQOcyi6DE5bL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_file_content(file_path, repo_path):\n",
        "    \"\"\"\n",
        "    Get content of a single file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the file\n",
        "\n",
        "    Returns:\n",
        "        Optional[Dict[str, str]]: Dictionary with file name and content\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            content = f.read()\n",
        "\n",
        "        # Get relative path from repo root\n",
        "        rel_path = os.path.relpath(file_path, repo_path)\n",
        "\n",
        "        return {\n",
        "            \"name\": rel_path,\n",
        "            \"content\": content\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file {file_path}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def get_main_files_content(repo_path: str):\n",
        "    \"\"\"\n",
        "    Get content of supported code files from the local repository.\n",
        "\n",
        "    Args:\n",
        "        repo_path: Path to the local repository\n",
        "\n",
        "    Returns:\n",
        "        List of dictionaries containing file names and contents\n",
        "    \"\"\"\n",
        "    files_content = []\n",
        "\n",
        "    try:\n",
        "        for root, _, files in os.walk(repo_path):\n",
        "            # Skip if current directory is in ignored directories\n",
        "            if any(ignored_dir in root for ignored_dir in IGNORED_DIRS):\n",
        "                continue\n",
        "\n",
        "            # Process each file in current directory\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                if os.path.splitext(file)[1] in SUPPORTED_EXTENSIONS:\n",
        "                    file_content = get_file_content(file_path, repo_path)\n",
        "                    if file_content:\n",
        "                        files_content.append(file_content)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading repository: {str(e)}\")\n",
        "\n",
        "    return files_content"
      ],
      "metadata": {
        "id": "qi0FbfdrF6Hd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_content = get_main_files_content(path)"
      ],
      "metadata": {
        "id": "9-x-fTUqHISX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drDUCMcWIC-v",
        "outputId": "53a0b2fe-48dc-4458-d390-d34f3bc38521"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'src/prompts.ts',\n",
              "  'content': 'import { encode, encodeChat } from \"gpt-tokenizer\";\\nimport type { ChatCompletionMessageParam } from \"groq-sdk/resources/chat/completions\";\\nimport type { PRFile } from \"./constants\";\\nimport {\\n  rawPatchStrategy,\\n  smarterContextPatchStrategy,\\n} from \"./context/review\";\\nimport { GROQ_MODEL, type GroqChatModel } from \"./llms/groq\";\\n\\nconst ModelsToTokenLimits: Record<GroqChatModel, number> = {\\n  \"mixtral-8x7b-32768\": 32768,\\n  \"gemma-7b-it\": 32768,\\n  \"llama3-70b-8192\": 8192,\\n  \"llama3-8b-8192\": 8192,\\n};\\n\\nexport const REVIEW_DIFF_PROMPT = `You are PR-Reviewer, a language model designed to review git pull requests.\\nYour task is to provide constructive and concise feedback for the PR, and also provide meaningful code suggestions.\\n\\nExample PR Diff input:\\n\\'\\n## src/file1.py\\n\\n@@ -12,5 +12,5 @@ def func1():\\ncode line that already existed in the file...\\ncode line that already existed in the file....\\n-code line that was removed in the PR\\n+new code line added in the PR\\n code line that already existed in the file...\\n code line that already existed in the file...\\n\\n@@ ... @@ def func2():\\n...\\n\\n\\n## src/file2.py\\n...\\n\\'\\n\\nThe review should focus on new code added in the PR (lines starting with \\'+\\'), and not on code that already existed in the file (lines starting with \\'-\\', or without prefix).\\n\\n- ONLY PROVIDE CODE SUGGESTIONS\\n- Focus on important suggestions like fixing code problems, improving performance, improving security, improving readability\\n- Avoid making suggestions that have already been implemented in the PR code. For example, if you want to add logs, or change a variable to const, or anything else, make sure it isn\\'t already in the PR code.\\n- Don\\'t suggest adding docstring, type hints, or comments.\\n- Suggestions should focus on improving the new code added in the PR (lines starting with \\'+\\')\\n- Do not say things like without seeing the full repo, or full code, or rest of the codebase. Comment only on the code you have!\\n\\nMake sure the provided code suggestions are in the same programming language.\\n\\nDon\\'t repeat the prompt in the answer, and avoid outputting the \\'type\\' and \\'description\\' fields.\\n\\nThink through your suggestions and make exceptional improvements.`;\\n\\nexport const XML_PR_REVIEW_PROMPT = `As the PR-Reviewer AI model, you are tasked to analyze git pull requests across any programming language and provide comprehensive and precise code enhancements. Keep your focus on the new code modifications indicated by \\'+\\' lines in the PR. Your feedback should hunt for code issues, opportunities for performance enhancement, security improvements, and ways to increase readability. \\n\\nEnsure your suggestions are novel and haven\\'t been previously incorporated in the \\'+\\' lines of the PR code. Refrain from proposing enhancements that add docstrings, type hints, or comments. Your recommendations should strictly target the \\'+\\' lines without suggesting the need for complete context such as the whole repo or codebase.\\n\\nYour code suggestions should match the programming language in the PR, steer clear of needless repetition or inclusion of \\'type\\' and \\'description\\' fields.\\n\\nFormulate thoughtful suggestions aimed at strengthening performance, security, and readability, and represent them in an XML format utilizing the tags: <review>, <code>, <suggestion>, <comment>, <type>, <describe>, <filename>. While multiple recommendations can be given, they should all reside within one <review> tag.\\n\\nAlso note, all your code suggestions should follow the valid Markdown syntax for GitHub, identifying the language they\\'re written in, and should be enclosed within backticks (\\\\`\\\\`\\\\`). \\n\\nDon\\'t hesitate to add as many constructive suggestions as are relevant to really improve the effectivity of the code.\\n\\nExample output:\\n\\\\`\\\\`\\\\`\\n<review>\\n  <suggestion>\\n    <describe>[Objective of the newly incorporated code]</describe>\\n    <type>[Category of the given suggestion such as performance, security, etc.]</type>\\n    <comment>[Guidance on enhancing the new code]</comment>\\n    <code>\\n    \\\\`\\\\`\\\\`[Programming Language]\\n    [Equivalent code amendment in the same language]\\n    \\\\`\\\\`\\\\`\\n    </code>\\n    <filename>[name of relevant file]</filename>\\n  </suggestion>\\n  <suggestion>\\n  ...\\n  </suggestion>\\n  ...\\n</review>\\n\\\\`\\\\`\\\\`\\n\\nNote: The \\'comment\\' and \\'describe\\' tags should elucidate the advice and why it’s given, while the \\'code\\' tag hosts the recommended code snippet within proper GitHub Markdown syntax. The \\'type\\' defines the suggestion\\'s category such as performance, security, readability, etc.`;\\n\\nexport const PR_SUGGESTION_TEMPLATE = `{COMMENT}\\n{ISSUE_LINK}\\n\\n{CODE}\\n`;\\n\\nconst assignLineNumbers = (diff: string) => {\\n  const lines = diff.split(\"\\\\n\");\\n  let newLine = 0;\\n  const lineNumbers = [];\\n\\n  for (const line of lines) {\\n    if (line.startsWith(\"@@\")) {\\n      // This is a chunk header. Parse the line numbers.\\n      const match = line.match(/@@ -\\\\d+,\\\\d+ \\\\+(\\\\d+),\\\\d+ @@/);\\n      newLine = parseInt(match[1]);\\n      lineNumbers.push(line); // keep chunk headers as is\\n    } else if (!line.startsWith(\"-\")) {\\n      // This is a line from the new file.\\n      lineNumbers.push(`${newLine++}: ${line}`);\\n    }\\n  }\\n\\n  return lineNumbers.join(\"\\\\n\");\\n};\\n\\nexport const buildSuggestionPrompt = (file: PRFile) => {\\n  const rawPatch = String.raw`${file.patch}`;\\n  const patchWithLines = assignLineNumbers(rawPatch);\\n  return `## ${file.filename}\\\\n\\\\n${patchWithLines}`;\\n};\\n\\nexport const buildPatchPrompt = (file: PRFile) => {\\n  if (file.old_contents == null) {\\n    return rawPatchStrategy(file);\\n  } else {\\n    return smarterContextPatchStrategy(file);\\n  }\\n};\\n\\nexport const getReviewPrompt = (diff: string): ChatCompletionMessageParam[] => {\\n  return [\\n    { role: \"system\", content: REVIEW_DIFF_PROMPT },\\n    { role: \"user\", content: diff },\\n  ];\\n};\\n\\nexport const getXMLReviewPrompt = (\\n  diff: string\\n): ChatCompletionMessageParam[] => {\\n  return [\\n    { role: \"system\", content: XML_PR_REVIEW_PROMPT },\\n    { role: \"user\", content: diff },\\n  ];\\n};\\n\\nexport const constructPrompt = (\\n  files: PRFile[],\\n  patchBuilder: (file: PRFile) => string,\\n  convoBuilder: (diff: string) => ChatCompletionMessageParam[]\\n) => {\\n  const patches = files.map((file) => patchBuilder(file));\\n  const diff = patches.join(\"\\\\n\");\\n  const convo = convoBuilder(diff);\\n  return convo;\\n};\\n\\nexport const getTokenLength = (blob: string) => {\\n  return encode(blob).length;\\n};\\n\\nexport const isConversationWithinLimit = (\\n  convo: any[],\\n  model: GroqChatModel = GROQ_MODEL\\n) => {\\n  // We don\\'t have the encoder for our Groq model, so we\\'re using\\n  // the one for gpt-3.5-turbo as a rough equivalent.\\n  const convoTokens = encodeChat(convo, \"gpt-3.5-turbo\").length;\\n  return convoTokens < ModelsToTokenLimits[model];\\n};\\n'},\n",
              " {'name': 'src/env.ts',\n",
              "  'content': 'import * as dotenv from \"dotenv\";\\nimport { createPrivateKey } from \"crypto\";\\nimport chalk from \"chalk\";\\n\\ndotenv.config();\\n\\nexport const env = {\\n  GITHUB_APP_ID: process.env.GITHUB_APP_ID,\\n  GITHUB_PRIVATE_KEY: process.env.GITHUB_PRIVATE_KEY,\\n  GITHUB_WEBHOOK_SECRET: process.env.GITHUB_WEBHOOK_SECRET,\\n  GROQ_API_KEY: process.env.GROQ_API_KEY,\\n} as const;\\n\\nlet valid = true;\\n\\nfor (const key in env) {\\n  if (!env[key as keyof typeof env]) {\\n    console.log(\\n      chalk.red(\"✖\") +\\n        chalk.gray(\" Missing required env var: \") +\\n        chalk.bold(`process.env.${key}`)\\n    );\\n    valid = false;\\n  }\\n}\\n\\ntry {\\n  createPrivateKey(env.GITHUB_PRIVATE_KEY);\\n} catch (error) {\\n  console.log(\\n    chalk.red(\\n      \"\\\\n✖ Invalid GitHub private key format for \" +\\n        chalk.bold(`process.env.GITHUB_PRIVATE_KEY`) +\\n        \"\\\\n\"\\n    ) +\\n      chalk.gray(\"  • Must start with: \") +\\n      chalk.bold(\"-----BEGIN RSA PRIVATE KEY-----\\\\n\") +\\n      chalk.gray(\"  • Must end with:   \") +\\n      chalk.bold(\"-----END RSA PRIVATE KEY-----\\\\n\")\\n  );\\n  valid = false;\\n}\\n\\nif (!valid) {\\n  console.log(\\n    chalk.yellow(\"\\\\n⚠ \") +\\n      chalk.bold(\"Please check your .env file and try again.\\\\n\")\\n  );\\n  process.exit(1);\\n}\\n'},\n",
              " {'name': 'src/app.ts',\n",
              "  'content': 'import { Octokit } from \"@octokit/rest\";\\nimport { createNodeMiddleware } from \"@octokit/webhooks\";\\nimport { WebhookEventMap } from \"@octokit/webhooks-definitions/schema\";\\nimport * as http from \"http\";\\nimport { App } from \"octokit\";\\nimport { Review } from \"./constants\";\\nimport { env } from \"./env\";\\nimport { processPullRequest } from \"./review-agent\";\\nimport { applyReview } from \"./reviews\";\\n\\n// This creates a new instance of the Octokit App class.\\nconst reviewApp = new App({\\n  appId: env.GITHUB_APP_ID,\\n  privateKey: env.GITHUB_PRIVATE_KEY,\\n  webhooks: {\\n    secret: env.GITHUB_WEBHOOK_SECRET,\\n  },\\n});\\n\\nconst getChangesPerFile = async (payload: WebhookEventMap[\"pull_request\"]) => {\\n  try {\\n    const octokit = await reviewApp.getInstallationOctokit(\\n      payload.installation.id\\n    );\\n    const { data: files } = await octokit.rest.pulls.listFiles({\\n      owner: payload.repository.owner.login,\\n      repo: payload.repository.name,\\n      pull_number: payload.pull_request.number,\\n    });\\n    console.dir({ files }, { depth: null });\\n    return files;\\n  } catch (exc) {\\n    console.log(\"exc\");\\n    return [];\\n  }\\n};\\n\\n// This adds an event handler that your code will call later. When this event handler is called, it will log the event to the console. Then, it will use GitHub\\'s REST API to add a comment to the pull request that triggered the event.\\nasync function handlePullRequestOpened({\\n  octokit,\\n  payload,\\n}: {\\n  octokit: Octokit;\\n  payload: WebhookEventMap[\"pull_request\"];\\n}) {\\n  console.log(\\n    `Received a pull request event for #${payload.pull_request.number}`\\n  );\\n  // const reposWithInlineEnabled = new Set<number>([601904706, 701925328]);\\n  // const canInlineSuggest = reposWithInlineEnabled.has(payload.repository.id);\\n  try {\\n    console.log(\"pr info\", {\\n      id: payload.repository.id,\\n      fullName: payload.repository.full_name,\\n      url: payload.repository.html_url,\\n    });\\n    const files = await getChangesPerFile(payload);\\n    const review: Review = await processPullRequest(\\n      octokit,\\n      payload,\\n      files,\\n      true\\n    );\\n    await applyReview({ octokit, payload, review });\\n    console.log(\"Review Submitted\");\\n  } catch (exc) {\\n    console.log(exc);\\n  }\\n}\\n\\n// This sets up a webhook event listener. When your app receives a webhook event from GitHub with a `X-GitHub-Event` header value of `pull_request` and an `action` payload value of `opened`, it calls the `handlePullRequestOpened` event handler that is defined above.\\n//@ts-ignore\\nreviewApp.webhooks.on(\"pull_request.opened\", handlePullRequestOpened);\\n\\nconst port = process.env.PORT || 3000;\\nconst reviewWebhook = `/api/review`;\\n\\nconst reviewMiddleware = createNodeMiddleware(reviewApp.webhooks, {\\n  path: \"/api/review\",\\n});\\n\\nconst server = http.createServer((req, res) => {\\n  if (req.url === reviewWebhook) {\\n    reviewMiddleware(req, res);\\n  } else {\\n    res.statusCode = 404;\\n    res.end();\\n  }\\n});\\n\\n// This creates a Node.js server that listens for incoming HTTP requests (including webhook payloads from GitHub) on the specified port. When the server receives a request, it executes the `middleware` function that you defined earlier. Once the server is running, it logs messages to the console to indicate that it is listening.\\nserver.listen(port, () => {\\n  console.log(`Server is listening for events.`);\\n  console.log(\"Press Ctrl + C to quit.\");\\n});\\n'},\n",
              " {'name': 'src/constants.ts',\n",
              "  'content': 'import { Node } from \"@babel/traverse\";\\nimport { JavascriptParser } from \"./context/language/javascript-parser\";\\nimport { ChatCompletionMessageParam } from \"groq-sdk/resources/chat/completions\";\\n\\nexport interface PRFile {\\n  sha: string;\\n  filename: string;\\n  status:\\n    | \"added\"\\n    | \"removed\"\\n    | \"renamed\"\\n    | \"changed\"\\n    | \"modified\"\\n    | \"copied\"\\n    | \"unchanged\";\\n  additions: number;\\n  deletions: number;\\n  changes: number;\\n  blob_url: string;\\n  raw_url: string;\\n  contents_url: string;\\n  patch?: string;\\n  previous_filename?: string;\\n  patchTokenLength?: number;\\n  old_contents?: string;\\n  current_contents?: string;\\n}\\n\\nexport interface BuilderResponse {\\n  comment: string;\\n  structuredComments: any[];\\n}\\n\\nexport interface Builders {\\n  convoBuilder: (diff: string) => ChatCompletionMessageParam[];\\n  responseBuilder: (feedbacks: string[]) => Promise<BuilderResponse>;\\n}\\n\\nexport interface PatchInfo {\\n  hunks: {\\n    oldStart: number;\\n    oldLines: number;\\n    newStart: number;\\n    newLines: number;\\n    lines: string[];\\n  }[];\\n}\\n\\nexport interface PRSuggestion {\\n  describe: string;\\n  type: string;\\n  comment: string;\\n  code: string;\\n  filename: string;\\n  toString: () => string;\\n  identity: () => string;\\n}\\n\\nexport interface CodeSuggestion {\\n  file: string;\\n  line_start: number;\\n  line_end: number;\\n  correction: string;\\n  comment: string;\\n}\\n\\nexport interface ChatMessage {\\n  role: string;\\n  content: string;\\n}\\n\\nexport interface Review {\\n  review: BuilderResponse;\\n  suggestions: CodeSuggestion[];\\n}\\n\\nexport interface BranchDetails {\\n  name: string;\\n  sha: string;\\n  url: string;\\n}\\n\\nexport const sleep = async (ms: number) => {\\n  return new Promise((resolve) => setTimeout(resolve, ms));\\n};\\n\\nexport const processGitFilepath = (filepath: string) => {\\n  // Remove the leading \\'/\\' if it exists\\n  return filepath.startsWith(\"/\") ? filepath.slice(1) : filepath;\\n};\\n\\nexport interface EnclosingContext {\\n  enclosingContext: Node | null;\\n}\\n\\nexport interface AbstractParser {\\n  findEnclosingContext(\\n    file: string,\\n    lineStart: number,\\n    lineEnd: number\\n  ): EnclosingContext;\\n  dryRun(file: string): { valid: boolean; error: string };\\n}\\n\\nconst EXTENSIONS_TO_PARSERS: Map<string, AbstractParser> = new Map([\\n  [\"ts\", new JavascriptParser()],\\n  [\"tsx\", new JavascriptParser()],\\n  [\"js\", new JavascriptParser()],\\n  [\"jsx\", new JavascriptParser()],\\n]);\\n\\nexport const getParserForExtension = (filename: string) => {\\n  const fileExtension = filename.split(\".\").pop().toLowerCase();\\n  return EXTENSIONS_TO_PARSERS.get(fileExtension) || null;\\n};\\n\\nexport const assignLineNumbers = (contents: string): string => {\\n  const lines = contents.split(\"\\\\n\");\\n  let lineNumber = 1;\\n  const linesWithNumbers = lines.map((line) => {\\n    const numberedLine = `${lineNumber}: ${line}`;\\n    lineNumber++;\\n    return numberedLine;\\n  });\\n  return linesWithNumbers.join(\"\\\\n\");\\n};\\n'},\n",
              " {'name': 'src/review-agent.ts',\n",
              "  'content': 'import { Octokit } from \"@octokit/rest\";\\nimport { WebhookEventMap } from \"@octokit/webhooks-definitions/schema\";\\nimport { ChatCompletionMessageParam } from \"groq-sdk/resources/chat/completions\";\\nimport * as xml2js from \"xml2js\";\\nimport type {\\n  BranchDetails,\\n  BuilderResponse,\\n  Builders,\\n  CodeSuggestion,\\n  PRFile,\\n  PRSuggestion,\\n} from \"./constants\";\\nimport { PRSuggestionImpl } from \"./data/PRSuggestionImpl\";\\nimport { generateChatCompletion } from \"./llms/chat\";\\nimport {\\n  PR_SUGGESTION_TEMPLATE,\\n  buildPatchPrompt,\\n  constructPrompt,\\n  getReviewPrompt,\\n  getTokenLength,\\n  getXMLReviewPrompt,\\n  isConversationWithinLimit,\\n} from \"./prompts\";\\nimport {\\n  INLINE_FIX_FUNCTION,\\n  getInlineFixPrompt,\\n} from \"./prompts/inline-prompt\";\\nimport { getGitFile } from \"./reviews\";\\n\\nexport const reviewDiff = async (messages: ChatCompletionMessageParam[]) => {\\n  const message = await generateChatCompletion({\\n    messages,\\n  });\\n  return message.content;\\n};\\n\\nexport const reviewFiles = async (\\n  files: PRFile[],\\n  patchBuilder: (file: PRFile) => string,\\n  convoBuilder: (diff: string) => ChatCompletionMessageParam[]\\n) => {\\n  const patches = files.map((file) => patchBuilder(file));\\n  const messages = convoBuilder(patches.join(\"\\\\n\"));\\n  const feedback = await reviewDiff(messages);\\n  return feedback;\\n};\\n\\nconst filterFile = (file: PRFile) => {\\n  const extensionsToIgnore = new Set<string>([\\n    \"pdf\",\\n    \"png\",\\n    \"jpg\",\\n    \"jpeg\",\\n    \"gif\",\\n    \"mp4\",\\n    \"mp3\",\\n    \"md\",\\n    \"json\",\\n    \"env\",\\n    \"toml\",\\n    \"svg\",\\n  ]);\\n  const filesToIgnore = new Set<string>([\\n    \"package-lock.json\",\\n    \"yarn.lock\",\\n    \".gitignore\",\\n    \"package.json\",\\n    \"tsconfig.json\",\\n    \"poetry.lock\",\\n    \"readme.md\",\\n  ]);\\n  const filename = file.filename.toLowerCase().split(\"/\").pop();\\n  if (filename && filesToIgnore.has(filename)) {\\n    console.log(`Filtering out ignored file: ${file.filename}`);\\n    return false;\\n  }\\n  const splitFilename = file.filename.toLowerCase().split(\".\");\\n  if (splitFilename.length <= 1) {\\n    console.log(`Filtering out file with no extension: ${file.filename}`);\\n    return false;\\n  }\\n  const extension = splitFilename.pop()?.toLowerCase();\\n  if (extension && extensionsToIgnore.has(extension)) {\\n    console.log(`Filtering out file with ignored extension: ${file.filename} (.${extension})`);\\n    return false;\\n  }\\n  return true;\\n};\\n\\nconst groupFilesByExtension = (files: PRFile[]): Map<string, PRFile[]> => {\\n  const filesByExtension: Map<string, PRFile[]> = new Map();\\n\\n  files.forEach((file) => {\\n    const extension = file.filename.split(\".\").pop()?.toLowerCase();\\n    if (extension) {\\n      if (!filesByExtension.has(extension)) {\\n        filesByExtension.set(extension, []);\\n      }\\n      filesByExtension.get(extension)?.push(file);\\n    }\\n  });\\n\\n  return filesByExtension;\\n};\\n\\n// all of the files here can be processed with the prompt at minimum\\nconst processWithinLimitFiles = (\\n  files: PRFile[],\\n  patchBuilder: (file: PRFile) => string,\\n  convoBuilder: (diff: string) => ChatCompletionMessageParam[]\\n) => {\\n  const processGroups: PRFile[][] = [];\\n  const convoWithinModelLimit = isConversationWithinLimit(\\n    constructPrompt(files, patchBuilder, convoBuilder)\\n  );\\n\\n  console.log(`Within model token limits: ${convoWithinModelLimit}`);\\n  if (!convoWithinModelLimit) {\\n    const grouped = groupFilesByExtension(files);\\n    for (const [extension, filesForExt] of grouped.entries()) {\\n      const extGroupWithinModelLimit = isConversationWithinLimit(\\n        constructPrompt(filesForExt, patchBuilder, convoBuilder)\\n      );\\n      if (extGroupWithinModelLimit) {\\n        processGroups.push(filesForExt);\\n      } else {\\n        // extension group exceeds model limit\\n        console.log(\\n          \"Processing files per extension that exceed model limit ...\"\\n        );\\n        let currentGroup: PRFile[] = [];\\n        filesForExt.sort((a, b) => a.patchTokenLength - b.patchTokenLength);\\n        filesForExt.forEach((file) => {\\n          const isPotentialGroupWithinLimit = isConversationWithinLimit(\\n            constructPrompt([...currentGroup, file], patchBuilder, convoBuilder)\\n          );\\n          if (isPotentialGroupWithinLimit) {\\n            currentGroup.push(file);\\n          } else {\\n            processGroups.push(currentGroup);\\n            currentGroup = [file];\\n          }\\n        });\\n        if (currentGroup.length > 0) {\\n          processGroups.push(currentGroup);\\n        }\\n      }\\n    }\\n  } else {\\n    processGroups.push(files);\\n  }\\n  return processGroups;\\n};\\n\\nconst stripRemovedLines = (originalFile: PRFile) => {\\n  // remove lines starting with a \\'-\\'\\n  const originalPatch = String.raw`${originalFile.patch}`;\\n  const strippedPatch = originalPatch\\n    .split(\"\\\\n\")\\n    .filter((line) => !line.startsWith(\"-\"))\\n    .join(\"\\\\n\");\\n  return { ...originalFile, patch: strippedPatch };\\n};\\n\\nconst processOutsideLimitFiles = (\\n  files: PRFile[],\\n  patchBuilder: (file: PRFile) => string,\\n  convoBuilder: (diff: string) => ChatCompletionMessageParam[]\\n) => {\\n  const processGroups: PRFile[][] = [];\\n  if (files.length == 0) {\\n    return processGroups;\\n  }\\n  files = files.map((file) => stripRemovedLines(file));\\n  const convoWithinModelLimit = isConversationWithinLimit(\\n    constructPrompt(files, patchBuilder, convoBuilder)\\n  );\\n  if (convoWithinModelLimit) {\\n    processGroups.push(files);\\n  } else {\\n    const exceedingLimits: PRFile[] = [];\\n    const withinLimits: PRFile[] = [];\\n    files.forEach((file) => {\\n      const isFileConvoWithinLimits = isConversationWithinLimit(\\n        constructPrompt([file], patchBuilder, convoBuilder)\\n      );\\n      if (isFileConvoWithinLimits) {\\n        withinLimits.push(file);\\n      } else {\\n        exceedingLimits.push(file);\\n      }\\n    });\\n    const withinLimitsGroup = processWithinLimitFiles(\\n      withinLimits,\\n      patchBuilder,\\n      convoBuilder\\n    );\\n    withinLimitsGroup.forEach((group) => {\\n      processGroups.push(group);\\n    });\\n    if (exceedingLimits.length > 0) {\\n      console.log(\"TODO: Need to further chunk large file changes.\");\\n      // throw \"Unimplemented\"\\n    }\\n  }\\n  return processGroups;\\n};\\n\\nconst processXMLSuggestions = async (feedbacks: string[]) => {\\n  const xmlParser = new xml2js.Parser();\\n  const parsedSuggestions = await Promise.all(\\n    feedbacks.map((fb) => {\\n      fb = fb\\n        .split(\"<code>\")\\n        .join(\"<code><![CDATA[\")\\n        .split(\"</code>\")\\n        .join(\"]]></code>\");\\n      console.log(fb);\\n      return xmlParser.parseStringPromise(fb);\\n    })\\n  );\\n  // gets suggestion arrays [[suggestion], [suggestion]], then flattens\\n  const allSuggestions = parsedSuggestions\\n    .map((sug) => sug.review.suggestion)\\n    .flat(1);\\n  const suggestions: PRSuggestion[] = allSuggestions.map((rawSuggestion) => {\\n    const lines = rawSuggestion.code[0].trim().split(\"\\\\n\");\\n    lines[0] = lines[0].trim();\\n    lines[lines.length - 1] = lines[lines.length - 1].trim();\\n    const code = lines.join(\"\\\\n\");\\n\\n    return new PRSuggestionImpl(\\n      rawSuggestion.describe[0],\\n      rawSuggestion.type[0],\\n      rawSuggestion.comment[0],\\n      code,\\n      rawSuggestion.filename[0]\\n    );\\n  });\\n  return suggestions;\\n};\\n\\nconst generateGithubIssueUrl = (\\n  owner: string,\\n  repoName: string,\\n  title: string,\\n  body: string,\\n  codeblock?: string\\n) => {\\n  const encodedTitle = encodeURIComponent(title);\\n  const encodedBody = encodeURIComponent(body);\\n  const encodedCodeBlock = codeblock\\n    ? encodeURIComponent(`\\\\n${codeblock}\\\\n`)\\n    : \"\";\\n\\n  let url = `https://github.com/${owner}/${repoName}/issues/new?title=${encodedTitle}&body=${encodedBody}${encodedCodeBlock}`;\\n\\n  if (url.length > 2048) {\\n    url = `https://github.com/${owner}/${repoName}/issues/new?title=${encodedTitle}&body=${encodedBody}`;\\n  }\\n  return `[Create Issue](${url})`;\\n};\\n\\nexport const dedupSuggestions = (\\n  suggestions: PRSuggestion[]\\n): PRSuggestion[] => {\\n  const suggestionsMap = new Map<string, PRSuggestion>();\\n  suggestions.forEach((suggestion) => {\\n    suggestionsMap.set(suggestion.identity(), suggestion);\\n  });\\n  return Array.from(suggestionsMap.values());\\n};\\n\\nconst convertPRSuggestionToComment = (\\n  owner: string,\\n  repo: string,\\n  suggestions: PRSuggestion[]\\n): string[] => {\\n  const suggestionsMap = new Map<string, PRSuggestion[]>();\\n  suggestions.forEach((suggestion) => {\\n    if (!suggestionsMap.has(suggestion.filename)) {\\n      suggestionsMap.set(suggestion.filename, []);\\n    }\\n    suggestionsMap.get(suggestion.filename).push(suggestion);\\n  });\\n  const comments: string[] = [];\\n  for (let [filename, suggestions] of suggestionsMap) {\\n    const temp = [`## ${filename}\\\\n`];\\n    suggestions.forEach((suggestion: PRSuggestion) => {\\n      const issueLink = generateGithubIssueUrl(\\n        owner,\\n        repo,\\n        suggestion.describe,\\n        suggestion.comment,\\n        suggestion.code\\n      );\\n      temp.push(\\n        PR_SUGGESTION_TEMPLATE.replace(\"{COMMENT}\", suggestion.comment)\\n          .replace(\"{CODE}\", suggestion.code)\\n          .replace(\"{ISSUE_LINK}\", issueLink)\\n      );\\n    });\\n    comments.push(temp.join(\"\\\\n\"));\\n  }\\n  return comments;\\n};\\n\\nconst xmlResponseBuilder = async (\\n  owner: string,\\n  repoName: string,\\n  feedbacks: string[]\\n): Promise<BuilderResponse> => {\\n  console.log(\"IN XML RESPONSE BUILDER\");\\n  const parsedXMLSuggestions = await processXMLSuggestions(feedbacks);\\n  const comments = convertPRSuggestionToComment(\\n    owner,\\n    repoName,\\n    dedupSuggestions(parsedXMLSuggestions)\\n  );\\n  const commentBlob = comments.join(\"\\\\n\");\\n  return { comment: commentBlob, structuredComments: parsedXMLSuggestions };\\n};\\n\\nconst curriedXmlResponseBuilder = (owner: string, repoName: string) => {\\n  return (feedbacks: string[]) =>\\n    xmlResponseBuilder(owner, repoName, feedbacks);\\n};\\n\\nconst basicResponseBuilder = async (\\n  feedbacks: string[]\\n): Promise<BuilderResponse> => {\\n  console.log(\"IN BASIC RESPONSE BUILDER\");\\n  const commentBlob = feedbacks.join(\"\\\\n\");\\n  return { comment: commentBlob, structuredComments: [] };\\n};\\n\\nexport const reviewChanges = async (\\n  files: PRFile[],\\n  convoBuilder: (diff: string) => ChatCompletionMessageParam[],\\n  responseBuilder: (responses: string[]) => Promise<BuilderResponse>\\n) => {\\n  const patchBuilder = buildPatchPrompt;\\n  const filteredFiles = files.filter((file) => filterFile(file));\\n  filteredFiles.map((file) => {\\n    file.patchTokenLength = getTokenLength(patchBuilder(file));\\n  });\\n  // further subdivide if necessary, maybe group files by common extension?\\n  const patchesWithinModelLimit: PRFile[] = [];\\n  // these single file patches are larger than the full model context\\n  const patchesOutsideModelLimit: PRFile[] = [];\\n\\n  filteredFiles.forEach((file) => {\\n    const patchWithPromptWithinLimit = isConversationWithinLimit(\\n      constructPrompt([file], patchBuilder, convoBuilder)\\n    );\\n    if (patchWithPromptWithinLimit) {\\n      patchesWithinModelLimit.push(file);\\n    } else {\\n      patchesOutsideModelLimit.push(file);\\n    }\\n  });\\n\\n  console.log(`files within limits: ${patchesWithinModelLimit.length}`);\\n  const withinLimitsPatchGroups = processWithinLimitFiles(\\n    patchesWithinModelLimit,\\n    patchBuilder,\\n    convoBuilder\\n  );\\n  const exceedingLimitsPatchGroups = processOutsideLimitFiles(\\n    patchesOutsideModelLimit,\\n    patchBuilder,\\n    convoBuilder\\n  );\\n  console.log(`${withinLimitsPatchGroups.length} within limits groups.`);\\n  console.log(\\n    `${patchesOutsideModelLimit.length} files outside limit, skipping them.`\\n  );\\n\\n  const groups = [...withinLimitsPatchGroups, ...exceedingLimitsPatchGroups];\\n\\n  const feedbacks = await Promise.all(\\n    groups.map((patchGroup) => {\\n      return reviewFiles(patchGroup, patchBuilder, convoBuilder);\\n    })\\n  );\\n  try {\\n    return await responseBuilder(feedbacks);\\n  } catch (exc) {\\n    console.log(\"XML parsing error\");\\n    console.log(exc);\\n    throw exc;\\n  }\\n};\\n\\nconst indentCodeFix = (\\n  file: string,\\n  code: string,\\n  lineStart: number\\n): string => {\\n  const fileLines = file.split(\"\\\\n\");\\n  const firstLine = fileLines[lineStart - 1];\\n  const codeLines = code.split(\"\\\\n\");\\n  const indentation = firstLine.match(/^(\\\\s*)/)[0];\\n  const indentedCodeLines = codeLines.map((line) => indentation + line);\\n  return indentedCodeLines.join(\"\\\\n\");\\n};\\n\\nconst isCodeSuggestionNew = (\\n  contents: string,\\n  suggestion: CodeSuggestion\\n): boolean => {\\n  const fileLines = contents.split(\"\\\\n\");\\n  const targetLines = fileLines\\n    .slice(suggestion.line_start - 1, suggestion.line_end)\\n    .join(\"\\\\n\");\\n  if (targetLines.trim() == suggestion.correction.trim()) {\\n    // same as existing code.\\n    return false;\\n  }\\n  return true;\\n};\\n\\nexport const generateInlineComments = async (\\n  suggestion: PRSuggestion,\\n  file: PRFile\\n): Promise<CodeSuggestion> => {\\n  try {\\n    const messages = getInlineFixPrompt(file.current_contents, suggestion);\\n    const { function_call } = await generateChatCompletion({\\n      messages,\\n      functions: [INLINE_FIX_FUNCTION],\\n      function_call: { name: INLINE_FIX_FUNCTION.name },\\n    });\\n    if (!function_call) {\\n      throw new Error(\"No function call found\");\\n    }\\n    const args = JSON.parse(function_call.arguments);\\n    const initialCode = String.raw`${args[\"code\"]}`;\\n    const indentedCode = indentCodeFix(\\n      file.current_contents,\\n      initialCode,\\n      args[\"lineStart\"]\\n    );\\n    const codeFix = {\\n      file: suggestion.filename,\\n      line_start: args[\"lineStart\"],\\n      line_end: args[\"lineEnd\"],\\n      correction: indentedCode,\\n      comment: args[\"comment\"],\\n    };\\n    if (isCodeSuggestionNew(file.current_contents, codeFix)) {\\n      return codeFix;\\n    }\\n    return null;\\n  } catch (exc) {\\n    console.log(exc);\\n    return null;\\n  }\\n};\\n\\nconst preprocessFile = async (\\n  octokit: Octokit,\\n  payload: WebhookEventMap[\"pull_request\"],\\n  file: PRFile\\n) => {\\n  const { base, head } = payload.pull_request;\\n  const baseBranch: BranchDetails = {\\n    name: base.ref,\\n    sha: base.sha,\\n    url: payload.pull_request.url,\\n  };\\n  const currentBranch: BranchDetails = {\\n    name: head.ref,\\n    sha: head.sha,\\n    url: payload.pull_request.url,\\n  };\\n  // Handle scenario where file does not exist!!\\n  const [oldContents, currentContents] = await Promise.all([\\n    getGitFile(octokit, payload, baseBranch, file.filename),\\n    getGitFile(octokit, payload, currentBranch, file.filename),\\n  ]);\\n\\n  if (oldContents.content != null) {\\n    file.old_contents = String.raw`${oldContents.content}`;\\n  } else {\\n    file.old_contents = null;\\n  }\\n\\n  if (currentContents.content != null) {\\n    file.current_contents = String.raw`${currentContents.content}`;\\n  } else {\\n    file.current_contents = null;\\n  }\\n};\\n\\nconst reviewChangesRetry = async (files: PRFile[], builders: Builders[]) => {\\n  for (const { convoBuilder, responseBuilder } of builders) {\\n    try {\\n      console.log(`Trying with convoBuilder: ${convoBuilder.name}.`);\\n      return await reviewChanges(files, convoBuilder, responseBuilder);\\n    } catch (error) {\\n      console.log(\\n        `Error with convoBuilder: ${convoBuilder.name}, trying next one. Error: ${error}`\\n      );\\n    }\\n  }\\n  throw new Error(\"All convoBuilders failed.\");\\n};\\n\\nexport const processPullRequest = async (\\n  octokit: Octokit,\\n  payload: WebhookEventMap[\"pull_request\"],\\n  files: PRFile[],\\n  includeSuggestions = false\\n) => {\\n  console.dir({ files }, { depth: null });\\n  const filteredFiles = files.filter((file) => filterFile(file));\\n  console.dir({ filteredFiles }, { depth: null });\\n  if (filteredFiles.length == 0) {\\n    console.log(\"Nothing to comment on, all files were filtered out. The PR Agent does not support the following file types: pdf, png, jpg, jpeg, gif, mp4, mp3, md, json, env, toml, svg, package-lock.json, yarn.lock, .gitignore, package.json, tsconfig.json, poetry.lock, readme.md\");\\n    return {\\n      review: null,\\n      suggestions: [],\\n    };\\n  }\\n  await Promise.all(\\n    filteredFiles.map((file) => {\\n      return preprocessFile(octokit, payload, file);\\n    })\\n  );\\n  const owner = payload.repository.owner.login;\\n  const repoName = payload.repository.name;\\n  const curriedXMLResponseBuilder = curriedXmlResponseBuilder(owner, repoName);\\n  if (includeSuggestions) {\\n    const reviewComments = await reviewChangesRetry(filteredFiles, [\\n      {\\n        convoBuilder: getXMLReviewPrompt,\\n        responseBuilder: curriedXMLResponseBuilder,\\n      },\\n      {\\n        convoBuilder: getReviewPrompt,\\n        responseBuilder: basicResponseBuilder,\\n      },\\n    ]);\\n    let inlineComments: CodeSuggestion[] = [];\\n    if (reviewComments.structuredComments.length > 0) {\\n      console.log(\"STARTING INLINE COMMENT PROCESSING\");\\n      inlineComments = await Promise.all(\\n        reviewComments.structuredComments.map((suggestion) => {\\n          // find relevant file\\n          const file = files.find(\\n            (file) => file.filename === suggestion.filename\\n          );\\n          if (file == null) {\\n            return null;\\n          }\\n          return generateInlineComments(suggestion, file);\\n        })\\n      );\\n    }\\n    const filteredInlineComments = inlineComments.filter(\\n      (comment) => comment !== null\\n    );\\n    return {\\n      review: reviewComments,\\n      suggestions: filteredInlineComments,\\n    };\\n  } else {\\n    const [review] = await Promise.all([\\n      reviewChangesRetry(filteredFiles, [\\n        {\\n          convoBuilder: getXMLReviewPrompt,\\n          responseBuilder: curriedXMLResponseBuilder,\\n        },\\n        {\\n          convoBuilder: getReviewPrompt,\\n          responseBuilder: basicResponseBuilder,\\n        },\\n      ]),\\n    ]);\\n\\n    return {\\n      review,\\n      suggestions: [],\\n    };\\n  }\\n};\\n'},\n",
              " {'name': 'src/reviews.ts',\n",
              "  'content': 'import {\\n  BranchDetails,\\n  BuilderResponse,\\n  CodeSuggestion,\\n  Review,\\n  processGitFilepath,\\n} from \"./constants\";\\nimport { Octokit } from \"@octokit/rest\";\\nimport { WebhookEventMap } from \"@octokit/webhooks-definitions/schema\";\\n\\nconst postGeneralReviewComment = async (\\n  octokit: Octokit,\\n  payload: WebhookEventMap[\"pull_request\"],\\n  review: string\\n) => {\\n  try {\\n    await octokit.request(\\n      \"POST /repos/{owner}/{repo}/issues/{issue_number}/comments\",\\n      {\\n        owner: payload.repository.owner.login,\\n        repo: payload.repository.name,\\n        issue_number: payload.pull_request.number,\\n        body: review,\\n        headers: {\\n          \"x-github-api-version\": \"2022-11-28\",\\n        },\\n      }\\n    );\\n  } catch (exc) {\\n    console.log(exc);\\n  }\\n};\\n\\nconst postInlineComment = async (\\n  octokit: Octokit,\\n  payload: WebhookEventMap[\"pull_request\"],\\n  suggestion: CodeSuggestion\\n) => {\\n  try {\\n    const line = suggestion.line_end;\\n    let startLine = null;\\n    if (suggestion.line_end != suggestion.line_start) {\\n      startLine = suggestion.line_start;\\n    }\\n    const suggestionBody = `${suggestion.comment}\\\\n\\\\`\\\\`\\\\`suggestion\\\\n${suggestion.correction}`;\\n\\n    await octokit.request(\\n      \"POST /repos/{owner}/{repo}/pulls/{pull_number}/comments\",\\n      {\\n        owner: payload.repository.owner.login,\\n        repo: payload.repository.name,\\n        pull_number: payload.pull_request.number,\\n        body: suggestionBody,\\n        commit_id: payload.pull_request.head.sha,\\n        path: suggestion.file,\\n        line: line,\\n        ...(startLine ? { start_line: startLine } : {}),\\n        // position: suggestion.line_start,\\n        // subject_type: \"line\",\\n        start_side: \"RIGHT\",\\n        side: \"RIGHT\",\\n        headers: {\\n          \"X-GitHub-Api-Version\": \"2022-11-28\",\\n        },\\n      }\\n    );\\n  } catch (exc) {\\n    console.log(exc);\\n  }\\n};\\n\\nexport const applyReview = async ({\\n  octokit,\\n  payload,\\n  review,\\n}: {\\n  octokit: Octokit;\\n  payload: WebhookEventMap[\"pull_request\"];\\n  review: Review;\\n}) => {\\n  let commentPromise = null;\\n  const comment = review.review?.comment;\\n  if (comment != null) {\\n    commentPromise = postGeneralReviewComment(octokit, payload, comment);\\n  }\\n  const suggestionPromises = review.suggestions.map((suggestion) =>\\n    postInlineComment(octokit, payload, suggestion)\\n  );\\n  await Promise.all([\\n    ...(commentPromise ? [commentPromise] : []),\\n    ...suggestionPromises,\\n  ]);\\n};\\n\\nconst addLineNumbers = (contents: string) => {\\n  const rawContents = String.raw`${contents}`;\\n  const prepended = rawContents\\n    .split(\"\\\\n\")\\n    .map((line, idx) => `${idx + 1}: ${line}`)\\n    .join(\"\\\\n\");\\n  return prepended;\\n};\\n\\nexport const getGitFile = async (\\n  octokit: Octokit,\\n  payload: WebhookEventMap[\"issues\"] | WebhookEventMap[\"pull_request\"],\\n  branch: BranchDetails,\\n  filepath: string\\n) => {\\n  try {\\n    const response = await octokit.request(\\n      \"GET /repos/{owner}/{repo}/contents/{path}\",\\n      {\\n        owner: payload.repository.owner.login,\\n        repo: payload.repository.name,\\n        path: filepath,\\n        ref: branch.name, // specify the branch name here\\n        headers: {\\n          \"X-GitHub-Api-Version\": \"2022-11-28\",\\n        },\\n      }\\n    );\\n    //@ts-ignore\\n    const decodedContent = Buffer.from(\\n      response.data.content,\\n      \"base64\"\\n    ).toString(\"utf8\");\\n    //@ts-ignore\\n    return { content: decodedContent, sha: response.data.sha };\\n  } catch (exc) {\\n    if (exc.status === 404) {\\n      return { content: null, sha: null };\\n    }\\n    console.log(exc);\\n    throw exc;\\n  }\\n};\\n\\nexport const getFileContents = async (\\n  octokit: Octokit,\\n  payload: WebhookEventMap[\"issues\"],\\n  branch: BranchDetails,\\n  filepath: string\\n) => {\\n  const gitFile = await getGitFile(\\n    octokit,\\n    payload,\\n    branch,\\n    processGitFilepath(filepath)\\n  );\\n  const fileWithLines = `# ${filepath}\\\\n${addLineNumbers(gitFile.content)}`;\\n  return { result: fileWithLines, functionString: `Opening file: ${filepath}` };\\n};\\n\\nexport const commentIssue = async (\\n  octokit: Octokit,\\n  payload: WebhookEventMap[\"issues\"],\\n  comment: string\\n) => {\\n  await octokit.rest.issues.createComment({\\n    owner: payload.repository.owner.login,\\n    repo: payload.repository.name,\\n    issue_number: payload.issue.number,\\n    body: comment,\\n  });\\n};\\n\\nexport const createBranch = async (\\n  octokit: Octokit,\\n  payload: WebhookEventMap[\"issues\"]\\n) => {\\n  let branchDetails = null;\\n  try {\\n    const title = payload.issue.title.replace(/\\\\s/g, \"-\").substring(0, 15);\\n\\n    const hash = Math.random().toString(36).substring(2, 7);\\n    const subName = `${title}-${hash}`.substring(0, 20);\\n    const branchName = `Code-Bot/${subName}`;\\n    // Get the default branch for the repository\\n    const { data: repo } = await octokit.rest.repos.get({\\n      owner: payload.repository.owner.login,\\n      repo: payload.repository.name,\\n    });\\n\\n    // Get the commit SHA of the default branch\\n    const { data: ref } = await octokit.rest.git.getRef({\\n      owner: payload.repository.owner.login,\\n      repo: payload.repository.name,\\n      ref: `heads/${repo.default_branch}`,\\n    });\\n\\n    // Create a new branch from the commit SHA\\n    const { data: newBranch } = await octokit.rest.git.createRef({\\n      owner: payload.repository.owner.login,\\n      repo: payload.repository.name,\\n      ref: `refs/heads/${branchName}`,\\n      sha: ref.object.sha,\\n    });\\n\\n    console.log(newBranch);\\n\\n    branchDetails = {\\n      name: branchName,\\n      sha: newBranch.object.sha,\\n      url: newBranch.url,\\n    };\\n    let branchUrl = `https://github.com/${payload.repository.owner.login}/${payload.repository.name}/tree/${branchName}`;\\n    const branchComment = `Branch created: [${branchName}](${branchUrl})`;\\n    await commentIssue(octokit, payload, branchComment);\\n\\n    console.log(`Branch ${branchName} created`);\\n  } catch (exc) {\\n    console.log(exc);\\n  }\\n  return branchDetails;\\n};\\n'},\n",
              " {'name': 'src/data/PRSuggestionImpl.ts',\n",
              "  'content': 'import { PRSuggestion } from \"../constants\";\\n\\nexport class PRSuggestionImpl implements PRSuggestion {\\n  describe: string;\\n  type: string;\\n  comment: string;\\n  code: string;\\n  filename: string;\\n\\n  constructor(\\n    describe: string,\\n    type: string,\\n    comment: string,\\n    code: string,\\n    filename: string\\n  ) {\\n    this.describe = describe;\\n    this.type = type;\\n    this.comment = comment;\\n    this.code = code;\\n    this.filename = filename;\\n  }\\n\\n  toString(): string {\\n    const xmlElements = [\\n      `<suggestion>`,\\n      `  <describe>${this.describe}</describe>`,\\n      `  <type>${this.type}</type>`,\\n      `  <comment>${this.comment}</comment>`,\\n      `  <code>${this.code}</code>`,\\n      `  <filename>${this.filename}</filename>`,\\n      `</suggestion>`,\\n    ];\\n    return xmlElements.join(\"\\\\n\");\\n  }\\n\\n  identity(): string {\\n    return `${this.filename}:${this.comment}`;\\n  }\\n}\\n'},\n",
              " {'name': 'src/context/review.ts',\n",
              "  'content': 'import {\\n  AbstractParser,\\n  PRFile,\\n  PatchInfo,\\n  getParserForExtension,\\n} from \"../constants\";\\nimport * as diff from \"diff\";\\nimport { JavascriptParser } from \"./language/javascript-parser\";\\nimport { Node } from \"@babel/traverse\";\\n\\nconst expandHunk = (\\n  contents: string,\\n  hunk: diff.Hunk,\\n  linesAbove: number = 5,\\n  linesBelow: number = 5\\n) => {\\n  const fileLines = contents.split(\"\\\\n\");\\n  const curExpansion: string[] = [];\\n  const start = Math.max(0, hunk.oldStart - 1 - linesAbove);\\n  const end = Math.min(\\n    fileLines.length,\\n    hunk.oldStart - 1 + hunk.oldLines + linesBelow\\n  );\\n\\n  for (let i = start; i < hunk.oldStart - 1; i++) {\\n    curExpansion.push(fileLines[i]);\\n  }\\n\\n  curExpansion.push(\\n    `@@ -${hunk.oldStart},${hunk.oldLines} +${hunk.newStart},${hunk.newLines} @@`\\n  );\\n  hunk.lines.forEach((line) => {\\n    if (!curExpansion.includes(line)) {\\n      curExpansion.push(line);\\n    }\\n  });\\n\\n  for (let i = hunk.oldStart - 1 + hunk.oldLines; i < end; i++) {\\n    curExpansion.push(fileLines[i]);\\n  }\\n  return curExpansion.join(\"\\\\n\");\\n};\\n\\nconst expandFileLines = (\\n  file: PRFile,\\n  linesAbove: number = 5,\\n  linesBelow: number = 5\\n) => {\\n  const fileLines = file.old_contents.split(\"\\\\n\");\\n  const patches: PatchInfo[] = diff.parsePatch(file.patch);\\n  const expandedLines: string[][] = [];\\n  patches.forEach((patch) => {\\n    patch.hunks.forEach((hunk) => {\\n      const curExpansion: string[] = [];\\n      const start = Math.max(0, hunk.oldStart - 1 - linesAbove);\\n      const end = Math.min(\\n        fileLines.length,\\n        hunk.oldStart - 1 + hunk.oldLines + linesBelow\\n      );\\n\\n      for (let i = start; i < hunk.oldStart - 1; i++) {\\n        curExpansion.push(fileLines[i]);\\n      }\\n\\n      curExpansion.push(\\n        `@@ -${hunk.oldStart},${hunk.oldLines} +${hunk.newStart},${hunk.newLines} @@`\\n      );\\n      hunk.lines.forEach((line) => {\\n        if (!curExpansion.includes(line)) {\\n          curExpansion.push(line);\\n        }\\n      });\\n\\n      for (let i = hunk.oldStart - 1 + hunk.oldLines; i < end; i++) {\\n        curExpansion.push(fileLines[i]);\\n      }\\n      expandedLines.push(curExpansion);\\n    });\\n  });\\n\\n  return expandedLines;\\n};\\n\\nexport const expandedPatchStrategy = (file: PRFile) => {\\n  const expandedPatches = expandFileLines(file);\\n  const expansions = expandedPatches\\n    .map((patchLines) => patchLines.join(\"\\\\n\"))\\n    .join(\"\\\\n\\\\n\");\\n  return `## ${file.filename}\\\\n\\\\n${expansions}`;\\n};\\n\\nexport const rawPatchStrategy = (file: PRFile) => {\\n  return `## ${file.filename}\\\\n\\\\n${file.patch}`;\\n};\\n\\nconst trimHunk = (hunk: diff.Hunk): diff.Hunk => {\\n  const startIdx = hunk.lines.findIndex(\\n    (line) => line.startsWith(\"+\") || line.startsWith(\"-\")\\n  );\\n  const endIdx = hunk.lines\\n    .slice()\\n    .reverse()\\n    .findIndex((line) => line.startsWith(\"+\") || line.startsWith(\"-\"));\\n  const editLines = hunk.lines.slice(startIdx, hunk.lines.length - endIdx);\\n  return { ...hunk, lines: editLines, newStart: startIdx + hunk.newStart };\\n};\\n\\nconst buildingScopeString = (\\n  currentFile: string,\\n  scope: Node,\\n  hunk: diff.Hunk\\n) => {\\n  const res: string[] = [];\\n  const trimmedHunk = trimHunk(hunk);\\n  const functionStartLine = scope.loc.start.line;\\n  const functionEndLine = scope.loc.end.line;\\n  const updatedFileLines = currentFile.split(\"\\\\n\");\\n  // Extract the lines of the function\\n  const functionContext = updatedFileLines.slice(\\n    functionStartLine - 1,\\n    functionEndLine\\n  );\\n  // Calculate the index where the changes should be injected into the function\\n  const injectionIdx =\\n    hunk.newStart -\\n    functionStartLine +\\n    hunk.lines.findIndex(\\n      (line) => line.startsWith(\"+\") || line.startsWith(\"-\")\\n    );\\n  // Count the number of lines that should be dropped from the function\\n  const dropCount = trimmedHunk.lines.filter(\\n    (line) => !line.startsWith(\"-\")\\n  ).length;\\n\\n  const hunkHeader = `@@ -${hunk.oldStart},${hunk.oldLines} +${hunk.newStart},${hunk.newLines} @@`;\\n  // Inject the changes into the function, dropping the necessary lines\\n  functionContext.splice(injectionIdx, dropCount, ...trimmedHunk.lines);\\n\\n  res.push(functionContext.join(\"\\\\n\"));\\n  res.unshift(hunkHeader);\\n  return res;\\n};\\n\\n/*\\nline nums are 0 index, file is 1 index\\n*/\\nconst combineHunks = (\\n  file: string,\\n  overlappingHunks: diff.Hunk[]\\n): diff.Hunk => {\\n  if (!overlappingHunks || overlappingHunks.length === 0) {\\n    throw \"Overlapping hunks are empty, this should never happen.\";\\n  }\\n  const sortedHunks = overlappingHunks.sort((a, b) => a.newStart - b.newStart);\\n  const fileLines = file.split(\"\\\\n\");\\n  let lastHunkEnd = sortedHunks[0].newStart + sortedHunks[0].newLines;\\n\\n  const combinedHunk: diff.Hunk = {\\n    oldStart: sortedHunks[0].oldStart,\\n    oldLines: sortedHunks[0].oldLines,\\n    newStart: sortedHunks[0].newStart,\\n    newLines: sortedHunks[0].newLines,\\n    lines: [...sortedHunks[0].lines],\\n    linedelimiters: [...sortedHunks[0].linedelimiters],\\n  };\\n\\n  for (let i = 1; i < sortedHunks.length; i++) {\\n    const hunk = sortedHunks[i];\\n\\n    // If there\\'s a gap between the last hunk and this one, add the lines in between\\n    if (hunk.newStart > lastHunkEnd) {\\n      combinedHunk.lines.push(\\n        ...fileLines.slice(lastHunkEnd - 1, hunk.newStart - 1)\\n      );\\n      combinedHunk.newLines += hunk.newStart - lastHunkEnd;\\n    }\\n\\n    combinedHunk.oldLines += hunk.oldLines;\\n    combinedHunk.newLines += hunk.newLines;\\n    combinedHunk.lines.push(...hunk.lines);\\n    combinedHunk.linedelimiters.push(...hunk.linedelimiters);\\n\\n    lastHunkEnd = hunk.newStart + hunk.newLines;\\n  }\\n  return combinedHunk;\\n};\\n\\nconst diffContextPerHunk = (file: PRFile, parser: AbstractParser) => {\\n  const updatedFile = diff.applyPatch(file.old_contents, file.patch);\\n  const patches = diff.parsePatch(file.patch);\\n  if (!updatedFile || typeof updatedFile !== \"string\") {\\n    console.log(\"APPLYING PATCH ERROR - FALLINGBACK\");\\n    throw \"THIS SHOULD NOT HAPPEN!\";\\n  }\\n\\n  const hunks: diff.Hunk[] = [];\\n  const order: number[] = [];\\n  const scopeRangeHunkMap = new Map<string, diff.Hunk[]>();\\n  const scopeRangeNodeMap = new Map<string, Node>();\\n  const expandStrategy: diff.Hunk[] = [];\\n\\n  patches.forEach((p) => {\\n    p.hunks.forEach((hunk) => {\\n      hunks.push(hunk);\\n    });\\n  });\\n\\n  hunks.forEach((hunk, idx) => {\\n    try {\\n      const trimmedHunk = trimHunk(hunk);\\n      const insertions = hunk.lines.filter((line) =>\\n        line.startsWith(\"+\")\\n      ).length;\\n      const lineStart = trimmedHunk.newStart;\\n      const lineEnd = lineStart + insertions;\\n      const largestEnclosingFunction = parser.findEnclosingContext(\\n        updatedFile,\\n        lineStart,\\n        lineEnd\\n      ).enclosingContext;\\n\\n      if (largestEnclosingFunction) {\\n        const enclosingRangeKey = `${largestEnclosingFunction.loc.start.line} -> ${largestEnclosingFunction.loc.end.line}`;\\n        let existingHunks = scopeRangeHunkMap.get(enclosingRangeKey) || [];\\n        existingHunks.push(hunk);\\n        scopeRangeHunkMap.set(enclosingRangeKey, existingHunks);\\n        scopeRangeNodeMap.set(enclosingRangeKey, largestEnclosingFunction);\\n      } else {\\n        throw \"No enclosing function.\";\\n      }\\n      order.push(idx);\\n    } catch (exc) {\\n      console.log(file.filename);\\n      console.log(\"NORMAL STRATEGY\");\\n      console.log(exc);\\n      expandStrategy.push(hunk);\\n      order.push(idx);\\n    }\\n  });\\n\\n  const scopeStategy: [string, diff.Hunk][] = []; // holds map range key and combined hunk: [[key, hunk]]\\n  for (const [range, hunks] of scopeRangeHunkMap.entries()) {\\n    const combinedHunk = combineHunks(updatedFile, hunks);\\n    scopeStategy.push([range, combinedHunk]);\\n  }\\n\\n  const contexts: string[] = [];\\n  scopeStategy.forEach(([rangeKey, hunk]) => {\\n    const context = buildingScopeString(\\n      updatedFile,\\n      scopeRangeNodeMap.get(rangeKey),\\n      hunk\\n    ).join(\"\\\\n\");\\n    contexts.push(context);\\n  });\\n  expandStrategy.forEach((hunk) => {\\n    const context = expandHunk(file.old_contents, hunk);\\n    contexts.push(context);\\n  });\\n  return contexts;\\n};\\n\\nconst functionContextPatchStrategy = (\\n  file: PRFile,\\n  parser: AbstractParser\\n): string => {\\n  let res = null;\\n  try {\\n    const contextChunks = diffContextPerHunk(file, parser);\\n    res = `## ${file.filename}\\\\n\\\\n${contextChunks.join(\"\\\\n\\\\n\")}`;\\n  } catch (exc) {\\n    console.log(exc);\\n    res = expandedPatchStrategy(file);\\n  }\\n  return res;\\n};\\n\\nexport const smarterContextPatchStrategy = (file: PRFile) => {\\n  const parser: AbstractParser = getParserForExtension(file.filename);\\n  if (parser != null) {\\n    return functionContextPatchStrategy(file, parser);\\n  } else {\\n    return expandedPatchStrategy(file);\\n  }\\n};\\n'},\n",
              " {'name': 'src/context/language/javascript-parser.ts',\n",
              "  'content': 'import { AbstractParser, EnclosingContext } from \"../../constants\";\\nimport * as parser from \"@babel/parser\";\\nimport traverse, { NodePath, Node } from \"@babel/traverse\";\\n\\nconst processNode = (\\n  path: NodePath<Node>,\\n  lineStart: number,\\n  lineEnd: number,\\n  largestSize: number,\\n  largestEnclosingContext: Node | null\\n) => {\\n  const { start, end } = path.node.loc;\\n  if (start.line <= lineStart && lineEnd <= end.line) {\\n    const size = end.line - start.line;\\n    if (size > largestSize) {\\n      largestSize = size;\\n      largestEnclosingContext = path.node;\\n    }\\n  }\\n  return { largestSize, largestEnclosingContext };\\n};\\n\\nexport class JavascriptParser implements AbstractParser {\\n  findEnclosingContext(\\n    file: string,\\n    lineStart: number,\\n    lineEnd: number\\n  ): EnclosingContext {\\n    const ast = parser.parse(file, {\\n      sourceType: \"module\",\\n      plugins: [\"jsx\", \"typescript\"], // To allow JSX and TypeScript\\n    });\\n    let largestEnclosingContext: Node = null;\\n    let largestSize = 0;\\n    traverse(ast, {\\n      Function(path) {\\n        ({ largestSize, largestEnclosingContext } = processNode(\\n          path,\\n          lineStart,\\n          lineEnd,\\n          largestSize,\\n          largestEnclosingContext\\n        ));\\n      },\\n      TSInterfaceDeclaration(path) {\\n        ({ largestSize, largestEnclosingContext } = processNode(\\n          path,\\n          lineStart,\\n          lineEnd,\\n          largestSize,\\n          largestEnclosingContext\\n        ));\\n      },\\n    });\\n    return {\\n      enclosingContext: largestEnclosingContext,\\n    } as EnclosingContext;\\n  }\\n\\n  dryRun(file: string): { valid: boolean; error: string } {\\n    try {\\n      const ast = parser.parse(file, {\\n        sourceType: \"module\",\\n        plugins: [\"jsx\", \"typescript\"], // To allow JSX and TypeScript\\n      });\\n      return {\\n        valid: true,\\n        error: \"\",\\n      };\\n    } catch (exc) {\\n      return {\\n        valid: false,\\n        error: exc,\\n      };\\n    }\\n  }\\n}\\n'},\n",
              " {'name': 'src/context/language/python-parser.ts',\n",
              "  'content': 'import { AbstractParser, EnclosingContext } from \"../../constants\";\\nexport class PythonParser implements AbstractParser {\\n  findEnclosingContext(\\n    file: string,\\n    lineStart: number,\\n    lineEnd: number\\n  ): EnclosingContext {\\n    // TODO: Implement this method for Python\\n    return null;\\n  }\\n  dryRun(file: string): { valid: boolean; error: string } {\\n    // TODO: Implement this method for Python\\n    return { valid: false, error: \"Not implemented yet\" };\\n  }\\n}\\n'},\n",
              " {'name': 'src/prompts/inline-prompt.ts',\n",
              "  'content': 'import { ChatCompletionMessageParam } from \"groq-sdk/resources/chat/completions\";\\nimport { PRSuggestion } from \"../constants\";\\n\\nexport const INLINE_FIX_PROMPT = `In this task, you are provided with a code suggestion in XML format, along with the corresponding file content. Your task is to radiate from this suggestion and draft a precise code fix. Here\\'s how your input will look:\\n\\n\\\\`\\\\`\\\\`xml\\n  <suggestion>\\n    <describe>Your Description Here</describe>\\n    <type>Your Type Here</type>\\n    <comment>Your Suggestions Here</comment>\\n    <code>Original Code Here</code>\\n    <filename>File Name Here</filename>\\n  </suggestion>\\n\\\\`\\\\`\\\\`\\n\\n{file}\\n\\nThe \\'comment\\' field contains specific code modification instructions. Based on these instructions, you\\'re required to formulate a precise code fix. Bear in mind that the fix must include only the lines between the starting line (linestart) and ending line (lineend) where the changes are applied.\\n\\nThe adjusted code doesn\\'t necessarily need to be standalone valid code, but when incorporated into the corresponding file, it must result in valid, functional code, without errors. Ensure to include only the specific lines affected by the modifications. Avoid including placeholders such as \\'rest of code...\\'\\n\\nPlease interpret the given directions and apply the necessary changes to the provided suggestion and file content. Make the modifications unambiguous and appropriate for utilizing in an inline suggestion on GitHub.`;\\n\\nexport const INLINE_FIX_FUNCTION = {\\n  name: \"fix\",\\n  description: \"The code fix to address the suggestion and rectify the issue\",\\n  parameters: {\\n    type: \"object\",\\n    properties: {\\n      comment: {\\n        type: \"string\",\\n        description: \"Why this change improves the code\",\\n      },\\n      code: {\\n        type: \"string\",\\n        description: \"Modified Code Snippet\",\\n      },\\n      lineStart: {\\n        type: \"number\",\\n        description: \"Starting Line Number\",\\n      },\\n      lineEnd: {\\n        type: \"number\",\\n        description: \"Ending Line Number\",\\n      },\\n    },\\n  },\\n  required: [\"action\"],\\n};\\n\\nconst INLINE_USER_MESSAGE_TEMPLATE = `{SUGGESTION}\\n\\n{FILE}`;\\n\\nconst assignFullLineNumers = (contents: string): string => {\\n  const lines = contents.split(\"\\\\n\");\\n  let lineNumber = 1;\\n  const linesWithNumbers = lines.map((line) => {\\n    const numberedLine = `${lineNumber}: ${line}`;\\n    lineNumber++;\\n    return numberedLine;\\n  });\\n  return linesWithNumbers.join(\"\\\\n\");\\n};\\n\\nexport const getInlineFixPrompt = (\\n  fileContents: string,\\n  suggestion: PRSuggestion\\n): ChatCompletionMessageParam[] => {\\n  const userMessage = INLINE_USER_MESSAGE_TEMPLATE.replace(\\n    \"{SUGGESTION}\",\\n    suggestion.toString()\\n  ).replace(\"{FILE}\", assignFullLineNumers(fileContents));\\n  return [\\n    { role: \"system\", content: INLINE_FIX_PROMPT },\\n    { role: \"user\", content: userMessage },\\n  ];\\n};\\n'},\n",
              " {'name': 'src/llms/groq.ts',\n",
              "  'content': 'import { Groq } from \"groq-sdk\";\\nimport { env } from \"../env\";\\nimport { ChatCompletionCreateParamsBase } from \"groq-sdk/resources/chat/completions\";\\n\\nexport const groq = new Groq({\\n  apiKey: env.GROQ_API_KEY,\\n});\\n\\nexport type GroqChatModel = ChatCompletionCreateParamsBase[\"model\"];\\n\\nexport const GROQ_MODEL: GroqChatModel = \"mixtral-8x7b-32768\";\\n'},\n",
              " {'name': 'src/llms/chat.ts',\n",
              "  'content': 'import { ChatCompletionCreateParamsNonStreaming } from \"groq-sdk/resources/chat/completions\";\\nimport { groq, GROQ_MODEL } from \"./groq\";\\n\\nexport const generateChatCompletion = async (\\n  options: Omit<ChatCompletionCreateParamsNonStreaming, \"model\">\\n) => {\\n  const response = await groq.chat.completions.create({\\n    model: GROQ_MODEL,\\n    temperature: 0,\\n    ...options,\\n  });\\n  return response.choices[0].message;\\n};\\n'}]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embeddings"
      ],
      "metadata": {
        "id": "fTHEOUgp1Nmv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_huggingface_embeddings(text, model_name=\"sentence-transformers/all-mpnet-base-v2\"):\n",
        "    model = SentenceTransformer(model_name)\n",
        "    return model.encode(text)"
      ],
      "metadata": {
        "id": "pRz7UnvJoL-d"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I am a programmer\"\n",
        "\n",
        "embeddings = get_huggingface_embeddings(text)"
      ],
      "metadata": {
        "id": "ojCvJduqIEQW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493,
          "referenced_widgets": [
            "740d03b15a2f4790babd1f5302c4462f",
            "8859cace83e643b78782a7d266d9431f",
            "960e2fb8726746ec8bd009d893968761",
            "df1e3869ede74a728dc1b0836c48136b",
            "90feeb189fe247dcb6118ff58806fb68",
            "e1c0b53853674b50bc7fa9d5fbb38ea3",
            "7cd810f0c8d7411da2b1b54771294419",
            "93b4b1fb49ce41e4bbf8de13e2d59f8a",
            "804d167e02c0463283ed0da056282415",
            "4a6e241daba346e4aaaf88847be7fc22",
            "fb5dfe79e87141e1a858a4f7974a34f2",
            "8cdf80b7c5174318a48acb61784fbfd6",
            "3f8176ec1b534a618361d454160d3416",
            "d99b5f98b4da47179aa1f36a4e0dc6d6",
            "666d8308333a406ca3098804595aef0d",
            "9e4027c1687e48d9a146879340cf77d1",
            "60f0b04c19e34243b1a4aecdec2cca8f",
            "2aa40a8f068f452d811bb5d12f582a34",
            "a6ea32a305c44dd08438c663150cc11a",
            "869a0ca44295495e8fe4d1e9aa471b92",
            "883c7d88248346d19901888b027094b3",
            "0e4958341ce24c94b66e96a0781c8d1e",
            "5201090141364aeba096441540f33b5f",
            "6ce7c0629c984ddebf4f120445611441",
            "2009440f51c24149a9864a339b439a9a",
            "b69f9b080c6f400e9b61f3322980972c",
            "728464a0b895450b8597fcf6828a3872",
            "680b67597b384d248e14fe70aa3c0590",
            "5b9c9c605f064f45b33b3ad6c390ad01",
            "27998701e96b4fb6b58eba1521699fea",
            "7c69d0740aeb434088dbdfaddf3f2789",
            "04f23a82749d4b9081eb90d880999461",
            "5796f9785db54f48b12f0e8a7fa37f22",
            "d84e2b53c9264cc68bad646b65ca975e",
            "d02b263e5b294ecca9b54e7edadc40d7",
            "8583e584f2c042b09f97629ce0765c87",
            "582e344d4ecb4327aba2ebbe4a9accb1",
            "536a43125e054fe496bd750a5d4c32d3",
            "49265b1de3b74671979c222c6b3373da",
            "d6518fa91312439a81dc7ab5dae8d2d7",
            "e79a36e568914d9ebf2995243e743fc2",
            "60da72eb0ef24bb784d8fc92c556940f",
            "99231476ff8740f1899f166484048b08",
            "2baed9fd434b440197379da8e77f69e1",
            "c580f84e67bd4d3f97682afe6cbcdb08",
            "04f581031f224f9cbf8a78a671dd30bf",
            "b3b9d6ef89224aa9a785b7c028ea097e",
            "1f068e78b4374923834644ba29a6f1d1",
            "e77637acadd14b7e8211dddda53f0477",
            "77eede7460544253b1f31c8d9148e461",
            "34223b5ad016435b8a8cecc009cebcd1",
            "710b7ae46b45434e9ac22cce091abe9e",
            "d1a820c371c94c378f46eb20a14464c5",
            "36817b23123544fea23fea73f3fe6bee",
            "3bec7ac03e12422abfb3be963a6706e1",
            "9769a5bbc7e542efabb44d646968c99d",
            "c53302de49af4f2683046b7f9cc18ed4",
            "e593425190f34bb285a6f7d88090ba34",
            "0c422e863ba1402a9fd8326262756ada",
            "214136d2e53647f49e39877de3005a5b",
            "d4a5948147304fa6ba400b5285df29ce",
            "be47f67f1d924a73a4509e76f1e02b60",
            "8be26080bf204359af36157777687b49",
            "6ef7d77164284ad8877733e3504f7e5e",
            "476568b0657d4529983415d9f7f3c01c",
            "cc2b712f8fcd4faea2285eaddbdfdcfa",
            "ca972af323294581ab2a4d86b03ea453",
            "4d86e3f7b8604c4a890649fbcfb07933",
            "468d676385f14b8e9082aabada4a4550",
            "0c0164019ec54b3f9d59593502fadab1",
            "c191a380147748df9b9fccf662418ed1",
            "6c6b86a84dc041a38b8a9bbc84009bbb",
            "95aed7ca9db649aeb957a0d1c44e65d4",
            "9b90432b951d497391eab594c0c72fa1",
            "b29711797e1f48c695056664790f3283",
            "5f3118e32b1a4e148a1dbd28e0b6c2ea",
            "cacc76c6df9441f9a2448ae6d32e89c9",
            "98ea81ebb0174825bc7761c21a9ff18c",
            "743ed016c86644c98286f50059aa775f",
            "582b70a324c6417fabcc6471dde2a358",
            "3a17f4ba1b1c4bbd96edf8717c61f465",
            "5554d345503f476aa91b0c7805fab906",
            "735ab10dc60f44babdf48afedd8f20a3",
            "ccf16d6de7d044319593480ce5125529",
            "d279bc51f7e049aa962b3d081ae6adeb",
            "23583af8388f403781c8fe3d3b387a77",
            "5edff04c32424354ae6b90569e411f05",
            "638d9c875143491d82643a7271aa7332",
            "36b79347c6d046f09bb7f4d7f155af1f",
            "ace1ad2599e940d9a2dde2783e5f1714",
            "ffe765e8d331432a95c9f2638d446df9",
            "48fcc65f283f4bf4a0de7aec61cd74d9",
            "98681534c63d40578b38fb0aa2632484",
            "faad2852729849279a01d775a0a2e9e0",
            "dab6106d08e94ce78e348cf5224ffe41",
            "82e9285bac06468b94d038ee71b7f16c",
            "7f924e666f8a493ba5c6b91ab7269ef9",
            "5fa60c0ea4f046bd9ba0948b879a4fff",
            "8bcdf3e35eeb4989a3573a61bdd6112b",
            "5c373b2df2c542acb9b0fa73f36f71af",
            "f352e76f23cf499faf10525b72f95dad",
            "76ddfd5ac9cd43cbb80f89e0e8ff1e8a",
            "117de8a811514d08966c6552316a18a8",
            "b13117da84b0487c959ddfb2d7425698",
            "c5b6ec0915a148ccac128117119deaf6",
            "abff1f9e80674ce59b8c651cebac91e8",
            "f54b5edb8aff4e2ebdf3280c8f2b603e",
            "0b9e1305a84f433fa6af823c8f044c9a",
            "279e45c7f35542f1861acd8e3573c16b",
            "6e2e0f96f92c4a46a92623118bde0084",
            "7bfedd7aafaf4b0a9889a724caa397d7",
            "89b57e3cddb5441fa89aa39d56f3fc85",
            "78d35f20ec894990a42add1c08bba697",
            "e827e34b258b4926a4adf113ccf1ffbf",
            "259d2db53fe04d9eafdef1be306751e1",
            "97dc186b773e4d3f85caf31477862910",
            "43fc7c6449514883bbefdb66409e8e6c",
            "8cb4201f169e458fa5ff2de49ad7c89b",
            "a6c6e8ad6601410f8ae0aa9b05e9b255",
            "e8c75a6fd9e746ceb21862c9f2f119ff",
            "b40a41a464d54aadb63b04e7fc34843a"
          ]
        },
        "outputId": "97a7e338-1e69-4006-bd2a-984366f4ddca"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "740d03b15a2f4790babd1f5302c4462f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8cdf80b7c5174318a48acb61784fbfd6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5201090141364aeba096441540f33b5f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d84e2b53c9264cc68bad646b65ca975e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c580f84e67bd4d3f97682afe6cbcdb08"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9769a5bbc7e542efabb44d646968c99d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca972af323294581ab2a4d86b03ea453"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98ea81ebb0174825bc7761c21a9ff18c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36b79347c6d046f09bb7f4d7f155af1f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c373b2df2c542acb9b0fa73f36f71af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7bfedd7aafaf4b0a9889a724caa397d7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Oas_olkZSkU",
        "outputId": "57d219ef-fb0e-44ed-e521-580fa33694f2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.81737654e-02, -3.02657508e-03, -4.77465875e-02,  1.86379403e-02,\n",
              "        3.14537995e-02,  1.87255293e-02, -1.52534274e-02, -6.77293688e-02,\n",
              "       -1.26903653e-02,  1.28427576e-02,  5.80701306e-02,  4.00234833e-02,\n",
              "        3.27073298e-02,  7.12998435e-02,  5.56373373e-02,  1.68628506e-02,\n",
              "        6.97603747e-02, -5.02619930e-02,  6.13140827e-03, -1.46559235e-02,\n",
              "       -4.51957993e-03,  4.82934639e-02, -2.53051296e-02, -1.97862904e-03,\n",
              "       -4.36902530e-02, -2.41507161e-02,  1.29505759e-02, -3.78611824e-03,\n",
              "       -2.05718316e-02,  1.09819308e-01,  3.07672890e-03, -2.80443169e-02,\n",
              "       -1.55807249e-02, -1.24789868e-02,  1.75239131e-06, -2.93756695e-03,\n",
              "       -1.43048428e-02,  4.88386713e-02, -6.21114224e-02,  2.95061413e-02,\n",
              "       -1.40470508e-02,  2.20708270e-02,  1.13067888e-02,  4.70893271e-02,\n",
              "        7.58305984e-03, -8.30314530e-05,  6.67821169e-02, -1.21320095e-02,\n",
              "        4.39386303e-03,  2.47453637e-02,  1.02529004e-02, -6.54432410e-03,\n",
              "       -5.53147821e-03, -1.88787878e-02, -5.65547235e-02, -8.61437898e-03,\n",
              "        9.17806011e-03,  4.72954214e-02,  3.66610773e-02,  4.16185074e-02,\n",
              "       -2.49964073e-02, -6.78151846e-02,  6.27576793e-03,  2.28892658e-02,\n",
              "        5.63387126e-02,  4.84214425e-02,  4.10140194e-02, -7.02802166e-02,\n",
              "        2.37883274e-02,  1.47998030e-03,  1.69444215e-02, -2.93291695e-02,\n",
              "       -1.11225909e-02,  4.25577499e-02,  7.48567656e-03, -4.39104214e-02,\n",
              "       -2.76734494e-02,  4.78422605e-02, -2.08101282e-03, -3.47002447e-02,\n",
              "       -2.33029164e-02, -6.11970248e-03, -2.89495587e-02, -4.91501093e-02,\n",
              "       -2.88692601e-02,  2.06755679e-02, -5.95949916e-03, -7.59897800e-03,\n",
              "       -1.26038678e-02,  1.25793023e-02,  2.28636013e-03,  4.14904673e-04,\n",
              "        4.59124222e-02,  2.63599046e-02, -2.33863164e-02, -1.22356033e-02,\n",
              "        7.56905321e-03,  1.67931952e-02, -1.77070182e-02,  3.53323203e-03,\n",
              "       -4.28936668e-02, -6.92434749e-03, -1.01979217e-02,  1.43273529e-02,\n",
              "       -4.73025953e-03,  1.27361165e-02,  3.79431397e-02,  4.01016697e-02,\n",
              "       -3.45702805e-02,  2.56913733e-02, -2.62000803e-02, -1.15285348e-02,\n",
              "        1.04733901e-02, -2.22328061e-04,  5.68597168e-02,  5.21823652e-02,\n",
              "       -2.19242815e-02,  5.35193384e-02, -1.23537739e-03,  3.53214256e-02,\n",
              "       -1.67341158e-02, -2.27758493e-02,  1.72111448e-02,  6.45435527e-02,\n",
              "        6.58219121e-03, -4.08305414e-02, -3.10201719e-02,  2.23486195e-03,\n",
              "       -2.57478338e-02, -3.19049731e-02,  1.29830539e-02, -2.61127707e-02,\n",
              "       -1.10535929e-02, -3.96891646e-02, -4.76274639e-03,  2.39800811e-02,\n",
              "       -3.50866131e-02,  5.66669144e-02,  8.37167609e-04, -3.63666974e-02,\n",
              "        2.61066351e-02, -1.61578767e-02, -1.83447096e-02, -5.55725694e-02,\n",
              "       -9.33758635e-03,  1.87277384e-02, -1.94000099e-02,  1.79931670e-02,\n",
              "        2.42580362e-02,  1.58868264e-02, -4.28457148e-02,  4.69506718e-02,\n",
              "       -4.28000055e-02,  8.86193069e-04,  4.31625992e-02,  2.16580611e-02,\n",
              "        4.42673378e-02, -5.37621304e-02, -4.43626642e-02,  6.75782561e-02,\n",
              "       -4.26721293e-03, -5.40975593e-02,  7.05882534e-02,  1.95075683e-02,\n",
              "       -5.82847707e-02, -1.76913049e-02,  4.58377637e-02,  3.58919539e-02,\n",
              "       -7.60997273e-03, -5.24799898e-03,  5.15250638e-02, -2.74890270e-02,\n",
              "       -4.65321504e-02,  7.44159073e-02,  1.47800595e-02, -3.88491824e-02,\n",
              "        7.06428736e-02,  4.29205485e-02, -1.74887516e-02, -2.61149872e-02,\n",
              "       -3.05779167e-02, -1.17235564e-01,  8.63823853e-03,  6.41901195e-02,\n",
              "       -4.60085692e-03,  3.55602950e-02, -3.05580813e-02,  1.20736221e-02,\n",
              "       -1.23474998e-02, -2.77650692e-02, -6.63859863e-03, -2.58687101e-02,\n",
              "       -8.91572516e-03,  3.51217054e-02,  1.96691584e-02, -3.83135304e-02,\n",
              "        3.85989286e-02, -2.49597966e-03, -1.08006606e-02, -4.35230695e-02,\n",
              "       -2.68697497e-02, -4.37627360e-02, -4.02603075e-02,  6.88361749e-02,\n",
              "        9.86472610e-03, -9.01129097e-02,  2.05333903e-03, -2.20368076e-02,\n",
              "        4.24189717e-02, -2.84167379e-02,  5.78805357e-02, -5.54716680e-03,\n",
              "       -4.35152724e-02,  2.42435727e-02, -3.82706407e-03, -2.14942731e-02,\n",
              "       -1.22395949e-03,  2.74500512e-02,  2.23104041e-02,  3.29487287e-02,\n",
              "       -2.18573436e-02,  3.27293128e-02,  1.59087852e-02, -1.32144215e-02,\n",
              "       -7.62805808e-03, -5.78398891e-02, -3.64295882e-03,  7.60957925e-03,\n",
              "       -1.68873428e-03, -2.50096153e-03, -1.27403941e-02,  1.64351910e-02,\n",
              "        1.83963738e-02,  3.17538194e-02, -2.61214618e-02, -2.62164809e-02,\n",
              "        4.38268073e-02, -3.44015546e-02,  4.29137470e-03, -3.37397158e-02,\n",
              "       -3.75598259e-02,  1.88001189e-02, -1.56786814e-02,  4.88208234e-02,\n",
              "        6.33974895e-02, -2.97319051e-02,  3.43256257e-02,  3.55255641e-02,\n",
              "        4.25961474e-03, -2.92933155e-02, -2.89669093e-02,  3.46054547e-02,\n",
              "        5.35513274e-04,  8.82588103e-02, -4.19697864e-03,  9.53747053e-03,\n",
              "       -6.43947395e-03,  4.12340276e-03, -7.03925788e-02, -2.01493013e-03,\n",
              "        3.63083892e-02, -7.75657445e-02,  2.24708971e-02,  9.34197102e-03,\n",
              "        2.36142483e-02, -1.47393849e-02,  3.98179963e-02, -9.37732980e-02,\n",
              "       -6.38186634e-02,  1.89055055e-02, -2.23645493e-02,  1.08356057e-02,\n",
              "       -1.92357134e-02, -5.91046992e-04, -3.84381860e-02,  6.88673742e-03,\n",
              "       -7.17324577e-03, -8.10823515e-02, -2.26357542e-02,  3.27474512e-02,\n",
              "       -5.98204089e-03, -1.41919972e-02, -4.02819552e-02, -4.84507792e-02,\n",
              "       -4.44589294e-02, -5.58693381e-03,  5.88101288e-03, -5.55807799e-02,\n",
              "       -3.65543477e-02,  9.06211045e-03,  4.40725870e-03,  6.70855725e-03,\n",
              "       -8.21993686e-03, -2.54573934e-02, -3.41273323e-02, -4.62009991e-03,\n",
              "       -1.03184227e-02, -2.13340912e-02, -2.17126589e-02,  3.45262773e-02,\n",
              "        3.64461504e-02, -2.50899289e-02,  1.94047000e-02,  1.89810190e-02,\n",
              "        4.44756709e-02, -1.01769459e-03,  6.38390332e-02, -4.88875434e-02,\n",
              "        2.68839463e-03,  3.41419466e-02,  5.95646724e-02, -1.78532721e-03,\n",
              "        2.17235088e-02,  4.75256741e-02,  2.64142398e-02,  1.44469198e-02,\n",
              "       -1.58330835e-02, -2.75752461e-03,  2.58850213e-02,  2.66580954e-02,\n",
              "       -3.29117551e-02,  1.56424958e-02,  6.35205209e-02, -1.65102836e-02,\n",
              "        6.75749220e-03,  3.43154296e-02, -8.33553970e-02, -2.15553287e-02,\n",
              "       -9.91051551e-03, -5.64505830e-02,  6.60370104e-03, -1.37644587e-02,\n",
              "       -4.16489318e-02,  2.32808273e-02,  9.33221634e-03, -3.05641256e-03,\n",
              "       -1.71474367e-02, -2.11736839e-02, -2.73284297e-02, -1.27584180e-02,\n",
              "       -4.92252548e-05,  8.66624713e-03, -4.29727025e-02,  5.69052703e-04,\n",
              "       -3.90635394e-02, -1.14897061e-02,  6.89247921e-02,  2.06043236e-02,\n",
              "       -5.10902097e-03, -3.32521237e-02,  9.41237360e-02,  2.14949157e-02,\n",
              "        4.36881222e-02, -1.10364240e-02,  2.50744708e-02, -1.02216993e-02,\n",
              "       -1.44289322e-02,  1.71323027e-02, -5.07592000e-02, -2.84155342e-03,\n",
              "       -6.23462945e-02, -1.68697871e-02,  1.13718007e-02,  3.16557987e-03,\n",
              "       -4.25686203e-02, -4.94772382e-02,  8.40964764e-02,  7.30610976e-04,\n",
              "       -7.62321651e-02, -8.08312185e-03, -6.38484582e-02,  6.23139506e-03,\n",
              "       -6.65650517e-02,  3.45914885e-02,  1.93540156e-02,  1.05748326e-02,\n",
              "        6.06727647e-03,  2.92328168e-02, -4.24626246e-02,  1.70929357e-02,\n",
              "        6.69758767e-02, -7.82421082e-02, -2.56719664e-02, -1.25769693e-02,\n",
              "       -2.07151193e-02, -1.44397691e-02,  2.24479102e-02,  8.12805258e-04,\n",
              "       -2.30364036e-02, -1.00448718e-02,  1.68006960e-02, -8.27940367e-03,\n",
              "       -8.95911921e-03, -4.99348156e-02,  8.77979398e-03, -1.40894633e-02,\n",
              "        2.15155408e-02,  1.60865337e-02, -4.32758965e-03,  2.96334475e-02,\n",
              "       -1.81923937e-02, -8.92420579e-03,  3.93342413e-03,  4.39314023e-02,\n",
              "        5.07197343e-02, -2.79976744e-02,  6.93289787e-02,  2.40696482e-02,\n",
              "       -4.26815934e-02,  1.69534758e-02,  2.40891520e-02,  1.45840691e-02,\n",
              "        5.26947714e-02, -1.72672085e-02, -7.82489718e-04, -2.44506598e-02,\n",
              "        1.47008961e-02,  4.09015752e-02,  2.31351256e-02, -9.27794576e-02,\n",
              "       -3.15664411e-02,  6.75973669e-03,  3.68096866e-02, -2.13384591e-02,\n",
              "       -1.21394852e-02, -5.56081682e-02, -1.94428340e-02,  4.88481298e-03,\n",
              "       -1.92082918e-03, -5.84014095e-02, -4.72958311e-02, -6.46710582e-03,\n",
              "        1.45573169e-02,  2.44667269e-02,  9.50117502e-03, -6.58090264e-02,\n",
              "       -9.25837532e-02,  2.79778428e-03, -4.72670272e-02, -4.71501574e-02,\n",
              "        3.47478427e-02, -2.13035364e-02,  3.68678048e-02, -1.39256679e-02,\n",
              "       -4.07598875e-02,  1.06460497e-01,  2.15989016e-02, -8.01496804e-02,\n",
              "       -7.98491612e-02, -1.27654811e-02,  3.64464708e-02, -2.89539285e-02,\n",
              "       -3.08991428e-02,  2.32358314e-02, -8.00713245e-03, -7.50880763e-02,\n",
              "       -4.35848236e-02, -5.66319712e-02,  3.40571697e-03, -2.86409967e-02,\n",
              "        6.41760752e-02,  3.11382506e-02, -4.06176262e-02, -7.12169753e-03,\n",
              "        8.70679412e-03, -5.80938384e-02,  6.54488057e-02, -3.89220789e-02,\n",
              "        5.68002835e-02, -3.75550985e-02, -4.45007645e-02, -2.49207672e-03,\n",
              "       -6.55737743e-02, -6.73922300e-02, -6.16171584e-02,  5.37670963e-02,\n",
              "       -1.76740717e-02,  1.34923439e-02, -1.88954361e-02,  9.60909948e-03,\n",
              "        6.33508638e-02,  5.55375824e-03, -2.81222048e-03, -5.09193614e-02,\n",
              "       -5.03838761e-03,  2.44048275e-02, -4.86793835e-03, -2.60613579e-02,\n",
              "       -1.73134282e-02, -3.18363272e-02,  2.64154039e-02, -1.35053853e-02,\n",
              "        1.63955204e-02, -5.46275079e-02, -9.03728232e-03, -1.17571736e-02,\n",
              "       -6.01919775e-04,  1.54943727e-02, -4.17018905e-02,  2.56800987e-02,\n",
              "       -1.28812594e-02,  2.63562780e-02, -1.63648576e-02, -2.48654392e-02,\n",
              "        6.83061257e-02, -1.10762352e-02, -8.86232778e-03,  1.17652519e-02,\n",
              "       -4.64824215e-02,  4.35998775e-02, -9.88261495e-03, -1.45275006e-03,\n",
              "       -3.81557047e-02, -4.81920093e-02,  7.16136023e-02,  3.03445347e-02,\n",
              "       -1.76447001e-03, -6.43536029e-03, -2.03769971e-02, -2.82286815e-02,\n",
              "        6.07062802e-02, -1.47767337e-02,  6.94487616e-02,  3.52218226e-02,\n",
              "       -2.20680330e-02,  2.56673130e-03,  1.82896666e-02, -1.34139368e-02,\n",
              "       -3.29877064e-02,  6.86464980e-02, -8.80264770e-03, -9.77273285e-03,\n",
              "       -7.19158351e-02, -3.46992463e-02,  1.73757561e-02,  2.78787371e-02,\n",
              "       -1.14716906e-02,  2.41462104e-02, -2.38998011e-02,  3.39115486e-02,\n",
              "        2.88954340e-02, -2.25447770e-02, -3.02896965e-02,  3.92612033e-02,\n",
              "        5.23577817e-02,  1.79756749e-02,  2.19729282e-02,  3.48603949e-02,\n",
              "       -2.83227582e-03, -6.72665192e-03, -3.31720151e-02,  2.98512466e-02,\n",
              "        7.56078679e-03,  1.31715750e-02, -2.97637796e-03, -5.70811057e-33,\n",
              "       -3.80509794e-02, -3.16624343e-02, -9.48769413e-03,  3.78614813e-02,\n",
              "        3.46019380e-02, -1.84394326e-02,  2.54497137e-02,  3.30912583e-02,\n",
              "        2.27330811e-02, -4.36293893e-03, -6.79162238e-03,  4.87050861e-02,\n",
              "        3.07431426e-02, -2.48618703e-02,  2.57188585e-02,  2.78976914e-02,\n",
              "        3.20611559e-02,  8.69012699e-02,  1.54426275e-02, -1.78990401e-02,\n",
              "       -4.25924994e-02, -5.21406010e-02, -3.36066373e-02,  3.21245869e-03,\n",
              "        1.11497613e-02,  6.60055457e-03,  2.64069694e-03, -2.53874250e-02,\n",
              "        7.19865644e-03, -3.98480566e-03,  4.11321521e-02,  5.46340011e-02,\n",
              "       -1.07930657e-02,  8.11833739e-02, -3.12558957e-03,  5.73425628e-02,\n",
              "       -4.59358171e-02, -2.06820797e-02,  2.38380488e-02,  6.21537007e-02,\n",
              "       -1.33593604e-02, -2.26839576e-02,  8.64603817e-02, -3.95820849e-03,\n",
              "       -9.00164712e-03, -2.66625304e-02,  6.16095699e-02, -5.05187502e-03,\n",
              "        7.53135011e-02,  6.89164596e-03, -4.21271473e-02, -1.00599660e-03,\n",
              "       -6.65680468e-02,  3.00322175e-02, -7.27648987e-03, -7.17262621e-04,\n",
              "       -9.28907562e-03, -4.34596166e-02, -7.98471272e-03,  3.19854431e-02,\n",
              "        1.25607401e-02,  1.55433090e-02,  4.60264459e-02, -7.92506980e-05,\n",
              "       -2.70152502e-02,  3.65146762e-03,  3.65657583e-02,  5.04147075e-02,\n",
              "        3.12001575e-02,  4.24613617e-02,  8.31128273e-04,  3.28413397e-02,\n",
              "       -5.69479093e-02,  3.99193428e-02,  7.27800606e-03, -4.30167988e-02,\n",
              "       -2.44255620e-03, -4.08578366e-02,  4.03577322e-03, -6.58857003e-02,\n",
              "       -1.10568628e-02,  4.57109176e-02,  2.11421237e-03, -5.05883023e-02,\n",
              "        3.27953510e-02,  2.03283504e-02, -1.46882273e-02, -2.21633706e-02,\n",
              "       -1.44265546e-02, -3.65788233e-04,  3.82656492e-02, -1.46960672e-02,\n",
              "       -4.89108302e-02, -1.05908848e-02,  2.36379374e-02, -1.40959630e-02,\n",
              "       -7.25374278e-03, -6.78296434e-03, -4.75778393e-02,  1.97396148e-02,\n",
              "       -4.55502383e-02,  2.20282096e-02, -4.66148555e-02, -8.22540745e-03,\n",
              "        5.65045811e-02,  3.25221345e-02,  7.13564642e-03, -6.78856671e-03,\n",
              "       -3.57893296e-02, -4.17531393e-02, -2.23811176e-02,  1.55671332e-02,\n",
              "       -4.67589777e-03,  2.90885810e-02,  1.63342133e-02, -4.89148963e-03,\n",
              "        4.36896123e-02, -1.36233009e-02, -6.67339638e-02, -5.67200817e-02,\n",
              "       -2.42128968e-02, -1.49621116e-02, -6.70799017e-02, -3.80460429e-03,\n",
              "        8.46558530e-03, -3.17309722e-02,  1.21465558e-02,  3.32484432e-02,\n",
              "       -1.39469700e-02, -6.41508326e-02, -1.46747800e-02,  2.96846051e-02,\n",
              "        2.19403660e-07, -2.10174136e-02,  5.85861765e-02,  2.46249791e-03,\n",
              "        6.63666353e-02, -4.03294945e-03,  2.52895821e-02, -2.17929818e-02,\n",
              "        1.58693418e-02, -8.65200273e-05,  3.77423093e-02, -6.97717741e-02,\n",
              "        3.90547402e-02, -1.47047322e-02, -5.25773540e-02, -3.13702854e-03,\n",
              "       -1.44916233e-02,  4.88454383e-03,  3.74173373e-02,  6.53500855e-03,\n",
              "       -1.14912270e-02,  7.18390793e-02,  2.73808977e-03,  5.86540215e-02,\n",
              "        1.22258952e-02,  3.42471129e-03, -3.16531211e-02, -2.10776385e-02,\n",
              "       -7.29871332e-04,  7.71138370e-02,  7.94972852e-02, -7.31387958e-02,\n",
              "        2.38037799e-02,  2.94722375e-02,  7.88793638e-02, -1.79399326e-02,\n",
              "       -9.66326669e-02,  5.78400046e-02,  9.25918818e-02,  2.60844274e-04,\n",
              "        9.80608836e-02,  1.26944501e-02, -4.04330250e-03, -3.99733335e-02,\n",
              "       -4.17981762e-03,  8.02013278e-03,  2.34413873e-02,  3.59379873e-02,\n",
              "        5.20487987e-02, -5.25579089e-03, -6.59703091e-02, -3.95181924e-02,\n",
              "       -1.26121759e-05,  4.12586406e-02, -8.67936760e-03,  2.41092239e-02,\n",
              "       -5.67298941e-02, -7.11889043e-02,  2.41271202e-02,  9.12857335e-03,\n",
              "        4.15410958e-02, -3.44169587e-02, -5.25238663e-02, -1.96926179e-03,\n",
              "        2.09436361e-02,  5.44395335e-02,  4.93962131e-02, -7.67187634e-03,\n",
              "        1.55831682e-34,  2.51677241e-02,  4.98390896e-03, -4.37567495e-02,\n",
              "       -8.83557834e-03,  6.64051175e-02, -1.19425394e-02,  1.97270215e-02,\n",
              "       -1.57919135e-02,  9.68538038e-03,  9.80035439e-02, -5.09533919e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oe-7UwHGvCno"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up Pinecone\n",
        "**1. Create an account on [Pinecone.io](https://app.pinecone.io/)**\n",
        "\n",
        "**2. Create a new index called \"codebase-rag\" and set the dimensions to 768. Leave the rest of the settings as they are.**\n",
        "\n",
        "![Screenshot 2024-11-24 at 10 58 50 PM](https://github.com/user-attachments/assets/f5fda046-4087-432a-a8c2-86e061005238)\n",
        "\n",
        "\n",
        "\n",
        "**3. Create an API Key for Pinecone**\n",
        "\n",
        "![Screenshot 2024-11-24 at 10 44 37 PM](https://github.com/user-attachments/assets/e7feacc6-2bd1-472a-82e5-659f65624a88)\n",
        "\n",
        "\n",
        "**4. Store your Pinecone API Key within Google Colab's secrets section, and then enable access to it (see the blue checkmark)**\n",
        "\n",
        "![Screenshot 2024-11-24 at 10 45 25 PM](https://github.com/user-attachments/assets/eaf73083-0b5f-4d17-9e0c-eab84f91b0bc)\n",
        "\n"
      ],
      "metadata": {
        "id": "umKbNfk3aBOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the PINECONE_API_KEY as an environment variable\n",
        "pinecone_api_key = userdata.get(\"PINECONE_API_KEY\")\n",
        "os.environ['PINECONE_API_KEY'] = pinecone_api_key\n",
        "\n",
        "# Initialize Pinecone\n",
        "pc = Pinecone(api_key=userdata.get(\"PINECONE_API_KEY\"),)\n",
        "\n",
        "# Connect to your Pinecone index\n",
        "pinecone_index = pc.Index(\"codebase-rag\")"
      ],
      "metadata": {
        "id": "y05YK2IjaGgm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = PineconeVectorStore(index_name=\"codebase-rag\", embedding=HuggingFaceEmbeddings())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQN1SdEQbwDI",
        "outputId": "e8afe514-8325-4952-bee5-5129a24b3439"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-5982ffb8f713>:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  vectorstore = PineconeVectorStore(index_name=\"codebase-rag\", embedding=HuggingFaceEmbeddings())\n",
            "<ipython-input-14-5982ffb8f713>:1: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
            "  vectorstore = PineconeVectorStore(index_name=\"codebase-rag\", embedding=HuggingFaceEmbeddings())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents = []\n",
        "\n",
        "for file in file_content:\n",
        "    doc = Document(\n",
        "        page_content=f\"{file['name']}\\n{file['content']}\",\n",
        "        metadata={\"source\": file['name']}\n",
        "    )\n",
        "\n",
        "    documents.append(doc)\n",
        "\n",
        "\n",
        "vectorstore = PineconeVectorStore.from_documents(\n",
        "    documents=documents,\n",
        "    embedding=HuggingFaceEmbeddings(),\n",
        "    index_name=\"codebase-rag\",\n",
        "    namespace=\"https://github.com/CoderAgent/SecureAgent\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDAB_siIb93B",
        "outputId": "46f4dc30-ca9a-43b5-a431-c137ac61cd4b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-ed1448f89c1f>:14: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
            "  embedding=HuggingFaceEmbeddings(),\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TGuQiFQmd4HZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perform RAG\n",
        "\n",
        "1. Get your Groq API Key [here](https://console.groq.com/keys)\n",
        "\n",
        "2. Paste your Groq API Key into your Google Colab secrets, and make sure to enable permissions for it\n",
        "\n",
        "![Screenshot 2024-11-25 at 12 00 16 AM](https://github.com/user-attachments/assets/e5525d29-bca6-4dbd-892b-cc770a6b281d)\n"
      ],
      "metadata": {
        "id": "e75xrBVCrRL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(\n",
        "    base_url=\"https://api.groq.com/openai/v1\",\n",
        "    api_key=userdata.get(\"GROQ_API_KEY\")\n",
        ")"
      ],
      "metadata": {
        "id": "K9DJQMc_nrsZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How are python files parsed?\""
      ],
      "metadata": {
        "id": "73ahsGAUnY22"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_query_embedding = get_huggingface_embeddings(query)\n",
        "\n",
        "raw_query_embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lwg3ZpsHnhhk",
        "outputId": "a5966790-f578-4480-e2c9-d3500cda00cd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 5.29357232e-02, -6.24647178e-02, -2.87437718e-02,  1.83179416e-02,\n",
              "       -4.33840672e-04,  4.03239094e-02, -7.76652806e-03, -2.74394872e-03,\n",
              "        2.53445264e-02, -8.10819939e-02, -8.44583288e-03, -6.59269514e-03,\n",
              "        4.16187495e-02,  3.98627296e-02,  2.82911733e-02,  2.84344628e-02,\n",
              "        2.65303329e-02, -2.60126498e-02,  4.16299142e-02,  3.92820686e-02,\n",
              "       -5.15580364e-02,  5.83349541e-02,  5.88829117e-03,  3.46064568e-02,\n",
              "       -2.46872660e-03,  2.72809248e-02,  1.07212560e-02,  4.55760621e-02,\n",
              "       -1.69188846e-02, -4.85301390e-02, -3.02424375e-02, -3.29698175e-02,\n",
              "        2.46010050e-02,  3.23601812e-02,  1.16030503e-06,  9.71379410e-03,\n",
              "       -3.70800160e-02,  1.84200946e-02, -1.39834182e-02,  4.25723344e-02,\n",
              "        6.78140819e-02, -6.66246563e-02,  2.11651716e-02, -1.11712900e-03,\n",
              "       -1.80115458e-02, -7.90139660e-02,  5.93152717e-02, -5.23733571e-02,\n",
              "        5.63013554e-02,  4.31280173e-02,  7.77091645e-03, -2.30586994e-02,\n",
              "       -2.94572674e-02,  2.77148280e-02, -4.47695516e-02,  9.26124305e-03,\n",
              "        2.05623228e-02,  1.89164635e-02, -1.17686111e-03, -5.75425215e-02,\n",
              "        6.23189472e-02, -6.24255650e-02, -1.03146341e-02,  2.10920591e-02,\n",
              "       -2.46260199e-03,  1.55239447e-03, -2.58621313e-02, -8.25273320e-02,\n",
              "       -1.62820444e-02, -1.60428416e-02, -9.51341633e-03, -3.61014716e-02,\n",
              "       -3.72008123e-02, -3.06942966e-02, -3.55277257e-03, -4.09893915e-02,\n",
              "       -4.44806628e-02,  5.48975803e-02,  1.24197537e-02,  2.40757260e-02,\n",
              "        6.85857162e-02, -2.74425447e-02,  2.51467973e-02, -3.05046495e-02,\n",
              "       -9.07214805e-02,  8.37038383e-02, -1.79595165e-02, -4.08667848e-02,\n",
              "       -3.23812962e-02,  4.20789756e-02, -1.16966674e-02, -5.89074828e-02,\n",
              "        5.40730990e-02, -1.61598772e-02,  3.99520099e-02, -1.29148280e-02,\n",
              "       -9.99879651e-03, -1.50061967e-02,  2.09497125e-03,  8.62607360e-03,\n",
              "       -3.09340749e-02,  1.84233319e-02, -4.64415289e-02,  1.31826950e-02,\n",
              "        3.10080703e-02,  6.74632285e-03,  2.38200743e-02,  3.98994498e-02,\n",
              "        2.22703815e-02,  6.18386548e-03, -8.69596098e-03, -2.51342878e-02,\n",
              "       -3.50810960e-02, -2.34969296e-02,  1.84800290e-02,  1.21879419e-02,\n",
              "        3.25379819e-02,  1.41922627e-02,  5.00620622e-03,  3.89296338e-02,\n",
              "       -3.72823626e-02, -2.71471292e-02,  2.89377086e-02,  3.11496146e-02,\n",
              "       -2.57724281e-02,  3.29544023e-02,  2.84123346e-02, -4.72989911e-03,\n",
              "       -2.35042349e-02, -1.74627360e-02,  2.09163851e-03,  1.12597523e-02,\n",
              "        1.37390122e-02, -1.92198250e-02, -2.42441474e-03,  4.58117574e-02,\n",
              "        2.00344231e-02,  2.40761433e-02,  3.83133553e-02,  4.86851064e-03,\n",
              "        4.09107804e-02,  1.27003007e-02,  1.02278003e-02, -3.14175934e-02,\n",
              "       -1.90840550e-02,  6.56972528e-02,  2.11260486e-02, -5.34587502e-02,\n",
              "       -1.36227347e-02, -8.12978391e-03, -7.64817595e-02,  1.93469711e-02,\n",
              "       -9.81907919e-03, -3.36908922e-02, -3.25244553e-02, -4.96620908e-02,\n",
              "       -2.79479404e-03, -6.36658520e-02,  2.75942553e-02, -3.15714255e-02,\n",
              "       -1.51135447e-03, -8.72665346e-02,  8.31876602e-03, -6.17535189e-02,\n",
              "       -2.22608522e-02, -3.06138187e-03,  1.73493270e-02, -2.11428781e-03,\n",
              "        3.26970406e-02, -1.72854625e-02, -3.01894378e-02,  3.36198770e-02,\n",
              "       -6.67419378e-03, -1.01257898e-02, -9.62471142e-02,  8.46370980e-02,\n",
              "       -1.96114797e-02, -2.88200453e-02,  7.15460777e-02,  5.81254959e-02,\n",
              "        4.77788486e-02,  7.82423988e-02, -1.38306366e-02, -2.19270401e-02,\n",
              "        3.99027281e-02, -2.27788612e-02, -1.18104480e-02,  3.33289206e-02,\n",
              "        5.07154055e-02,  1.52400322e-03, -6.07940741e-02,  4.19562086e-02,\n",
              "        5.17812558e-02, -4.86721694e-02, -3.48876300e-03, -3.31365429e-02,\n",
              "       -2.18327232e-02,  8.91789701e-03,  2.30654832e-02, -2.47854199e-02,\n",
              "       -1.22968452e-02, -9.04856157e-03, -4.89094444e-02,  6.31100312e-02,\n",
              "        3.78329307e-02,  3.73008810e-02,  2.12741420e-02, -5.94597049e-02,\n",
              "       -5.44957407e-02, -1.80757958e-02, -2.94007417e-02,  2.36048326e-02,\n",
              "        1.18150152e-02, -1.68431157e-04, -2.93773636e-02, -3.20025273e-02,\n",
              "        1.70538649e-02,  1.84272043e-02, -3.88709269e-02, -4.22035418e-02,\n",
              "       -6.89314632e-03,  3.49993967e-02, -1.63522996e-02,  5.40451258e-02,\n",
              "       -6.86168345e-03,  8.39837157e-05, -2.28055064e-02,  1.84533168e-02,\n",
              "       -5.23327589e-02,  5.85398152e-02, -6.05440140e-02,  4.67985570e-02,\n",
              "        2.97169536e-02,  3.79333459e-02,  1.08826034e-01, -1.34921046e-02,\n",
              "       -3.65445688e-02,  5.36772460e-02,  5.20055704e-02,  1.73453912e-02,\n",
              "       -2.86381096e-02,  2.51034051e-02,  7.99697563e-02,  8.45411420e-03,\n",
              "       -8.40059854e-03,  1.62152145e-02,  3.37266438e-02,  1.04514658e-02,\n",
              "        2.85697170e-02,  1.27325226e-02,  5.88391013e-02,  4.45223339e-02,\n",
              "       -5.37755005e-02,  3.13246250e-02, -1.95734426e-02,  5.36993407e-02,\n",
              "        1.35699175e-02,  5.48132136e-02, -2.60083731e-02, -8.54836255e-02,\n",
              "        5.50538935e-02,  4.39006835e-03, -3.81788313e-02, -6.26975438e-03,\n",
              "       -2.66886223e-02,  3.93094644e-02, -3.83768678e-02, -2.26170477e-03,\n",
              "        1.01410700e-02, -1.67041607e-02,  1.52516896e-02,  3.10032777e-02,\n",
              "       -5.70694022e-02,  1.19964825e-02,  2.10933457e-03,  1.90199930e-02,\n",
              "       -5.28421663e-02, -3.40813473e-02, -5.73657919e-04,  1.67012084e-02,\n",
              "        3.37425731e-02, -1.69162545e-02, -4.27704938e-02, -4.10331115e-02,\n",
              "       -3.51206250e-02,  5.66735975e-02,  1.48050943e-02, -5.41750975e-02,\n",
              "       -3.35608721e-02,  3.00901551e-02, -6.50472799e-03, -3.19957994e-02,\n",
              "        1.81440525e-02, -5.37339337e-02,  4.36227443e-03, -5.37622087e-02,\n",
              "        1.50756063e-02,  2.33239513e-02, -1.38578322e-02, -3.34760034e-03,\n",
              "        5.32320254e-02, -2.44215168e-02, -1.18555985e-02, -1.05982032e-02,\n",
              "        1.77718867e-02, -1.37670292e-02,  1.44015998e-02, -6.25981688e-02,\n",
              "       -4.68251556e-02,  6.42345995e-02,  5.49896061e-03,  3.26832570e-02,\n",
              "       -1.80160943e-02,  2.26008743e-02, -3.93174402e-02, -2.66569089e-02,\n",
              "       -1.59493722e-02, -1.35790920e-02,  4.52421755e-02,  1.70296375e-02,\n",
              "        1.14436615e-02, -1.96961984e-02,  7.43182823e-02, -4.17754464e-02,\n",
              "       -5.52875036e-03, -2.08973959e-02, -2.74067391e-02, -2.89906301e-02,\n",
              "        4.83474433e-02,  5.47394454e-02, -4.23560254e-02,  1.28818853e-02,\n",
              "       -6.16977215e-02,  1.15630412e-02,  1.32414121e-02,  2.89795864e-02,\n",
              "        2.16499940e-02, -2.65879929e-02,  2.28246469e-02,  5.02937194e-03,\n",
              "       -4.52497602e-03,  2.87271291e-02,  2.32655872e-02,  1.61632728e-02,\n",
              "       -3.92808132e-02,  3.48354690e-02, -6.54509338e-03, -3.81122641e-02,\n",
              "        1.66636724e-02,  5.22398911e-02,  5.42763621e-02,  1.46358449e-03,\n",
              "        4.05131541e-02,  2.79734097e-02, -1.03878193e-02, -1.23619968e-02,\n",
              "       -8.55705589e-02, -3.98034155e-02, -1.03295259e-02, -3.06918216e-03,\n",
              "        1.12385461e-02, -3.92905772e-02, -2.37615686e-02,  3.73438485e-02,\n",
              "       -6.09335490e-03,  8.03027302e-03,  3.26007269e-02,  1.72168072e-02,\n",
              "       -3.07254791e-02,  5.34810759e-02, -5.66900149e-02, -3.31042074e-02,\n",
              "        3.15087684e-03,  4.01630960e-02,  3.73294167e-02,  4.30786237e-02,\n",
              "        2.35213339e-02, -6.31922707e-02, -4.67105471e-02,  1.52614329e-03,\n",
              "        2.12465562e-02, -2.98658665e-02, -1.75441918e-03, -3.56526449e-02,\n",
              "        3.30406837e-02,  1.38599211e-02,  2.68207416e-02,  1.34316301e-02,\n",
              "        3.49891968e-02,  5.81625141e-02,  8.51069298e-03,  3.70358527e-02,\n",
              "       -3.87328975e-02,  2.32067350e-02, -5.87725751e-02, -1.05009917e-02,\n",
              "        5.82161825e-03,  5.60881197e-02, -1.43478820e-02,  3.23774256e-02,\n",
              "        3.04519664e-02, -1.76104959e-02,  4.66957837e-02, -3.46063450e-03,\n",
              "        3.63383293e-02,  1.66605405e-05,  5.00891022e-02,  2.17343122e-02,\n",
              "       -5.97168058e-02,  2.37415321e-02,  4.31473628e-02, -3.18265036e-02,\n",
              "        1.77777745e-02,  3.15772282e-04, -1.66752969e-03,  6.83109984e-02,\n",
              "       -2.12938918e-04,  4.88594323e-02, -4.54998836e-02, -2.93329880e-02,\n",
              "       -1.74761023e-02, -4.37862203e-02,  3.16109210e-02, -3.79561298e-02,\n",
              "       -4.94188108e-02,  3.52672637e-02, -1.74175203e-02, -3.25312167e-02,\n",
              "        2.89960671e-02,  4.52595726e-02,  7.38306269e-02, -8.94753039e-02,\n",
              "       -7.83321336e-02, -2.74328399e-03, -1.87086891e-02, -2.89897919e-02,\n",
              "        4.76684794e-02, -9.56911035e-03, -4.72693071e-02, -4.63580564e-02,\n",
              "        1.19095892e-02,  2.20620520e-02, -9.29961056e-02, -3.78828533e-02,\n",
              "       -4.13094535e-02, -9.80007742e-03,  3.03513799e-02, -4.30159867e-02,\n",
              "        9.04986449e-03,  7.71178529e-02,  3.58079970e-02, -5.53936623e-02,\n",
              "       -1.05007030e-01,  1.63989495e-02,  2.27310620e-02, -1.85960066e-02,\n",
              "       -3.08086388e-02, -2.71823891e-02, -1.11027379e-02,  6.46360889e-02,\n",
              "       -4.28788066e-02,  1.08859725e-02, -2.96998862e-02,  2.61759851e-02,\n",
              "       -8.78900103e-03, -1.43633271e-02,  6.00802563e-02, -6.33777231e-02,\n",
              "        2.11548079e-02,  1.00529138e-02,  8.03632941e-03,  2.75852643e-02,\n",
              "       -1.75669491e-02,  3.40637118e-02, -3.72855663e-02,  2.70865439e-03,\n",
              "       -2.25255303e-02, -1.47845307e-02, -6.94794431e-02,  2.88431905e-02,\n",
              "        1.13193139e-01,  9.42971930e-03,  5.81743270e-02, -5.44002987e-02,\n",
              "        2.34902035e-02,  1.37522770e-02,  1.88645368e-04,  2.38735182e-03,\n",
              "       -6.18971586e-02, -2.54469346e-02,  6.11802563e-04,  1.65084866e-03,\n",
              "        3.84528264e-02,  3.83724980e-02, -2.18702760e-02,  4.91976254e-02,\n",
              "       -1.41742257e-02,  8.67886543e-02,  4.70688902e-02, -1.33780744e-02,\n",
              "        2.43281052e-02,  2.13121204e-03, -7.80028244e-03, -1.94360726e-02,\n",
              "       -3.51535641e-02,  1.94779765e-02,  6.13575010e-03,  6.65924698e-02,\n",
              "       -5.17740548e-02, -1.71758644e-02,  1.49639137e-02,  3.49695086e-02,\n",
              "       -2.75514014e-02, -2.56296303e-02,  3.78721096e-02, -9.43364482e-03,\n",
              "       -1.71610042e-02, -1.16130132e-02,  5.20718023e-02, -3.90320569e-02,\n",
              "        1.38096353e-02, -1.07297488e-02,  6.45306334e-02, -3.71271046e-04,\n",
              "        1.66364405e-02, -5.59038334e-02, -1.95198786e-02, -4.32062373e-02,\n",
              "       -1.28881456e-02,  1.61057562e-02, -1.22971386e-02,  5.02005406e-02,\n",
              "        2.27776617e-02, -5.06645814e-02,  1.50559274e-02, -6.99809100e-03,\n",
              "       -1.78999752e-02,  2.83965450e-02, -1.61609277e-02,  7.43088797e-02,\n",
              "        5.80936810e-03, -3.79783735e-02, -3.01361773e-02,  4.63075861e-02,\n",
              "       -1.88925471e-02, -8.24493393e-02, -2.90479530e-02,  4.06599678e-02,\n",
              "       -2.34174076e-02,  1.74947940e-02, -2.53150538e-02,  5.00644967e-02,\n",
              "       -2.05937028e-02,  3.87852400e-04, -3.11556421e-02, -3.36270693e-33,\n",
              "       -3.64931338e-02, -9.84395854e-03, -1.27960062e-02,  3.68757360e-02,\n",
              "        7.21485913e-02, -2.93234568e-02, -1.90742612e-02,  1.27502130e-02,\n",
              "       -2.75648553e-02, -3.92989963e-02,  1.47465020e-02,  5.34276338e-03,\n",
              "        6.80222269e-03, -5.00147976e-02, -3.25024202e-02, -3.29955854e-03,\n",
              "       -4.41080108e-02,  4.25063707e-02, -2.22562682e-02, -4.24127504e-02,\n",
              "        4.97953296e-02,  1.96501762e-02,  7.10432082e-02, -1.33239513e-03,\n",
              "       -1.59612596e-02, -3.19576152e-02,  7.12694693e-03, -3.98079790e-02,\n",
              "       -1.02065224e-03,  5.80803081e-02,  4.18779766e-03, -5.21540269e-02,\n",
              "        2.75403280e-02,  9.57602169e-03, -3.45047154e-02,  1.75637621e-02,\n",
              "       -1.15363076e-02,  2.99454741e-02, -1.88699998e-02,  2.50332966e-03,\n",
              "       -9.36552323e-03,  3.24886967e-03,  9.50335637e-02, -2.04751957e-02,\n",
              "        9.50887986e-03,  3.28423679e-02, -3.02088875e-02, -1.78127643e-02,\n",
              "       -6.97341049e-03,  3.42991017e-02,  4.33424627e-03,  1.85266007e-02,\n",
              "       -1.02243433e-02,  2.98240222e-02,  5.75671420e-02, -1.29387267e-02,\n",
              "       -3.49400751e-02,  2.46349052e-02,  1.52298668e-02,  8.63341428e-03,\n",
              "        3.54272649e-02,  3.50684822e-02, -1.01720709e-02, -6.12878129e-02,\n",
              "       -1.37158949e-02, -1.14263073e-02,  4.86185066e-02,  1.04862265e-03,\n",
              "        1.53522743e-02,  3.61609012e-02, -2.83763465e-02,  1.60172360e-03,\n",
              "       -5.29458486e-02, -1.93459056e-02, -2.98061296e-02,  1.66548986e-03,\n",
              "       -8.09500832e-03,  4.39759018e-03,  4.46845368e-02,  5.34071634e-03,\n",
              "       -6.30121827e-02,  1.23348786e-02,  1.99630223e-02,  3.15872557e-03,\n",
              "       -4.30848002e-02,  1.51273776e-02, -2.88297422e-02, -2.31993031e-02,\n",
              "       -2.59096827e-02, -3.08083408e-02, -3.88282202e-02,  3.47705670e-02,\n",
              "        1.39503572e-02, -6.15109643e-03,  1.83904003e-02,  8.75682291e-03,\n",
              "       -1.10230789e-01,  1.99390873e-02, -1.60657596e-02, -5.22733433e-04,\n",
              "        1.18507147e-02, -1.24846967e-02, -2.22272500e-02, -1.16752125e-01,\n",
              "        5.94093502e-02,  2.55837198e-02, -5.00593670e-02,  2.07637530e-02,\n",
              "       -2.28052568e-02, -1.17855547e-02, -1.86712090e-02,  1.88255648e-03,\n",
              "       -3.07054985e-02,  6.18604720e-02,  1.36793191e-02,  2.31921971e-02,\n",
              "       -4.05400060e-03, -5.55821992e-02, -8.11269134e-03, -2.45206580e-02,\n",
              "       -1.45674394e-02,  3.35017256e-02,  1.73942912e-02, -2.79465523e-02,\n",
              "       -8.23854730e-02, -3.22012492e-02, -2.29693297e-02, -1.69347953e-02,\n",
              "        4.42384668e-02,  8.61013904e-02, -1.80193479e-03,  5.69039732e-02,\n",
              "        1.80935459e-07,  5.13121597e-02,  3.70615497e-02,  6.87917843e-02,\n",
              "        4.76195812e-02,  1.33519815e-02,  4.64612804e-02, -7.49314353e-02,\n",
              "        1.45223085e-02,  9.45933349e-03, -5.34114987e-02, -1.06149567e-02,\n",
              "       -3.35417390e-02, -6.11253316e-04,  1.55675402e-02,  6.57154946e-03,\n",
              "        5.05602211e-02, -2.86131725e-02, -2.96778604e-02, -3.09103560e-02,\n",
              "        1.43582774e-02,  1.43137369e-02,  4.98098806e-02,  3.52621358e-03,\n",
              "       -8.30848422e-03, -1.33262547e-02, -3.71968523e-02, -1.30646368e-02,\n",
              "       -5.25826435e-05,  3.71610261e-02,  5.53453807e-04, -4.29663137e-02,\n",
              "       -2.59780921e-02,  6.19598941e-05, -9.12478287e-03, -1.68120135e-02,\n",
              "       -3.33810300e-02, -4.00932971e-03,  8.06670859e-02,  8.46774224e-03,\n",
              "        6.66167662e-02, -4.38745087e-03, -2.76705027e-02, -1.04519110e-02,\n",
              "       -2.51315739e-02,  1.76669389e-03,  2.08077207e-02, -1.91202238e-02,\n",
              "       -4.90711443e-02, -1.00785969e-02,  4.09475975e-02, -3.99245694e-02,\n",
              "        2.54177023e-02,  2.23034937e-02,  4.49332073e-02, -7.68014323e-03,\n",
              "       -1.72685441e-02,  7.24878814e-03,  3.24925259e-02, -1.36583801e-02,\n",
              "       -8.47304314e-02, -1.55934365e-02, -2.89406851e-02, -4.69765663e-02,\n",
              "       -2.00475454e-02,  4.18929346e-02,  2.60193925e-03,  2.67458446e-02,\n",
              "        1.31175320e-34,  6.73702685e-04, -3.93718407e-02,  1.87982321e-02,\n",
              "       -6.08650222e-03, -3.60376686e-02,  2.95597631e-02,  4.36335197e-03,\n",
              "        2.76056901e-02, -3.13765667e-02, -6.78380718e-03,  6.06070319e-03],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feel free to change the \"top_k\" parameter to be a higher or lower number\n",
        "top_matches = pinecone_index.query(vector=raw_query_embedding.tolist(), top_k=5, include_metadata=True, namespace=\"https://github.com/CoderAgent/SecureAgent\")"
      ],
      "metadata": {
        "id": "5DQKsXMunhkD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_matches"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6JOvq6Tnhmf",
        "outputId": "ea09df7b-2822-4755-bbf9-f6a4be6a9d24"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'matches': [{'id': '4a34e444-0f65-4053-8eb5-fb3dab95fd28',\n",
              "              'metadata': {'source': 'src/context/language/python-parser.ts',\n",
              "                           'text': 'src/context/language/python-parser.ts\\n'\n",
              "                                   'import { AbstractParser, EnclosingContext '\n",
              "                                   '} from \"../../constants\";\\n'\n",
              "                                   'export class PythonParser implements '\n",
              "                                   'AbstractParser {\\n'\n",
              "                                   '  findEnclosingContext(\\n'\n",
              "                                   '    file: string,\\n'\n",
              "                                   '    lineStart: number,\\n'\n",
              "                                   '    lineEnd: number\\n'\n",
              "                                   '  ): EnclosingContext {\\n'\n",
              "                                   '    // TODO: Implement this method for '\n",
              "                                   'Python\\n'\n",
              "                                   '    return null;\\n'\n",
              "                                   '  }\\n'\n",
              "                                   '  dryRun(file: string): { valid: boolean; '\n",
              "                                   'error: string } {\\n'\n",
              "                                   '    // TODO: Implement this method for '\n",
              "                                   'Python\\n'\n",
              "                                   '    return { valid: false, error: \"Not '\n",
              "                                   'implemented yet\" };\\n'\n",
              "                                   '  }\\n'\n",
              "                                   '}\\n'},\n",
              "              'score': 0.473508358,\n",
              "              'values': []},\n",
              "             {'id': 'ca8f9195-bd1b-4ef5-bbe2-923c31f7a072',\n",
              "              'metadata': {'source': 'src/context/language/python-parser.ts',\n",
              "                           'text': 'src/context/language/python-parser.ts\\n'\n",
              "                                   'import { AbstractParser, EnclosingContext '\n",
              "                                   '} from \"../../constants\";\\n'\n",
              "                                   'export class PythonParser implements '\n",
              "                                   'AbstractParser {\\n'\n",
              "                                   '  findEnclosingContext(\\n'\n",
              "                                   '    file: string,\\n'\n",
              "                                   '    lineStart: number,\\n'\n",
              "                                   '    lineEnd: number\\n'\n",
              "                                   '  ): EnclosingContext {\\n'\n",
              "                                   '    // TODO: Implement this method for '\n",
              "                                   'Python\\n'\n",
              "                                   '    return null;\\n'\n",
              "                                   '  }\\n'\n",
              "                                   '  dryRun(file: string): { valid: boolean; '\n",
              "                                   'error: string } {\\n'\n",
              "                                   '    // TODO: Implement this method for '\n",
              "                                   'Python\\n'\n",
              "                                   '    return { valid: false, error: \"Not '\n",
              "                                   'implemented yet\" };\\n'\n",
              "                                   '  }\\n'\n",
              "                                   '}\\n'},\n",
              "              'score': 0.473508358,\n",
              "              'values': []},\n",
              "             {'id': '8169456e-e4ab-4bad-8a0b-bdd3bc07d3ef',\n",
              "              'metadata': {'source': 'src/context/language/python-parser.ts',\n",
              "                           'text': 'src/context/language/python-parser.ts\\n'\n",
              "                                   'import { AbstractParser, EnclosingContext '\n",
              "                                   '} from \"../../constants\";\\n'\n",
              "                                   'export class PythonParser implements '\n",
              "                                   'AbstractParser {\\n'\n",
              "                                   '  findEnclosingContext(\\n'\n",
              "                                   '    file: string,\\n'\n",
              "                                   '    lineStart: number,\\n'\n",
              "                                   '    lineEnd: number\\n'\n",
              "                                   '  ): EnclosingContext {\\n'\n",
              "                                   '    // TODO: Implement this method for '\n",
              "                                   'Python\\n'\n",
              "                                   '    return null;\\n'\n",
              "                                   '  }\\n'\n",
              "                                   '  dryRun(file: string): { valid: boolean; '\n",
              "                                   'error: string } {\\n'\n",
              "                                   '    // TODO: Implement this method for '\n",
              "                                   'Python\\n'\n",
              "                                   '    return { valid: false, error: \"Not '\n",
              "                                   'implemented yet\" };\\n'\n",
              "                                   '  }\\n'\n",
              "                                   '}\\n'},\n",
              "              'score': 0.473508358,\n",
              "              'values': []},\n",
              "             {'id': '36da4233-0d75-4532-9065-c4ab5f5d22c3',\n",
              "              'metadata': {'source': 'src/context/language/python-parser.ts',\n",
              "                           'text': 'src/context/language/python-parser.ts\\n'\n",
              "                                   'import { AbstractParser, EnclosingContext '\n",
              "                                   '} from \"../../constants\";\\n'\n",
              "                                   'export class PythonParser implements '\n",
              "                                   'AbstractParser {\\n'\n",
              "                                   '  findEnclosingContext(\\n'\n",
              "                                   '    file: string,\\n'\n",
              "                                   '    lineStart: number,\\n'\n",
              "                                   '    lineEnd: number\\n'\n",
              "                                   '  ): EnclosingContext {\\n'\n",
              "                                   '    // TODO: Implement this method for '\n",
              "                                   'Python\\n'\n",
              "                                   '    return null;\\n'\n",
              "                                   '  }\\n'\n",
              "                                   '  dryRun(file: string): { valid: boolean; '\n",
              "                                   'error: string } {\\n'\n",
              "                                   '    // TODO: Implement this method for '\n",
              "                                   'Python\\n'\n",
              "                                   '    return { valid: false, error: \"Not '\n",
              "                                   'implemented yet\" };\\n'\n",
              "                                   '  }\\n'\n",
              "                                   '}\\n'},\n",
              "              'score': 0.473508358,\n",
              "              'values': []},\n",
              "             {'id': '1ee5a9bc-c44b-4d99-b759-46eeb504f555',\n",
              "              'metadata': {'source': 'src/context/language/python-parser.ts',\n",
              "                           'text': 'src/context/language/python-parser.ts\\n'\n",
              "                                   'import { AbstractParser, EnclosingContext '\n",
              "                                   '} from \"../../constants\";\\n'\n",
              "                                   'export class PythonParser implements '\n",
              "                                   'AbstractParser {\\n'\n",
              "                                   '  findEnclosingContext(\\n'\n",
              "                                   '    file: string,\\n'\n",
              "                                   '    lineStart: number,\\n'\n",
              "                                   '    lineEnd: number\\n'\n",
              "                                   '  ): EnclosingContext {\\n'\n",
              "                                   '    // TODO: Implement this method for '\n",
              "                                   'Python\\n'\n",
              "                                   '    return null;\\n'\n",
              "                                   '  }\\n'\n",
              "                                   '  dryRun(file: string): { valid: boolean; '\n",
              "                                   'error: string } {\\n'\n",
              "                                   '    // TODO: Implement this method for '\n",
              "                                   'Python\\n'\n",
              "                                   '    return { valid: false, error: \"Not '\n",
              "                                   'implemented yet\" };\\n'\n",
              "                                   '  }\\n'\n",
              "                                   '}\\n'},\n",
              "              'score': 0.473508358,\n",
              "              'values': []}],\n",
              " 'namespace': 'https://github.com/CoderAgent/SecureAgent',\n",
              " 'usage': {'read_units': 6}}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "contexts = [item['metadata']['text'] for item in top_matches['matches']]"
      ],
      "metadata": {
        "id": "ahEZbqcAnhox"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contexts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOwLKCRNqKF0",
        "outputId": "5af0c1df-1bd4-41c7-826c-329ba9099bfb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['src/context/language/python-parser.ts\\nimport { AbstractParser, EnclosingContext } from \"../../constants\";\\nexport class PythonParser implements AbstractParser {\\n  findEnclosingContext(\\n    file: string,\\n    lineStart: number,\\n    lineEnd: number\\n  ): EnclosingContext {\\n    // TODO: Implement this method for Python\\n    return null;\\n  }\\n  dryRun(file: string): { valid: boolean; error: string } {\\n    // TODO: Implement this method for Python\\n    return { valid: false, error: \"Not implemented yet\" };\\n  }\\n}\\n',\n",
              " 'src/context/language/python-parser.ts\\nimport { AbstractParser, EnclosingContext } from \"../../constants\";\\nexport class PythonParser implements AbstractParser {\\n  findEnclosingContext(\\n    file: string,\\n    lineStart: number,\\n    lineEnd: number\\n  ): EnclosingContext {\\n    // TODO: Implement this method for Python\\n    return null;\\n  }\\n  dryRun(file: string): { valid: boolean; error: string } {\\n    // TODO: Implement this method for Python\\n    return { valid: false, error: \"Not implemented yet\" };\\n  }\\n}\\n',\n",
              " 'src/context/language/python-parser.ts\\nimport { AbstractParser, EnclosingContext } from \"../../constants\";\\nexport class PythonParser implements AbstractParser {\\n  findEnclosingContext(\\n    file: string,\\n    lineStart: number,\\n    lineEnd: number\\n  ): EnclosingContext {\\n    // TODO: Implement this method for Python\\n    return null;\\n  }\\n  dryRun(file: string): { valid: boolean; error: string } {\\n    // TODO: Implement this method for Python\\n    return { valid: false, error: \"Not implemented yet\" };\\n  }\\n}\\n',\n",
              " 'src/context/language/python-parser.ts\\nimport { AbstractParser, EnclosingContext } from \"../../constants\";\\nexport class PythonParser implements AbstractParser {\\n  findEnclosingContext(\\n    file: string,\\n    lineStart: number,\\n    lineEnd: number\\n  ): EnclosingContext {\\n    // TODO: Implement this method for Python\\n    return null;\\n  }\\n  dryRun(file: string): { valid: boolean; error: string } {\\n    // TODO: Implement this method for Python\\n    return { valid: false, error: \"Not implemented yet\" };\\n  }\\n}\\n',\n",
              " 'src/context/language/python-parser.ts\\nimport { AbstractParser, EnclosingContext } from \"../../constants\";\\nexport class PythonParser implements AbstractParser {\\n  findEnclosingContext(\\n    file: string,\\n    lineStart: number,\\n    lineEnd: number\\n  ): EnclosingContext {\\n    // TODO: Implement this method for Python\\n    return null;\\n  }\\n  dryRun(file: string): { valid: boolean; error: string } {\\n    // TODO: Implement this method for Python\\n    return { valid: false, error: \"Not implemented yet\" };\\n  }\\n}\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_query = \"<CONTEXT>\\n\" + \"\\n\\n-------\\n\\n\".join(contexts[ : 10]) + \"\\n-------\\n</CONTEXT>\\n\\n\\n\\nMY QUESTION:\\n\" + query"
      ],
      "metadata": {
        "id": "gHWR6szqqK7S"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(augmented_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AROG6MwJqNnC",
        "outputId": "90309579-642e-4394-e308-5cf2302b2341"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<CONTEXT>\n",
            "src/context/language/python-parser.ts\n",
            "import { AbstractParser, EnclosingContext } from \"../../constants\";\n",
            "export class PythonParser implements AbstractParser {\n",
            "  findEnclosingContext(\n",
            "    file: string,\n",
            "    lineStart: number,\n",
            "    lineEnd: number\n",
            "  ): EnclosingContext {\n",
            "    // TODO: Implement this method for Python\n",
            "    return null;\n",
            "  }\n",
            "  dryRun(file: string): { valid: boolean; error: string } {\n",
            "    // TODO: Implement this method for Python\n",
            "    return { valid: false, error: \"Not implemented yet\" };\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "-------\n",
            "\n",
            "src/context/language/python-parser.ts\n",
            "import { AbstractParser, EnclosingContext } from \"../../constants\";\n",
            "export class PythonParser implements AbstractParser {\n",
            "  findEnclosingContext(\n",
            "    file: string,\n",
            "    lineStart: number,\n",
            "    lineEnd: number\n",
            "  ): EnclosingContext {\n",
            "    // TODO: Implement this method for Python\n",
            "    return null;\n",
            "  }\n",
            "  dryRun(file: string): { valid: boolean; error: string } {\n",
            "    // TODO: Implement this method for Python\n",
            "    return { valid: false, error: \"Not implemented yet\" };\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "-------\n",
            "\n",
            "src/context/language/python-parser.ts\n",
            "import { AbstractParser, EnclosingContext } from \"../../constants\";\n",
            "export class PythonParser implements AbstractParser {\n",
            "  findEnclosingContext(\n",
            "    file: string,\n",
            "    lineStart: number,\n",
            "    lineEnd: number\n",
            "  ): EnclosingContext {\n",
            "    // TODO: Implement this method for Python\n",
            "    return null;\n",
            "  }\n",
            "  dryRun(file: string): { valid: boolean; error: string } {\n",
            "    // TODO: Implement this method for Python\n",
            "    return { valid: false, error: \"Not implemented yet\" };\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "-------\n",
            "\n",
            "src/context/language/python-parser.ts\n",
            "import { AbstractParser, EnclosingContext } from \"../../constants\";\n",
            "export class PythonParser implements AbstractParser {\n",
            "  findEnclosingContext(\n",
            "    file: string,\n",
            "    lineStart: number,\n",
            "    lineEnd: number\n",
            "  ): EnclosingContext {\n",
            "    // TODO: Implement this method for Python\n",
            "    return null;\n",
            "  }\n",
            "  dryRun(file: string): { valid: boolean; error: string } {\n",
            "    // TODO: Implement this method for Python\n",
            "    return { valid: false, error: \"Not implemented yet\" };\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "-------\n",
            "\n",
            "src/context/language/python-parser.ts\n",
            "import { AbstractParser, EnclosingContext } from \"../../constants\";\n",
            "export class PythonParser implements AbstractParser {\n",
            "  findEnclosingContext(\n",
            "    file: string,\n",
            "    lineStart: number,\n",
            "    lineEnd: number\n",
            "  ): EnclosingContext {\n",
            "    // TODO: Implement this method for Python\n",
            "    return null;\n",
            "  }\n",
            "  dryRun(file: string): { valid: boolean; error: string } {\n",
            "    // TODO: Implement this method for Python\n",
            "    return { valid: false, error: \"Not implemented yet\" };\n",
            "  }\n",
            "}\n",
            "\n",
            "-------\n",
            "</CONTEXT>\n",
            "\n",
            "\n",
            "\n",
            "MY QUESTION:\n",
            "How are python files parsed?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = f\"\"\"You are a Senior Software Engineer, specializing in TypeScript.\n",
        "\n",
        "Answer any questions I have about the codebase, based on the code provided. Always consider all of the context provided when forming a response.\n",
        "\"\"\"\n",
        "\n",
        "llm_response = client.chat.completions.create(\n",
        "    model=\"llama-3.1-70b-versatile\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": augmented_query}\n",
        "    ]\n",
        ")\n",
        "\n",
        "response = llm_response.choices[0].message.content"
      ],
      "metadata": {
        "id": "Q-l0gwYHqNpl"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "reEO69LpqNr9",
        "outputId": "73a415b3-edcf-481a-9836-73571679da46"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Based on the provided context, there is currently no implementation for parsing python files in the given `PythonParser` class. The methods `findEnclosingContext` and `dryRun` are both stubs with TODO comments indicating that they need to be implemented.\\n\\nIn order to parse python files, you will need to implement these methods or potentially add additional functionality to the `PythonParser` class. Here is a high-level overview of what each method might need to do:\\n\\n1. `findEnclosingContext`: This method could use a python parsing library or implement a parser from scratch to determine the enclosing context (e.g. class, function, module) of a given line range in a python file.\\n\\n2. `dryRun`: This method could also utilize a python parsing library to check the syntax of a given python file and return the result. If the file is valid, it could return `{ valid: true, error: \"\" }`, otherwise it could return `{ valid: false, error: \"Error message\" }`.\\n\\nHere\\'s an example using the `fs` and `python-syntax-error` packages:\\n\\n```typescript\\nimport fs from \\'fs\\';\\nimport { AbstractParser, EnclosingContext } from \"../../constants\";\\nimport { PythonSyntaxError } from \\'python-syntax-error\\';\\n\\nexport class PythonParser implements AbstractParser {\\n  findEnclosingContext(\\n    file: string,\\n    lineStart: number,\\n    lineEnd: number\\n  ): EnclosingContext {\\n    // Read the file content\\n    const fileContent = fs.readFileSync(file, \\'utf8\\');\\n    // Implement python parsing logic here or use a library\\n    // For simplicity, we\\'ll return null for now\\n    return null;\\n  }\\n\\n  dryRun(file: string): { valid: boolean; error: string } {\\n    try {\\n      // Read the file content\\n      const fileContent = fs.readFileSync(file, \\'utf8\\');\\n      // Use the python-syntax-error library to parse the file\\n      // This will throw an exception if the file is not valid\\n      new PythonSyntaxError(fileContent, file, { filename: file });\\n      return { valid: true, error: \"\" };\\n    } catch (error) {\\n      return { valid: false, error: error.message };\\n    }\\n  }\\n}\\n```\\nMake sure to install `python-syntax-error` package with npm or yarn first.\\n\\nThis is a very basic example. For a real-world application, you would likely want to handle more complex scenarios and error cases.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MqJtdpK_qNut"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Putting it all together"
      ],
      "metadata": {
        "id": "OBi56NBnjYMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_rag(query):\n",
        "    raw_query_embedding = get_huggingface_embeddings(query)\n",
        "\n",
        "    top_matches = pinecone_index.query(vector=raw_query_embedding.tolist(), top_k=5, include_metadata=True, namespace=\"https://github.com/CoderAgent/SecureAgent\")\n",
        "\n",
        "    # Get the list of retrieved texts\n",
        "    contexts = [item['metadata']['text'] for item in top_matches['matches']]\n",
        "\n",
        "    augmented_query = \"<CONTEXT>\\n\" + \"\\n\\n-------\\n\\n\".join(contexts[ : 10]) + \"\\n-------\\n</CONTEXT>\\n\\n\\n\\nMY QUESTION:\\n\" + query\n",
        "\n",
        "    # Modify the prompt below as need to improve the response quality\n",
        "    system_prompt = f\"\"\"You are a Senior Software Engineer, specializing in TypeScript.\n",
        "\n",
        "    Answer any questions I have about the codebase, based on the code provided. Always consider all of the context provided when forming a response.\n",
        "    \"\"\"\n",
        "\n",
        "    llm_response = client.chat.completions.create(\n",
        "        model=\"llama-3.1-8b-instant\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": augmented_query}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return llm_response.choices[0].message.content"
      ],
      "metadata": {
        "id": "SUeLm0_uqkDJ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = perform_rag(\"How is the javascript parser used?\")\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWTmDGI-qkFm",
        "outputId": "fdde3b39-adfd-46f8-bf47-b046260b4857"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The JavascriptParser class is used to parse a JavaScript file and find the enclosing context of a given range of lines. \n",
            "\n",
            "Here is a step-by-step explanation of how it can be used:\n",
            "\n",
            "1. Create an instance of the JavascriptParser class: `const parser = new JavascriptParser();`\n",
            "\n",
            "2. Call the `findEnclosingContext` method on the parser instance, passing in the following parameters:\n",
            "   - `file`: the path to the JavaScript file to be parsed.\n",
            "   - `lineStart`: the starting line number of the range of interest.\n",
            "   - `lineEnd`: the ending line number of the range of interest.\n",
            "\n",
            "   Here is an example: `parser.findEnclosingContext(file, 10, 20);`\n",
            "\n",
            "   The `findEnclosingContext` method will return an EnclosingContext object, which contains the enclosing context (a Node) that spans the largest range of lines within the given range of interest.\n",
            "\n",
            "3. Alternatively, you can use the `dryRun` method to check if the file is valid without actually finding the enclosing context. This method returns an object with a `valid` property indicating whether the file is valid, and an `error` property containing the error message if the file is invalid.\n",
            "\n",
            "Here's an example of how you might use these methods:\n",
            "\n",
            "```typescript\n",
            "const file = './path/to/javascript/file.js';\n",
            "const parser = new JavascriptParser();\n",
            "\n",
            "const enclosingContext = parser.findEnclosingContext(file, 10, 20);\n",
            "console.log(enclosingContext); // prints the enclosing context\n",
            "\n",
            "const dryRunResult = parser.dryRun(file);\n",
            "console.log(dryRunResult); // prints { valid: true, error: '' } or { valid: false, error: error message }\n",
            "```\n",
            "\n",
            "This is a high-level overview of how the JavascriptParser class can be used. The exact usage will depend on your specific requirements and the structure of your code.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0cV5FZSGUeiT",
        "outputId": "78e75ecb-e258-48cd-d4dc-4a4806c90b34"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.7.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.5-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.5.0 (from gradio)\n",
            "  Downloading gradio_client-1.5.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.11)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart==0.0.12 (from gradio)\n",
            "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.8.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<1.0,>=0.1.1 (from gradio)\n",
            "  Downloading safehttpx-0.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.32.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.0->gradio) (2024.10.0)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.5.0->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.7.1-py3-none-any.whl (57.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.5.0-py3-none-any.whl (320 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.1/320.1 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
            "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.5-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading ruff-0.8.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.1-py3-none-any.whl (8.4 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.32.1-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.5 ffmpy-0.4.0 gradio-5.7.1 gradio-client-1.5.0 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.12 ruff-0.8.1 safehttpx-0.1.1 semantic-version-2.10.0 starlette-0.41.3 tomlkit-0.12.0 uvicorn-0.32.1 websockets-12.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "markupsafe"
                ]
              },
              "id": "117b34c8fb5b49f6b4a1415df7f86328"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Web app for Codebase RAG with Gradio"
      ],
      "metadata": {
        "id": "yTL7iOZXVQgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ultra-Fast RAG Chatbot with Groq's LPU:\n",
        "#https://github.com/mickymultani/Groq-RAG/blob/main/GROQ_RAG_Langchain.ipynb\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "# Setup the Gradio interface\n",
        "iface = gr.Interface(fn=perform_rag,\n",
        "                     inputs=gr.Textbox(lines=2, placeholder=\"Type your question here...\"),\n",
        "                     outputs=gr.Textbox(),\n",
        "                     examples=[\"How is the javascript parser used?\"],\n",
        "                     title=\"Codebase RAG\",\n",
        "                     description=\"Ask any question about your code for this https://github.com/CoderAgent/SecureAgent github repo, and get an answer along with the response time.\")\n",
        "\n",
        "# Launch the interface\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "lzGx7_IIUmSy",
        "outputId": "44dcc996-6eca-4eff-87dc-7cd3a130f2e3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://c68a4efa7b6505b38a.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c68a4efa7b6505b38a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://github.com/nadaataiyab/nutritionfacts_chat/blob/main/youtube_tutorials/app_rag.py\n",
        "\n",
        "'''\n",
        "answer_bot = gr.ChatInterface(\n",
        "                            fn=perform_rag,\n",
        "                            chatbot=gr.Chatbot(height=300),\n",
        "                            textbox=gr.Textbox(placeholder=\"Ask me a question about your code\", container=False, scale=7),\n",
        "                            title=\"Codebase RAG Chatbot\",\n",
        "                            description=\"Ask any question about your code for this https://github.com/CoderAgent/SecureAgent github repo, and get an answer along with the response time.\",\n",
        "                            theme=\"soft\",\n",
        "                            examples=[\"How is the javascript parser used?\"],\n",
        "                            cache_examples=False,\n",
        "                            submit_btn=\"Ask\",\n",
        "                            stop_btn=\"Interrupt\"\n",
        "                        )\n",
        "\n",
        "answer_bot.launch()\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "Tl6OnRyJaeRc",
        "outputId": "417470e5-4632-4a6b-a008-e146e851bd83"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nanswer_bot = gr.ChatInterface(\\n                            fn=perform_rag,\\n                            chatbot=gr.Chatbot(height=300),\\n                            textbox=gr.Textbox(placeholder=\"Ask me a question about your code\", container=False, scale=7),\\n                            title=\"Codebase RAG Chatbot\",\\n                            description=\"Ask any question about your code for this https://github.com/CoderAgent/SecureAgent github repo, and get an answer along with the response time.\",\\n                            theme=\"soft\",\\n                            examples=[\"How is the javascript parser used?\"],\\n                            cache_examples=False,\\n                            submit_btn=\"Ask\",\\n                            stop_btn=\"Interrupt\"\\n                        )\\n\\nanswer_bot.launch()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Web app for Codebase RAG with Streamlit"
      ],
      "metadata": {
        "id": "D53_wtCWP2Sn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install groq\n",
        "!pip install langchain-groq # Install the integration package for Groq and LangChain\n",
        "!pip install langchain_groq\n",
        "!pip install longchain --upgrade"
      ],
      "metadata": {
        "id": "7FwqRviPqkHy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5d91c0c-d4da-4238-d424-5a7abc9a3035"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.13.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq) (0.27.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.23.4)\n",
            "Downloading groq-0.13.0-py3-none-any.whl (108 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/108.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.8/108.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.13.0\n",
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-0.2.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: groq<1,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain-groq) (0.13.0)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain-groq) (0.3.21)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (0.27.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-groq) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-groq) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-groq) (0.1.143)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-groq) (24.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-groq) (9.0.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-groq) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-groq) (3.10.11)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-groq) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-groq) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-groq) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-groq) (2.2.3)\n",
            "Downloading langchain_groq-0.2.1-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: langchain-groq\n",
            "Successfully installed langchain-groq-0.2.1\n",
            "Requirement already satisfied: langchain_groq in /usr/local/lib/python3.10/dist-packages (0.2.1)\n",
            "Requirement already satisfied: groq<1,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain_groq) (0.13.0)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain_groq) (0.3.21)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (0.27.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_groq) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_groq) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_groq) (0.1.143)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_groq) (24.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_groq) (9.0.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain_groq) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_groq) (3.10.11)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_groq) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_groq) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_groq) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_groq) (2.2.3)\n",
            "Collecting longchain\n",
            "  Downloading longchain-0.4.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Downloading longchain-0.4.2-py3-none-any.whl (33 kB)\n",
            "Installing collected packages: longchain\n",
            "Successfully installed longchain-0.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq"
      ],
      "metadata": {
        "id": "88LsAyLhG386"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install streamlit pyngrok python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jxy2eQZOP-d-",
        "outputId": "d81921d6-fbc1-4084-b3ca-c4d9eaf650d2"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.40.2-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (11.0.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.25.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
            "Downloading streamlit-1.40.2-py2.py3-none-any.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.1-py3-none-any.whl (22 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pyngrok, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 pyngrok-7.2.1 streamlit-1.40.2 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title dotenv\n",
        "%%writefile /content/.env\n",
        "GOOGLE_API_KEY=AIzaSyBQP_bjm6karXRTnmU2AbQAT5pv4Vn8LNg\n",
        "GROQ_API_KEY=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\n",
        "PINECONE_API_KEY=pcsk_pXcDj_TNuzBWjfkVjmN9izB2LcWoifhnH7kf4JarwoHcdxvnJNwFKCSnvxGAYMxauPHWk"
      ],
      "metadata": {
        "cellView": "form",
        "id": "XjMzT3bkRBT_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccad1eea-cc22-405d-8d54-620d0afcd0bb"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/.env\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os # Import the os module\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get(\"GOOGLE_API_KEY\")\n",
        "os.environ['GROQ_API_KEY'] = userdata.get(\"GROQ_API_KEY\")\n",
        "os.environ['PINECONE_API_KEY'] = userdata.get(\"PINECONE_API_KEY\")"
      ],
      "metadata": {
        "id": "ifEmT4dSZliD"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from threading import Thread\n",
        "from pyngrok import ngrok\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "prSPtAFURBWf"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok_token = userdata.get('NGROK_AUTH_TOKEN')\n",
        "\n",
        "ngrok.set_auth_token(ngrok_token)"
      ],
      "metadata": {
        "id": "sT0-w_oWRNBh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90b44947-663c-47ff-97e2-984b13cfaa90"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok_token = userdata.get('NGROK_AUTH_TOKEN')\n",
        "\n",
        "ngrok.set_auth_token(ngrok_token)"
      ],
      "metadata": {
        "id": "4n8YzRtqRNEE"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_streamlit():\n",
        "    import os # Import the os module\n",
        "    os.system(\"streamlit run /content/app.py --server.port 8501\")"
      ],
      "metadata": {
        "id": "U6z9fziVRBZG"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "st.write(\"## Classification Results\")\n",
        "\n",
        "\n",
        "output_dir = 'saliency_maps'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "    with col1:\n",
        "\n",
        "    with col2:\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "lRuGLKHLcdMv",
        "outputId": "d5ee7d86-483f-43c3-8a52-62bbb23173b2"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nst.write(\"## Classification Results\")\\n\\n\\noutput_dir = \\'saliency_maps\\'\\nos.makedirs(output_dir, exist_ok=True)\\n\\n\\n    col1, col2 = st.columns(2)\\n    with col1:\\n\\n    with col2:\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://github.com/CoderAgent/SecureAgent\n",
        "#https://github.com/SriLaxmi1993/Document-Genie-using-RAG-Framwork/tree/main\n",
        "#https://github.com/SriLaxmi1993/Document-Genie-using-RAG-Framwork"
      ],
      "metadata": {
        "id": "j6YhRKo0c8qT"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/app.py\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from google.colab import userdata\n",
        "from pinecone import Pinecone\n",
        "import os\n",
        "import tempfile\n",
        "from github import Github, Repository\n",
        "from git import Repo\n",
        "from openai import OpenAI\n",
        "from pathlib import Path\n",
        "from langchain.schema import Document\n",
        "from pinecone import Pinecone\n",
        "\n",
        "import streamlit as st\n",
        "import os\n",
        "from langchain.document_loaders import GitLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "#from langchain.vectorstores import Pinecone\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain import PromptTemplate\n",
        "from dotenv import load_dotenv\n",
        "#import pinecone\n",
        "load_dotenv()\n",
        "\n",
        "def clone_repository(repo_url):\n",
        "    \"\"\"Clones a GitHub repository to a temporary directory.\n",
        "\n",
        "    Args:\n",
        "        repo_url: The URL of the GitHub repository.\n",
        "\n",
        "    Returns:\n",
        "        The path to the cloned repository.\n",
        "    \"\"\"\n",
        "    repo_name = repo_url.split(\"/\")[-1]  # Extract repository name from URL\n",
        "    repo_path = f\"/content/{repo_name}\"\n",
        "    #repo_path=os.makedirs(repo_path, exist_ok=True)\n",
        "    if not os.path.exists(repo_path):\n",
        "\n",
        "      Repo.clone_from(repo_url, str(repo_path))\n",
        "\n",
        "      return str(repo_path)\n",
        "\n",
        "    else:\n",
        "\n",
        "      return str(repo_path)\n",
        "\n",
        "    '''\n",
        "    #if os.path.exists(repo_path):\n",
        "\n",
        "      #return str(repo_path)\n",
        "\n",
        "    #else:\n",
        "\n",
        "      #Repo.clone_from(repo_url, str(repo_path))\n",
        "\n",
        "      #return str(repo_path)\n",
        "  '''\n",
        "\n",
        "\n",
        "SUPPORTED_EXTENSIONS = {'.py', '.js', '.tsx', '.jsx', '.ipynb', '.java',\n",
        "                         '.cpp', '.ts', '.go', '.rs', '.vue', '.swift', '.c', '.h'}\n",
        "\n",
        "IGNORED_DIRS = {'node_modules', 'venv', 'env', 'dist', 'build', '.git',\n",
        "                '__pycache__', '.next', '.vscode', 'vendor'}\n",
        "\n",
        "\n",
        "def get_file_content(file_path, repo_path):\n",
        "    \"\"\"\n",
        "    Get content of a single file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the file\n",
        "\n",
        "    Returns:\n",
        "        Optional[Dict[str, str]]: Dictionary with file name and content\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            content = f.read()\n",
        "\n",
        "        # Get relative path from repo root\n",
        "        rel_path = os.path.relpath(file_path, repo_path)\n",
        "\n",
        "        return {\n",
        "            \"name\": rel_path,\n",
        "            \"content\": content\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file {file_path}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def get_main_files_content(repo_path: str):\n",
        "    \"\"\"\n",
        "    Get content of supported code files from the local repository.\n",
        "\n",
        "    Args:\n",
        "        repo_path: Path to the local repository\n",
        "\n",
        "    Returns:\n",
        "        List of dictionaries containing file names and contents\n",
        "    \"\"\"\n",
        "    files_content = []\n",
        "\n",
        "    try:\n",
        "        for root, _, files in os.walk(repo_path):\n",
        "            # Skip if current directory is in ignored directories\n",
        "            if any(ignored_dir in root for ignored_dir in IGNORED_DIRS):\n",
        "                continue\n",
        "\n",
        "            # Process each file in current directory\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                if os.path.splitext(file)[1] in SUPPORTED_EXTENSIONS:\n",
        "                    file_content = get_file_content(file_path, repo_path)\n",
        "                    if file_content:\n",
        "                        files_content.append(file_content)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading repository: {str(e)}\")\n",
        "\n",
        "    return files_content\n",
        "\n",
        "\n",
        "# With Index = codebase-rag, 768 vector dimension\n",
        "def get_huggingface_embeddings(text, model_name=\"sentence-transformers/all-mpnet-base-v2\"):\n",
        "    model = SentenceTransformer(model_name)\n",
        "    return model.encode(text)\n",
        "\n",
        "\n",
        "def perform_rag(query, repo_url):\n",
        "    client = OpenAI(\n",
        "        base_url=\"https://api.groq.com/openai/v1\",\n",
        "        api_key=os.getenv(\"GROQ_API_KEY\"))\n",
        "\n",
        "\n",
        "    # With Index = codebase-rag, 768 vector dimension\n",
        "    raw_query_embedding = get_huggingface_embeddings(query)\n",
        "    # With Index = codebase-rag, 768 vector dimension\n",
        "    top_matches = pinecone_index.query(vector=raw_query_embedding.tolist(), top_k=5, include_metadata=True, namespace=repo_url)\n",
        "    # Initialize HuggingFace embeddings, with Index = codebase-rag-index, 384 vector dimension\n",
        "    #embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    #raw_query_embedding = embeddings.embed_query(query)\n",
        "    # With Index = codebase-rag-index, 384 vector dimension\n",
        "    #top_matches = pinecone_index.query(vector=raw_query_embedding, top_k=5, include_metadata=True, namespace=repo_url)\n",
        "\n",
        "\n",
        "    # Get the list of retrieved texts\n",
        "    contexts = [item['metadata']['text'] for item in top_matches['matches']]\n",
        "\n",
        "    augmented_query = \"<CONTEXT>\\n\" + \"\\n\\n-------\\n\\n\".join(contexts[ : 10]) + \"\\n-------\\n</CONTEXT>\\n\\n\\n\\nMY QUESTION:\\n\" + query\n",
        "\n",
        "    # Modify the prompt below as need to improve the response quality\n",
        "    system_prompt = f\"\"\"You are a Senior Software Engineer, specializing in TypeScript and in other progrmming languages.\n",
        "\n",
        "    Answer any questions I have about the codebase, based on the code provided. Always consider all of the context provided when forming a response.\n",
        "    \"\"\"\n",
        "\n",
        "    llm_response = client.chat.completions.create(\n",
        "        model=\"llama-3.1-70b-versatile\", #model=\"llama-3.1-8b-instant\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": augmented_query}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return llm_response.choices[0].message.content\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"Codebase RAG Chatbot for GitHub repository URL\")\n",
        "st.text(\"Ask about the codebase. Examples questions: How is the javascript parser used?, How to use Document-Genie-using-RAG-Framwork and show me the code from streamlit_App.py?\")\n",
        "\n",
        "# GitHub repo input\n",
        "#repo_url = st.text_input(\"Enter GitHub repository URL:\")\n",
        "repo_url = st.selectbox(\"Select GitHub repository URL:\",\n",
        "    (\"https://github.com/CoderAgent/SecureAgent\", \"https://github.com/SriLaxmi1993/Document-Genie-using-RAG-Framwork\"),)\n",
        "\n",
        "if repo_url==\"https://github.com/CoderAgent/SecureAgent\":\n",
        "\n",
        "  path = clone_repository(repo_url)\n",
        "  file_content = get_main_files_content(path)\n",
        "\n",
        "  # Set the PINECONE_API_KEY as an environment variable\n",
        "  pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
        "  os.environ['PINECONE_API_KEY'] = pinecone_api_key\n",
        "\n",
        "  # Initialize Pinecone\n",
        "  pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
        "\n",
        "  # Connect to your Pinecone index\n",
        "  pinecone_index = pc.Index(\"codebase-rag\") #pinecone_index = pc.Index(\"codebase-rag-index\") # 384 vector dimension\n",
        "  # Initialize HuggingFace embeddings, # With Index = codebase-rag, 768 vector dimension\n",
        "  embeddings = HuggingFaceEmbeddings()\n",
        "  # Initialize HuggingFace embeddings, with Index = codebase-rag-index, 384 vector dimension\n",
        "  #embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "  vectorstore = PineconeVectorStore(\n",
        "  index_name=\"codebase-rag\", #index_name=\"codebase-rag-index\", # 384 vector dimension\n",
        "  embedding=embeddings #embedding=HuggingFaceEmbeddings()\n",
        "  )\n",
        "\n",
        "  documents = []\n",
        "\n",
        "  for file in file_content:\n",
        "    doc = Document(\n",
        "        page_content=f\"{file['name']}\\n{file['content']}\",\n",
        "        metadata={\"source\": file['name']}\n",
        "      )\n",
        "\n",
        "    documents.append(doc)\n",
        "\n",
        "\n",
        "\n",
        "  vectorstore = PineconeVectorStore.from_documents(\n",
        "    documents=documents,\n",
        "    embedding=embeddings, #embedding=HuggingFaceEmbeddings(),\n",
        "    index_name=\"codebase-rag\", #index_name=\"codebase-rag-index\", # 384 vector dimension\n",
        "    namespace=repo_url #namespace=f\"{repo_url}\"\n",
        "    )\n",
        "\n",
        "\n",
        "  # Initialize Groq chat model\n",
        "  llm = ChatGroq(\n",
        "      api_key=os.getenv(\"GROQ_API_KEY\"),\n",
        "      model=\"llama-3.1-70b-versatile\", #model=\"llama-3.1-8b-instant\",\n",
        "      temperature=0)\n",
        "\n",
        "  # Define prompt template\n",
        "  system_prompt = \"\"\"\n",
        "        You are a Senior Software Engineer, specializing in TypeScript and in other progrmming languages.\n",
        "\n",
        "        Answer any questions I have about the codebase, based on the code provided.\n",
        "        Always consider all of the context provided when forming a response.\n",
        "\n",
        "        Context: {context}\n",
        "        Question: {question}\n",
        "        Answer:\n",
        "        \"\"\"\n",
        "  chat_prompt = PromptTemplate(template=system_prompt, input_variables=[\"context\", \"question\"])\n",
        "\n",
        "\n",
        "\n",
        "  # Set up QA chain\n",
        "  qa_chain = ConversationalRetrievalChain.from_llm(\n",
        "        llm, retriever=vectorstore.as_retriever(), return_source_documents=True\n",
        "        ,combine_docs_chain_kwargs={\"prompt\": chat_prompt}\n",
        "    )\n",
        "\n",
        "\n",
        "  # Initialize chat history\n",
        "  if \"messages\" not in st.session_state:\n",
        "      st.session_state.messages = []\n",
        "\n",
        "  # Display chat messages\n",
        "  for message in st.session_state.messages:\n",
        "      with st.chat_message(message[\"role\"]):\n",
        "          st.markdown(message[\"content\"])\n",
        "\n",
        "  # Chat input\n",
        "  if prompt := st.chat_input(\"Ask about the codebase\"):\n",
        "      st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "      with st.chat_message(\"user\"):\n",
        "            st.markdown(prompt)\n",
        "\n",
        "      with st.chat_message(\"assistant\"):\n",
        "          prompt=perform_rag(prompt, repo_url)\n",
        "          response = qa_chain({\"question\": prompt, \"chat_history\": [(m[\"role\"], m[\"content\"]) for m in st.session_state.messages]})\n",
        "          st.markdown(response[\"answer\"])\n",
        "          st.session_state.messages.append({\"role\": \"assistant\", \"content\": response[\"answer\"]})\n",
        "\n",
        "          # Optionally display source documents\n",
        "          with st.expander(\"Source Documents\"):\n",
        "              for doc in response[\"source_documents\"]:\n",
        "                    st.write(doc.page_content)\n",
        "\n",
        "elif repo_url==\"https://github.com/SriLaxmi1993/Document-Genie-using-RAG-Framwork\":\n",
        "\n",
        "  path = clone_repository(repo_url)\n",
        "  file_content = get_main_files_content(path)\n",
        "\n",
        "  # Set the PINECONE_API_KEY as an environment variable\n",
        "  pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
        "  os.environ['PINECONE_API_KEY'] = pinecone_api_key\n",
        "\n",
        "  # Initialize Pinecone\n",
        "  pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
        "\n",
        "  # Connect to your Pinecone index\n",
        "  pinecone_index = pc.Index(\"codebase-rag\") #pinecone_index = pc.Index(\"codebase-rag-index\") # 384 vector dimension\n",
        "  # Initialize HuggingFace embeddings, # With Index = codebase-rag, 768 vector dimension\n",
        "  embeddings = HuggingFaceEmbeddings()\n",
        "  # Initialize HuggingFace embeddings, with Index = codebase-rag-index, 384 vector dimension\n",
        "  #embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "  vectorstore = PineconeVectorStore(\n",
        "  index_name=\"codebase-rag\", #index_name=\"codebase-rag-index\", # 384 vector dimension\n",
        "  embedding=embeddings #embedding=HuggingFaceEmbeddings()\n",
        "  )\n",
        "\n",
        "  documents = []\n",
        "\n",
        "  for file in file_content:\n",
        "    doc = Document(\n",
        "        page_content=f\"{file['name']}\\n{file['content']}\",\n",
        "        metadata={\"source\": file['name']}\n",
        "      )\n",
        "\n",
        "    documents.append(doc)\n",
        "\n",
        "\n",
        "\n",
        "  vectorstore = PineconeVectorStore.from_documents(\n",
        "    documents=documents,\n",
        "    embedding=embeddings, #embedding=HuggingFaceEmbeddings(),\n",
        "    index_name=\"codebase-rag\", #index_name=\"codebase-rag-index\", # 384 vector dimension\n",
        "    namespace=repo_url #namespace=f\"{repo_url}\"\n",
        "    )\n",
        "\n",
        "\n",
        "  # Initialize Groq chat model\n",
        "  llm = ChatGroq(\n",
        "      api_key=os.getenv(\"GROQ_API_KEY\"),\n",
        "      model=\"llama-3.1-70b-versatile\", #model=\"llama-3.1-8b-instant\",\n",
        "      temperature=0)\n",
        "\n",
        "  # Define prompt template\n",
        "  system_prompt = \"\"\"\n",
        "        You are a Senior Software Engineer, specializing in TypeScript and in other progrmming languages.\n",
        "\n",
        "        Answer any questions I have about the codebase, based on the code provided.\n",
        "        Always consider all of the context provided when forming a response.\n",
        "\n",
        "        Context: {context}\n",
        "        Question: {question}\n",
        "        Answer:\n",
        "        \"\"\"\n",
        "  chat_prompt = PromptTemplate(template=system_prompt, input_variables=[\"context\", \"question\"])\n",
        "\n",
        "\n",
        "\n",
        "  # Set up QA chain\n",
        "  qa_chain = ConversationalRetrievalChain.from_llm(\n",
        "        llm, retriever=vectorstore.as_retriever(), return_source_documents=True\n",
        "        ,combine_docs_chain_kwargs={\"prompt\": chat_prompt}\n",
        "    )\n",
        "\n",
        "\n",
        "  # Initialize chat history\n",
        "  if \"messages\" not in st.session_state:\n",
        "      st.session_state.messages = []\n",
        "\n",
        "  # Display chat messages\n",
        "  for message in st.session_state.messages:\n",
        "      with st.chat_message(message[\"role\"]):\n",
        "          st.markdown(message[\"content\"])\n",
        "\n",
        "  # Chat input\n",
        "  if prompt := st.chat_input(\"Ask about the codebase\"):\n",
        "      st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "      with st.chat_message(\"user\"):\n",
        "            st.markdown(prompt)\n",
        "\n",
        "      with st.chat_message(\"assistant\"):\n",
        "          prompt=perform_rag(prompt, repo_url)\n",
        "          response = qa_chain({\"question\": prompt, \"chat_history\": [(m[\"role\"], m[\"content\"]) for m in st.session_state.messages]})\n",
        "          st.markdown(response[\"answer\"])\n",
        "          st.session_state.messages.append({\"role\": \"assistant\", \"content\": response[\"answer\"]})\n",
        "\n",
        "          # Optionally display source documents\n",
        "          with st.expander(\"Source Documents\"):\n",
        "              for doc in response[\"source_documents\"]:\n",
        "                    st.write(doc.page_content)\n",
        "\n",
        "\n",
        "else:\n",
        "    st.write(\"Please enter a GitHub repository URL to start chatting.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ujus3UPfRBbu",
        "outputId": "8ab688b0-34c8-4a1d-f03b-9f46989ada8d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "thread = Thread(target=run_streamlit)\n",
        "thread.start()"
      ],
      "metadata": {
        "id": "6TwUbD8KRfEU"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Disconnect all existing tunnels\n",
        "for tunnel in ngrok.get_tunnels():\n",
        "    ngrok.disconnect(tunnel.public_url)\n",
        "\n",
        "# Now connect your new tunnel\n",
        "public_url = ngrok.connect(addr='8501', proto='http')\n",
        "\n",
        "print(\"Public URL:\", public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLnrTf-xV6Yv",
        "outputId": "138a17fb-a426-4cf1-99c2-284ef3a9d9e3"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://b037-34-73-138-196.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "tunnels = ngrok.get_tunnels()\n",
        "for tunnel in tunnels:\n",
        "    print(f\"Closing tunnel: {tunnel.public_url} -> {tunnel.config['addr']}\")\n",
        "    ngrok.disconnect(tunnel.public_url)\n",
        "'''"
      ],
      "metadata": {
        "id": "tpl2lAKxV6au",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "caad8c8c-ed3d-4b85-e577-9459111d3c2c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntunnels = ngrok.get_tunnels()\\nfor tunnel in tunnels:\\n    print(f\"Closing tunnel: {tunnel.public_url} -> {tunnel.config[\\'addr\\']}\")\\n    ngrok.disconnect(tunnel.public_url)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Web app for Codebase RAG with Streamlit with repo_url = st.text_input(\"Enter GitHub repository URL:\"), index_name=\"codebase-rag-index\", 384 vector dimension"
      ],
      "metadata": {
        "id": "7p1rfCP7FI_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "%%writefile /content/app.py\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from google.colab import userdata\n",
        "from pinecone import Pinecone\n",
        "import os\n",
        "import tempfile\n",
        "from github import Github, Repository\n",
        "from git import Repo\n",
        "from openai import OpenAI\n",
        "from pathlib import Path\n",
        "from langchain.schema import Document\n",
        "from pinecone import Pinecone\n",
        "\n",
        "import streamlit as st\n",
        "import os\n",
        "from langchain.document_loaders import GitLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "#from langchain.vectorstores import Pinecone\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain import PromptTemplate\n",
        "from dotenv import load_dotenv\n",
        "#import pinecone\n",
        "load_dotenv()\n",
        "\n",
        "def clone_repository(repo_url):\n",
        "    \"\"\"Clones a GitHub repository to a temporary directory.\n",
        "\n",
        "    Args:\n",
        "        repo_url: The URL of the GitHub repository.\n",
        "\n",
        "    Returns:\n",
        "        The path to the cloned repository.\n",
        "    \"\"\"\n",
        "    repo_name = repo_url.split(\"/\")[-1]  # Extract repository name from URL\n",
        "    repo_path = f\"/content/{repo_name}\"\n",
        "    #repo_path=os.makedirs(repo_path, exist_ok=True)\n",
        "    if not os.path.exists(repo_path):\n",
        "\n",
        "      Repo.clone_from(repo_url, str(repo_path))\n",
        "\n",
        "      return str(repo_path)\n",
        "\n",
        "    else:\n",
        "\n",
        "      return str(repo_path)\n",
        "\n",
        "    '''\n",
        "    #if os.path.exists(repo_path):\n",
        "\n",
        "      #return str(repo_path)\n",
        "\n",
        "    #else:\n",
        "\n",
        "      #Repo.clone_from(repo_url, str(repo_path))\n",
        "\n",
        "      #return str(repo_path)\n",
        "'''\n",
        "\n",
        "\n",
        "SUPPORTED_EXTENSIONS = {'.py', '.js', '.tsx', '.jsx', '.ipynb', '.java',\n",
        "                         '.cpp', '.ts', '.go', '.rs', '.vue', '.swift', '.c', '.h'}\n",
        "\n",
        "IGNORED_DIRS = {'node_modules', 'venv', 'env', 'dist', 'build', '.git',\n",
        "                '__pycache__', '.next', '.vscode', 'vendor'}\n",
        "\n",
        "\n",
        "def get_file_content(file_path, repo_path):\n",
        "    \"\"\"\n",
        "    Get content of a single file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the file\n",
        "\n",
        "    Returns:\n",
        "        Optional[Dict[str, str]]: Dictionary with file name and content\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            content = f.read()\n",
        "\n",
        "        # Get relative path from repo root\n",
        "        rel_path = os.path.relpath(file_path, repo_path)\n",
        "\n",
        "        return {\n",
        "            \"name\": rel_path,\n",
        "            \"content\": content\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file {file_path}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def get_main_files_content(repo_path: str):\n",
        "    \"\"\"\n",
        "    Get content of supported code files from the local repository.\n",
        "\n",
        "    Args:\n",
        "        repo_path: Path to the local repository\n",
        "\n",
        "    Returns:\n",
        "        List of dictionaries containing file names and contents\n",
        "    \"\"\"\n",
        "    files_content = []\n",
        "\n",
        "    try:\n",
        "        for root, _, files in os.walk(repo_path):\n",
        "            # Skip if current directory is in ignored directories\n",
        "            if any(ignored_dir in root for ignored_dir in IGNORED_DIRS):\n",
        "                continue\n",
        "\n",
        "            # Process each file in current directory\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                if os.path.splitext(file)[1] in SUPPORTED_EXTENSIONS:\n",
        "                    file_content = get_file_content(file_path, repo_path)\n",
        "                    if file_content:\n",
        "                        files_content.append(file_content)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading repository: {str(e)}\")\n",
        "\n",
        "    return files_content\n",
        "\n",
        "\n",
        "\n",
        "def perform_rag(query, repo_url):\n",
        "    client = OpenAI(\n",
        "        base_url=\"https://api.groq.com/openai/v1\",\n",
        "        api_key=os.getenv(\"GROQ_API_KEY\"))\n",
        "\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    raw_query_embedding = embeddings.embed_query(query)\n",
        "    #raw_query_embedding = get_huggingface_embeddings(query)\n",
        "\n",
        "    top_matches = pinecone_index.query(vector=raw_query_embedding, top_k=5, include_metadata=True, namespace=repo_url)\n",
        "    #top_matches = pinecone_index.query(vector=raw_query_embedding.tolist(), top_k=5, include_metadata=True, namespace=repo_url)\n",
        "\n",
        "    # Get the list of retrieved texts\n",
        "    contexts = [item['metadata']['text'] for item in top_matches['matches']]\n",
        "\n",
        "    augmented_query = \"<CONTEXT>\\n\" + \"\\n\\n-------\\n\\n\".join(contexts[ : 10]) + \"\\n-------\\n</CONTEXT>\\n\\n\\n\\nMY QUESTION:\\n\" + query\n",
        "\n",
        "    # Modify the prompt below as need to improve the response quality\n",
        "    system_prompt = f\"\"\"You are a Senior Software Engineer, specializing in TypeScript and in other progrmming languages.\n",
        "\n",
        "    Answer any questions I have about the codebase, based on the code provided. Always consider all of the context provided when forming a response.\n",
        "    \"\"\"\n",
        "\n",
        "    llm_response = client.chat.completions.create(\n",
        "        model=\"llama-3.1-70b-versatile\", #model=\"llama-3.1-8b-instant\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": augmented_query}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return llm_response.choices[0].message.content\n",
        "\n",
        "def get_huggingface_embeddings(text, model_name=\"sentence-transformers/all-mpnet-base-v2\"):\n",
        "    model = SentenceTransformer(model_name)\n",
        "    return model.encode(text)\n",
        "\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"Codebase RAG Chatbot for GitHub repository URL\")\n",
        "st.text(\"Ask about the codebase. Example question: How is the javascript parser used?\")\n",
        "\n",
        "# GitHub repo input\n",
        "repo_url = st.text_input(\"Enter GitHub repository URL:\")\n",
        "if repo_url:\n",
        "\n",
        "  path = clone_repository(repo_url)\n",
        "  file_content = get_main_files_content(path)\n",
        "\n",
        "  # Set the PINECONE_API_KEY as an environment variable\n",
        "  pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
        "  os.environ['PINECONE_API_KEY'] = pinecone_api_key\n",
        "\n",
        "  # Initialize Pinecone\n",
        "  pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
        "\n",
        "  # Connect to your Pinecone index\n",
        "  pinecone_index = pc.Index(\"codebase-rag-index\")\n",
        "  # Initialize HuggingFace embeddings\n",
        "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "  vectorstore = PineconeVectorStore(\n",
        "  index_name=\"codebase-rag-index\",\n",
        "  embedding=embeddings #embedding=HuggingFaceEmbeddings()\n",
        "  )\n",
        "\n",
        "  documents = []\n",
        "\n",
        "  for file in file_content:\n",
        "    doc = Document(\n",
        "        page_content=f\"{file['name']}\\n{file['content']}\",\n",
        "        metadata={\"source\": file['name']}\n",
        "      )\n",
        "\n",
        "    documents.append(doc)\n",
        "\n",
        "\n",
        "\n",
        "  vectorstore = PineconeVectorStore.from_documents(\n",
        "    documents=documents,\n",
        "    embedding=embeddings, #embedding=HuggingFaceEmbeddings(),\n",
        "    index_name=\"codebase-rag-index\",\n",
        "    namespace=repo_url #namespace=f\"{repo_url}\"\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "  system_prompt = f\"\"\"You are a Senior Software Engineer,\n",
        "   specializing in TypeScript and in other progrmming languges.\n",
        "\n",
        "    Answer any questions I have about the codebase, based on the code provided. Always consider all of the context provided when forming a response.\n",
        "    \"\"\"\n",
        "  # Initialize Groq chat model\n",
        "  llm = ChatGroq(\n",
        "      api_key=os.getenv(\"GROQ_API_KEY\"),\n",
        "      model=\"llama-3.1-70b-versatile\", #model=\"llama-3.1-8b-instant\",\n",
        "      #messages=[\n",
        "      #      {\"role\": \"system\", \"content\": system_prompt},\n",
        "            #{\"role\": \"user\", \"content\": augmented_query}\n",
        "      #  ]\n",
        "\n",
        "      temperature=0)\n",
        "\n",
        "  # Define prompt template\n",
        "  system_prompt = \"\"\"\n",
        "        You are a Senior Software Engineer, specializing in TypeScript and in other progrmming languages.\n",
        "\n",
        "        Answer any questions I have about the codebase, based on the code provided.\n",
        "        Always consider all of the context provided when forming a response.\n",
        "\n",
        "        Context: {context}\n",
        "        Question: {question}\n",
        "        Answer:\n",
        "        \"\"\"\n",
        "  chat_prompt = PromptTemplate(template=system_prompt, input_variables=[\"context\", \"question\"])\n",
        "\n",
        "\n",
        "\n",
        "  # Set up QA chain\n",
        "  qa_chain = ConversationalRetrievalChain.from_llm(\n",
        "        llm, retriever=vectorstore.as_retriever(), return_source_documents=True\n",
        "        ,combine_docs_chain_kwargs={\"prompt\": chat_prompt}\n",
        "    )\n",
        "\n",
        "\n",
        "  # Initialize chat history\n",
        "  if \"messages\" not in st.session_state:\n",
        "      st.session_state.messages = []\n",
        "\n",
        "  # Display chat messages\n",
        "  for message in st.session_state.messages:\n",
        "      with st.chat_message(message[\"role\"]):\n",
        "          st.markdown(message[\"content\"])\n",
        "\n",
        "  # Chat input\n",
        "  if prompt := st.chat_input(\"Ask about the codebase\"):\n",
        "      st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "      with st.chat_message(\"user\"):\n",
        "            st.markdown(prompt)\n",
        "\n",
        "      with st.chat_message(\"assistant\"):\n",
        "          prompt=perform_rag(prompt, repo_url)\n",
        "          response = qa_chain({\"question\": prompt, \"chat_history\": [(m[\"role\"], m[\"content\"]) for m in st.session_state.messages]})\n",
        "          st.markdown(response[\"answer\"])\n",
        "          st.session_state.messages.append({\"role\": \"assistant\", \"content\": response[\"answer\"]})\n",
        "\n",
        "          # Optionally display source documents\n",
        "          with st.expander(\"Source Documents\"):\n",
        "              for doc in response[\"source_documents\"]:\n",
        "                    st.write(doc.page_content)\n",
        "\n",
        "else:\n",
        "    st.write(\"Please enter a GitHub repository URL to start chatting.\")\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "IIG2948eEjVo",
        "outputId": "158f8eb0-aadf-482e-b572-13a9647b901a"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n\\nSUPPORTED_EXTENSIONS = {\\'.py\\', \\'.js\\', \\'.tsx\\', \\'.jsx\\', \\'.ipynb\\', \\'.java\\',\\n                         \\'.cpp\\', \\'.ts\\', \\'.go\\', \\'.rs\\', \\'.vue\\', \\'.swift\\', \\'.c\\', \\'.h\\'}\\n\\nIGNORED_DIRS = {\\'node_modules\\', \\'venv\\', \\'env\\', \\'dist\\', \\'build\\', \\'.git\\',\\n                \\'__pycache__\\', \\'.next\\', \\'.vscode\\', \\'vendor\\'}\\n\\n\\ndef get_file_content(file_path, repo_path):\\n    \"\"\"\\n    Get content of a single file.\\n\\n    Args:\\n        file_path (str): Path to the file\\n\\n    Returns:\\n        Optional[Dict[str, str]]: Dictionary with file name and content\\n    \"\"\"\\n    try:\\n        with open(file_path, \\'r\\', encoding=\\'utf-8\\') as f:\\n            content = f.read()\\n\\n        # Get relative path from repo root\\n        rel_path = os.path.relpath(file_path, repo_path)\\n\\n        return {\\n            \"name\": rel_path,\\n            \"content\": content\\n        }\\n    except Exception as e:\\n        print(f\"Error processing file {file_path}: {str(e)}\")\\n        return None\\n\\n\\ndef get_main_files_content(repo_path: str):\\n    \"\"\"\\n    Get content of supported code files from the local repository.\\n\\n    Args:\\n        repo_path: Path to the local repository\\n\\n    Returns:\\n        List of dictionaries containing file names and contents\\n    \"\"\"\\n    files_content = []\\n\\n    try:\\n        for root, _, files in os.walk(repo_path):\\n            # Skip if current directory is in ignored directories\\n            if any(ignored_dir in root for ignored_dir in IGNORED_DIRS):\\n                continue\\n\\n            # Process each file in current directory\\n            for file in files:\\n                file_path = os.path.join(root, file)\\n                if os.path.splitext(file)[1] in SUPPORTED_EXTENSIONS:\\n                    file_content = get_file_content(file_path, repo_path)\\n                    if file_content:\\n                        files_content.append(file_content)\\n\\n    except Exception as e:\\n        print(f\"Error reading repository: {str(e)}\")\\n\\n    return files_content\\n\\n\\n\\ndef perform_rag(query, repo_url):\\n    client = OpenAI(\\n        base_url=\"https://api.groq.com/openai/v1\",\\n        api_key=os.getenv(\"GROQ_API_KEY\"))\\n\\n    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\\n    raw_query_embedding = embeddings.embed_query(query)\\n    #raw_query_embedding = get_huggingface_embeddings(query)\\n\\n    top_matches = pinecone_index.query(vector=raw_query_embedding, top_k=5, include_metadata=True, namespace=repo_url)\\n    #top_matches = pinecone_index.query(vector=raw_query_embedding.tolist(), top_k=5, include_metadata=True, namespace=repo_url)\\n\\n    # Get the list of retrieved texts\\n    contexts = [item[\\'metadata\\'][\\'text\\'] for item in top_matches[\\'matches\\']]\\n\\n    augmented_query = \"<CONTEXT>\\n\" + \"\\n\\n-------\\n\\n\".join(contexts[ : 10]) + \"\\n-------\\n</CONTEXT>\\n\\n\\n\\nMY QUESTION:\\n\" + query\\n\\n    # Modify the prompt below as need to improve the response quality\\n    system_prompt = f\"\"\"You are a Senior Software Engineer, specializing in TypeScript and in other progrmming languages.\\n\\n    Answer any questions I have about the codebase, based on the code provided. Always consider all of the context provided when forming a response.\\n    \"\"\"\\n\\n    llm_response = client.chat.completions.create(\\n        model=\"llama-3.1-70b-versatile\", #model=\"llama-3.1-8b-instant\",\\n        messages=[\\n            {\"role\": \"system\", \"content\": system_prompt},\\n            {\"role\": \"user\", \"content\": augmented_query}\\n        ]\\n    )\\n\\n    return llm_response.choices[0].message.content\\n\\ndef get_huggingface_embeddings(text, model_name=\"sentence-transformers/all-mpnet-base-v2\"):\\n    model = SentenceTransformer(model_name)\\n    return model.encode(text)\\n\\n\\n# Streamlit UI\\nst.title(\"Codebase RAG Chatbot for GitHub repository URL\")\\nst.text(\"Ask about the codebase. Example question: How is the javascript parser used?\")\\n\\n# GitHub repo input\\nrepo_url = st.text_input(\"Enter GitHub repository URL:\")\\nif repo_url:\\n\\n  path = clone_repository(repo_url)\\n  file_content = get_main_files_content(path)\\n\\n  # Set the PINECONE_API_KEY as an environment variable\\n  pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\\n  os.environ[\\'PINECONE_API_KEY\\'] = pinecone_api_key\\n\\n  # Initialize Pinecone\\n  pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\\n\\n  # Connect to your Pinecone index\\n  pinecone_index = pc.Index(\"codebase-rag-index\")\\n  # Initialize HuggingFace embeddings\\n  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\\n  vectorstore = PineconeVectorStore(\\n  index_name=\"codebase-rag-index\",\\n  embedding=embeddings #embedding=HuggingFaceEmbeddings()\\n  )\\n\\n  documents = []\\n\\n  for file in file_content:\\n    doc = Document(\\n        page_content=f\"{file[\\'name\\']}\\n{file[\\'content\\']}\",\\n        metadata={\"source\": file[\\'name\\']}\\n      )\\n\\n    documents.append(doc)\\n\\n\\n\\n  vectorstore = PineconeVectorStore.from_documents(\\n    documents=documents,\\n    embedding=embeddings, #embedding=HuggingFaceEmbeddings(),\\n    index_name=\"codebase-rag-index\",\\n    namespace=repo_url #namespace=f\"{repo_url}\"\\n    )\\n\\n\\n\\n  system_prompt = f\"\"\"You are a Senior Software Engineer,\\n   specializing in TypeScript and in other progrmming languges.\\n\\n    Answer any questions I have about the codebase, based on the code provided. Always consider all of the context provided when forming a response.\\n    \"\"\"\\n  # Initialize Groq chat model\\n  llm = ChatGroq(\\n      api_key=os.getenv(\"GROQ_API_KEY\"),\\n      model=\"llama-3.1-70b-versatile\", #model=\"llama-3.1-8b-instant\",\\n      #messages=[\\n      #      {\"role\": \"system\", \"content\": system_prompt},\\n            #{\"role\": \"user\", \"content\": augmented_query}\\n      #  ]\\n\\n      temperature=0)\\n\\n  # Define prompt template\\n  system_prompt = \"\"\"\\n        You are a Senior Software Engineer, specializing in TypeScript and in other progrmming languages.\\n\\n        Answer any questions I have about the codebase, based on the code provided.\\n        Always consider all of the context provided when forming a response.\\n\\n        Context: {context}\\n        Question: {question}\\n        Answer:\\n        \"\"\"\\n  chat_prompt = PromptTemplate(template=system_prompt, input_variables=[\"context\", \"question\"])\\n\\n\\n\\n  # Set up QA chain\\n  qa_chain = ConversationalRetrievalChain.from_llm(\\n        llm, retriever=vectorstore.as_retriever(), return_source_documents=True\\n        ,combine_docs_chain_kwargs={\"prompt\": chat_prompt}\\n    )\\n\\n\\n  # Initialize chat history\\n  if \"messages\" not in st.session_state:\\n      st.session_state.messages = []\\n\\n  # Display chat messages\\n  for message in st.session_state.messages:\\n      with st.chat_message(message[\"role\"]):\\n          st.markdown(message[\"content\"])\\n\\n  # Chat input\\n  if prompt := st.chat_input(\"Ask about the codebase\"):\\n      st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\\n      with st.chat_message(\"user\"):\\n            st.markdown(prompt)\\n\\n      with st.chat_message(\"assistant\"):\\n          prompt=perform_rag(prompt, repo_url)\\n          response = qa_chain({\"question\": prompt, \"chat_history\": [(m[\"role\"], m[\"content\"]) for m in st.session_state.messages]})\\n          st.markdown(response[\"answer\"])\\n          st.session_state.messages.append({\"role\": \"assistant\", \"content\": response[\"answer\"]})\\n\\n          # Optionally display source documents\\n          with st.expander(\"Source Documents\"):\\n              for doc in response[\"source_documents\"]:\\n                    st.write(doc.page_content)\\n\\nelse:\\n    st.write(\"Please enter a GitHub repository URL to start chatting.\")\\n\\n\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "%%writefile /content/app.py\n",
        "import streamlit as st\n",
        "import os\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "#from langchain.vectorstores import Pinecone\n",
        "from pinecone import Pinecone\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "# Initialize Pinecone\n",
        "pinecone_client = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"), environment=\"codebase-rag\")\n",
        "\n",
        "\n",
        "# Initialize HuggingFace embeddings\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# Initialize Groq chat model\n",
        "chat = ChatGroq(api_key=os.getenv(\"GROQ_API_KEY\"),\n",
        "                model=\"llama-3.1-8b-instant\", temperature=0)\n",
        "\n",
        "# Define available codebases\n",
        "codebases = {\n",
        "    \"SecureAgent\":\"https://github.com/CoderAgent/SecureAgent\",\n",
        "    \"Document-Genie-using-RAG-Framwork\": \"https://github.com/SriLaxmi1993/Document-Genie-using-RAG-Framwork\"\n",
        "}\n",
        "\n",
        "st.title(\"Codebase Chat\")\n",
        "\n",
        "# Codebase selection\n",
        "selected_codebase = st.sidebar.selectbox(\"Select a codebase\", list(codebases.keys()))\n",
        "\n",
        "# Initialize or update vectorstore\n",
        "@st.cache_resource(hash_funcs={Pinecone: lambda _: None})\n",
        "def get_vectorstore(index_name=\"codebase-rag\"):\n",
        "    return Pinecone.from_existing_index(index_name=\"codebase-rag\", embedding=embeddings)\n",
        "\n",
        "vectorstore = get_vectorstore(codebases[selected_codebase])\n",
        "\n",
        "# Create the conversational chain\n",
        "qa = ConversationalRetrievalChain.from_llm(\n",
        "    llm=chat,\n",
        "    retriever=vectorstore.as_retriever(),\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n",
        "# Initialize chat history\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "# Clear chat history when codebase changes\n",
        "if \"last_codebase\" not in st.session_state or st.session_state.last_codebase != selected_codebase:\n",
        "    st.session_state.messages = []\n",
        "    st.session_state.last_codebase = selected_codebase\n",
        "\n",
        "# Display chat messages\n",
        "for message in st.session_state.messages:\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "        st.markdown(message[\"content\"])\n",
        "\n",
        "# User input\n",
        "if prompt := st.chat_input(f\"Ask about the {selected_codebase} codebase\"):\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "    with st.chat_message(\"user\"):\n",
        "        st.markdown(prompt)\n",
        "\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        response = qa({\"question\": prompt, \"chat_history\": [(m[\"role\"], m[\"content\"]) for m in st.session_state.messages]})\n",
        "        st.markdown(response[\"answer\"])\n",
        "\n",
        "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response[\"answer\"]})\n",
        "\n",
        "# Display source code snippets\n",
        "if st.checkbox(\"Show source code\"):\n",
        "    for doc in response[\"source_documents\"]:\n",
        "        st.code(doc.page_content, language=\"python\")\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "nrwSWVhxep6q",
        "outputId": "01020b8f-f18e-4d2b-a420-668d23d55389"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n%%writefile /content/app.py\\nimport streamlit as st\\nimport os\\nfrom langchain.embeddings import HuggingFaceEmbeddings\\n#from langchain.vectorstores import Pinecone\\nfrom pinecone import Pinecone\\nfrom langchain_groq import ChatGroq\\nfrom langchain.chains import ConversationalRetrievalChain\\nfrom langchain_pinecone import PineconeVectorStore\\n\\n# Initialize Pinecone\\npinecone_client = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"), environment=\"codebase-rag\")\\n\\n\\n# Initialize HuggingFace embeddings\\nembeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\\n\\n# Initialize Groq chat model\\nchat = ChatGroq(api_key=os.getenv(\"GROQ_API_KEY\"),\\n                model=\"llama-3.1-8b-instant\", temperature=0)\\n\\n# Define available codebases\\ncodebases = {\\n    \"SecureAgent\":\"https://github.com/CoderAgent/SecureAgent\",\\n    \"Document-Genie-using-RAG-Framwork\": \"https://github.com/SriLaxmi1993/Document-Genie-using-RAG-Framwork\"\\n}\\n\\nst.title(\"Codebase Chat\")\\n\\n# Codebase selection\\nselected_codebase = st.sidebar.selectbox(\"Select a codebase\", list(codebases.keys()))\\n\\n# Initialize or update vectorstore\\n@st.cache_resource(hash_funcs={Pinecone: lambda _: None})\\ndef get_vectorstore(index_name=\"codebase-rag\"):\\n    return Pinecone.from_existing_index(index_name=\"codebase-rag\", embedding=embeddings)\\n\\nvectorstore = get_vectorstore(codebases[selected_codebase])\\n\\n# Create the conversational chain\\nqa = ConversationalRetrievalChain.from_llm(\\n    llm=chat,\\n    retriever=vectorstore.as_retriever(),\\n    return_source_documents=True\\n)\\n\\n# Initialize chat history\\nif \"messages\" not in st.session_state:\\n    st.session_state.messages = []\\n\\n# Clear chat history when codebase changes\\nif \"last_codebase\" not in st.session_state or st.session_state.last_codebase != selected_codebase:\\n    st.session_state.messages = []\\n    st.session_state.last_codebase = selected_codebase\\n\\n# Display chat messages\\nfor message in st.session_state.messages:\\n    with st.chat_message(message[\"role\"]):\\n        st.markdown(message[\"content\"])\\n\\n# User input\\nif prompt := st.chat_input(f\"Ask about the {selected_codebase} codebase\"):\\n    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\\n    with st.chat_message(\"user\"):\\n        st.markdown(prompt)\\n\\n    with st.chat_message(\"assistant\"):\\n        response = qa({\"question\": prompt, \"chat_history\": [(m[\"role\"], m[\"content\"]) for m in st.session_state.messages]})\\n        st.markdown(response[\"answer\"])\\n\\n    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response[\"answer\"]})\\n\\n# Display source code snippets\\nif st.checkbox(\"Show source code\"):\\n    for doc in response[\"source_documents\"]:\\n        st.code(doc.page_content, language=\"python\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "%%writefile /content/app.py\n",
        "import streamlit as st\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "import cv2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import PIL.Image\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))\n",
        "#genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))\n",
        "#genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "\n",
        "\n",
        "import streamlit as st\n",
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "st.title(\"llama-3.1-70b-versatile clone\")\n",
        "\n",
        "# Set OpenAI API key from Streamlit secrets\n",
        "import os\n",
        "\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url=\"https://api.groq.com/openai/v1\",\n",
        "    api_key=os.getenv(\"GROQ_API_KEY\")\n",
        ")\n",
        "# Set a default model\n",
        "if \"openai_model\" not in st.session_state:\n",
        "    st.session_state[\"openai_model\"] = \"llama-3.1-70b-versatile\"\n",
        "\n",
        "# Initialize chat history\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "# Display chat messages from history on app rerun\n",
        "for message in st.session_state.messages:\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "        st.markdown(message[\"content\"])\n",
        "\n",
        "# Accept user input\n",
        "if prompt := st.chat_input(\"What is up?\"):\n",
        "    # Add user message to chat history\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "    # Display user message in chat message container\n",
        "    with st.chat_message(\"user\"):\n",
        "        st.markdown(prompt)\n",
        "\n",
        "# Display assistant response in chat message container\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        stream = client.chat.completions.create(\n",
        "            model=st.session_state[\"openai_model\"],\n",
        "            messages=[\n",
        "                {\"role\": m[\"role\"], \"content\": m[\"content\"]}\n",
        "                for m in st.session_state.messages\n",
        "            ],\n",
        "            stream=True,\n",
        "        )\n",
        "        response = st.write_stream(stream)\n",
        "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "r3syhw-YQ-Ft",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "276be228-ad5a-458f-fc58-b6ea57bb7103"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n%%writefile /content/app.py\\nimport streamlit as st\\nimport tensorflow as tf\\nfrom tensorflow.keras.models import load_model\\nfrom tensorflow.keras.preprocessing import image\\nimport numpy as np\\nimport plotly.graph_objects as go\\nimport cv2\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\\nfrom tensorflow.keras.optimizers import Adamax\\nfrom tensorflow.keras.metrics import Precision, Recall\\nimport google.generativeai as genai\\nfrom google.colab import userdata\\nimport PIL.Image\\nimport os\\nfrom google.colab import userdata\\nfrom dotenv import load_dotenv\\nload_dotenv()\\n\\ngenai.configure(api_key=os.getenv(\\'GOOGLE_API_KEY\\'))\\n#genai.configure(api_key=os.getenv(\\'GOOGLE_API_KEY\\'))\\n#genai.configure(api_key=userdata.get(\\'GOOGLE_API_KEY\\'))\\n\\n\\nimport streamlit as st\\nfrom openai import OpenAI\\nimport os\\n\\nst.title(\"llama-3.1-70b-versatile clone\")\\n\\n# Set OpenAI API key from Streamlit secrets\\nimport os\\n\\n\\nclient = OpenAI(\\n    base_url=\"https://api.groq.com/openai/v1\",\\n    api_key=os.getenv(\"GROQ_API_KEY\")\\n)\\n# Set a default model\\nif \"openai_model\" not in st.session_state:\\n    st.session_state[\"openai_model\"] = \"llama-3.1-70b-versatile\"\\n\\n# Initialize chat history\\nif \"messages\" not in st.session_state:\\n    st.session_state.messages = []\\n\\n# Display chat messages from history on app rerun\\nfor message in st.session_state.messages:\\n    with st.chat_message(message[\"role\"]):\\n        st.markdown(message[\"content\"])\\n\\n# Accept user input\\nif prompt := st.chat_input(\"What is up?\"):\\n    # Add user message to chat history\\n    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\\n    # Display user message in chat message container\\n    with st.chat_message(\"user\"):\\n        st.markdown(prompt)\\n\\n# Display assistant response in chat message container\\n    with st.chat_message(\"assistant\"):\\n        stream = client.chat.completions.create(\\n            model=st.session_state[\"openai_model\"],\\n            messages=[\\n                {\"role\": m[\"role\"], \"content\": m[\"content\"]}\\n                for m in st.session_state.messages\\n            ],\\n            stream=True,\\n        )\\n        response = st.write_stream(stream)\\n    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\\n\\n\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "%%writefile /content/app.py\n",
        "import streamlit as st\n",
        "import os\n",
        "from langchain.document_loaders import GitLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Pinecone\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "import pinecone\n",
        "\n",
        "# Initialize Pinecone\n",
        "pinecone.init(api_key=os.getenv(\"PINECONE_API_KEY\"), environment=os.getenv(\"PINECONE_ENV\"))\n",
        "index_name = \"codebase-index\"\n",
        "\n",
        "# Set up embeddings and LLM\n",
        "embeddings = OpenAIEmbeddings()\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"GitHub Codebase Chatbot\")\n",
        "\n",
        "# GitHub repo input\n",
        "repo_url = st.text_input(\"Enter GitHub repository URL:\")\n",
        "if repo_url:\n",
        "    # Load and process the repository\n",
        "    loader = GitLoader(clone_url=repo_url, branch=\"main\")\n",
        "    documents = loader.load()\n",
        "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "    texts = text_splitter.split_documents(documents)\n",
        "\n",
        "    # Create or update Pinecone index\n",
        "    vectorstore = Pinecone.from_documents(texts, embeddings, index_name=index_name)\n",
        "\n",
        "    # Set up QA chain\n",
        "    qa_chain = ConversationalRetrievalChain.from_llm(\n",
        "        llm, retriever=vectorstore.as_retriever(), return_source_documents=True\n",
        "    )\n",
        "\n",
        "    # Initialize chat history\n",
        "    if \"messages\" not in st.session_state:\n",
        "        st.session_state.messages = []\n",
        "\n",
        "    # Display chat messages\n",
        "    for message in st.session_state.messages:\n",
        "        with st.chat_message(message[\"role\"]):\n",
        "            st.markdown(message[\"content\"])\n",
        "\n",
        "    # Chat input\n",
        "    if prompt := st.chat_input(\"Ask about the codebase\"):\n",
        "        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "        with st.chat_message(\"user\"):\n",
        "            st.markdown(prompt)\n",
        "\n",
        "        with st.chat_message(\"assistant\"):\n",
        "            response = qa_chain({\"question\": prompt, \"chat_history\": [(m[\"role\"], m[\"content\"]) for m in st.session_state.messages]})\n",
        "            st.markdown(response[\"answer\"])\n",
        "            st.session_state.messages.append({\"role\": \"assistant\", \"content\": response[\"answer\"]})\n",
        "\n",
        "            # Optionally display source documents\n",
        "            with st.expander(\"Source Documents\"):\n",
        "                for doc in response[\"source_documents\"]:\n",
        "                    st.write(doc.page_content)\n",
        "\n",
        "else:\n",
        "    st.write(\"Please enter a GitHub repository URL to start chatting.\")\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "ax6E7B0Ihzv_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "1d2d96e7-213b-4a06-f1b0-488d8738a403"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n%%writefile /content/app.py\\nimport streamlit as st\\nimport os\\nfrom langchain.document_loaders import GitLoader\\nfrom langchain.text_splitter import CharacterTextSplitter\\nfrom langchain.embeddings import OpenAIEmbeddings\\nfrom langchain.vectorstores import Pinecone\\nfrom langchain.chat_models import ChatOpenAI\\nfrom langchain.chains import ConversationalRetrievalChain\\nimport pinecone\\n\\n# Initialize Pinecone\\npinecone.init(api_key=os.getenv(\"PINECONE_API_KEY\"), environment=os.getenv(\"PINECONE_ENV\"))\\nindex_name = \"codebase-index\"\\n\\n# Set up embeddings and LLM\\nembeddings = OpenAIEmbeddings()\\nllm = ChatOpenAI(temperature=0)\\n\\n# Streamlit UI\\nst.title(\"GitHub Codebase Chatbot\")\\n\\n# GitHub repo input\\nrepo_url = st.text_input(\"Enter GitHub repository URL:\")\\nif repo_url:\\n    # Load and process the repository\\n    loader = GitLoader(clone_url=repo_url, branch=\"main\")\\n    documents = loader.load()\\n    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\\n    texts = text_splitter.split_documents(documents)\\n\\n    # Create or update Pinecone index\\n    vectorstore = Pinecone.from_documents(texts, embeddings, index_name=index_name)\\n\\n    # Set up QA chain\\n    qa_chain = ConversationalRetrievalChain.from_llm(\\n        llm, retriever=vectorstore.as_retriever(), return_source_documents=True\\n    )\\n\\n    # Initialize chat history\\n    if \"messages\" not in st.session_state:\\n        st.session_state.messages = []\\n\\n    # Display chat messages\\n    for message in st.session_state.messages:\\n        with st.chat_message(message[\"role\"]):\\n            st.markdown(message[\"content\"])\\n\\n    # Chat input\\n    if prompt := st.chat_input(\"Ask about the codebase\"):\\n        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\\n        with st.chat_message(\"user\"):\\n            st.markdown(prompt)\\n\\n        with st.chat_message(\"assistant\"):\\n            response = qa_chain({\"question\": prompt, \"chat_history\": [(m[\"role\"], m[\"content\"]) for m in st.session_state.messages]})\\n            st.markdown(response[\"answer\"])\\n            st.session_state.messages.append({\"role\": \"assistant\", \"content\": response[\"answer\"]})\\n\\n            # Optionally display source documents\\n            with st.expander(\"Source Documents\"):\\n                for doc in response[\"source_documents\"]:\\n                    st.write(doc.page_content)\\n\\nelse:\\n    st.write(\"Please enter a GitHub repository URL to start chatting.\")\\n\\n\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bu0kMfpfP-hy"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LDKAXsu1qkKF"
      },
      "execution_count": 50,
      "outputs": []
    }
  ]
}